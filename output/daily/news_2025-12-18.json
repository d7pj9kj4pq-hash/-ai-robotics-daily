[
  {
    "title": "OpenAI推出“AI工具链”，让湿实验室生物研究更快更智能",
    "summary": "",
    "raw_summary": "",
    "link": "https://www.jiqizhixin.com/articles/2025-12-18-3",
    "source": "机器之心",
    "published": "Thu, 18 Dec 2025 12:07:00 +0800",
    "category": "AI通用",
    "quality_score": 4,
    "collected_at": "2025-12-18T07:41:20.934481"
  },
  {
    "title": "比LoRA更快更强，全新框架LoFA上线，秒级适配大模型",
    "summary": "",
    "raw_summary": "",
    "link": "https://www.jiqizhixin.com/articles/2025-12-18",
    "source": "机器之心",
    "published": "Thu, 18 Dec 2025 10:20:26 +0800",
    "category": "大模型",
    "quality_score": 4,
    "collected_at": "2025-12-18T07:41:20.934498"
  },
  {
    "title": "官宣！姚顺雨出任腾讯首席AI科学家，带队大语言模型、AI Infra",
    "summary": "",
    "raw_summary": "",
    "link": "https://www.jiqizhixin.com/articles/2025-12-17-17",
    "source": "机器之心",
    "published": "Wed, 17 Dec 2025 17:28:00 +0800",
    "category": "AI通用",
    "quality_score": 4,
    "collected_at": "2025-12-18T07:41:20.934504"
  },
  {
    "title": "医生版ChatGPT，估值120亿美元",
    "summary": "",
    "raw_summary": "",
    "link": "https://www.qbitai.com/2025/12/361726.html",
    "source": "量子位",
    "published": "Thu, 18 Dec 2025 05:45:12 +0000",
    "category": "医疗健康",
    "quality_score": 4,
    "collected_at": "2025-12-18T07:41:20.934511"
  },
  {
    "title": "国产AI芯片看两个指标：模型覆盖+集群规模能力 | 百度智能云王雁鹏@MEET2026",
    "summary": "模型绑定硬件，硬件才能真正被接受",
    "raw_summary": "模型绑定硬件，硬件才能真正被接受",
    "link": "https://www.qbitai.com/2025/12/361645.html",
    "source": "量子位",
    "published": "Thu, 18 Dec 2025 04:37:30 +0000",
    "category": "芯片硬件",
    "quality_score": 5,
    "collected_at": "2025-12-18T07:41:20.934517"
  },
  {
    "title": "ISC.AI 2025创新百强颁奖典礼落幕，首发智能体专家驱动产业升级",
    "summary": "",
    "raw_summary": "",
    "link": "https://www.qbitai.com/2025/12/361631.html",
    "source": "量子位",
    "published": "Thu, 18 Dec 2025 03:53:41 +0000",
    "category": "AI通用",
    "quality_score": 5,
    "collected_at": "2025-12-18T07:41:20.934521"
  },
  {
    "title": "小米大模型“杀”进第一梯队：代码能力开源第一，智商情商全在线",
    "summary": "百万输出Token只要两块一",
    "raw_summary": "百万输出Token只要两块一",
    "link": "https://www.qbitai.com/2025/12/361601.html",
    "source": "量子位",
    "published": "Thu, 18 Dec 2025 00:57:11 +0000",
    "category": "大模型",
    "quality_score": 4,
    "collected_at": "2025-12-18T07:41:20.934526"
  },
  {
    "title": "对话张进：当 AI 不再只靠「看见」去理解世界丨GAIR 2025",
    "summary": "这几年，随着人工智能逐步走出实验室，进入真实世界，感知问题重新回到技术讨论的中心。从自动驾驶、智能终端，到空间智能和具身智能，系统不再只是理解信息，而是必须在复杂、动态的物理环境中持续获取可靠信号。现实应用中，单一依赖视觉的感知方式正不断暴露出局限，也由此促使学术界和产业界重新审视多模态感知在下一阶段智能系统中的位置。在这样的背景下，声波、毫米波等无线感知技术逐渐受到关注。这类技术并不以看见为目标，而是通过对物理信号的建模与分析，让设备在不增加额外负担、也更少干扰用户的情况下理解环境与行为。它们距离全面普及仍有距离，但已被视为支撑空间智能与真实世界交互的重要基础。在 GAIR 2025 期间，南方科技大学副教授张进围绕无线感知、多模态感知以及面向空间智能的新型感知技术展开分享。长期从事相关研究的她，更关注这些技术在真实场景中的可行性与可信性，而不仅仅是实验条件下的效果表现。在会议现场，AI 科技评论与张进教授围绕无线感知及其在真实世界中的应用展开对话。对话中，相比对技术前景的宏观判断，她更愿意从研究实践出发，讨论感知技术在落地过程中遭遇的限制与挑战，并且了分享自己精彩的个人经历和行业观",
    "raw_summary": "<p>这几年，随着人工智能逐步走出实验室，进入真实世界，感知问题重新回到技术讨论的中心。</p><p>从自动驾驶、智能终端，到空间智能和具身智能，系统不再只是理解信息，而是必须在复杂、动态的物理环境中持续获取可靠信号。现实应用中，单一依赖视觉的感知方式正不断暴露出局限，也由此促使学术界和产业界重新审视多模态感知在下一阶段智能系统中的位置。</p><p>在这样的背景下，声波、毫米波等无线感知技术逐渐受到关注。这类技术并不以看见为目标，而是通过对物理信号的建模与分析，让设备在不增加额外负担、也更少干扰用户的情况下理解环境与行为。它们距离全面普及仍有距离，但已被视为支撑空间智能与真实世界交互的重要基础。</p><p>在 GAIR 2025 期间，南方科技大学副教授张进围绕无线感知、多模态感知以及面向空间智能的新型感知技术展开分享。长期从事相关研究的她，更关注这些技术在真实场景中的可行性与可信性，而不仅仅是实验条件下的效果表现。</p><p>在会议现场，AI 科技评论与张进教授围绕无线感知及其在真实世界中的应用展开对话。对话中，相比对技术前景的宏观判断，她更愿意从研究实践出发，讨论感知技术在落地过程中遭遇的限制与挑战，并且了分享自己精彩的个人经历和行业观点。相关内容 AI 科技评论做了不改变原意的编辑整理：</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251218/6943704de2602.png?imageView2/2/w/740\" /></p><h2>一所大学的成长，与一个学者的判断</h2><p>AI 科技评论：您从清华到港科大，学术背景非常扎实，为什么最终选择来到南方科技大学任教？</p><p>张进：我当时选择南方科技大学，核心原因并不是个人发展的跳槽逻辑，而是我非常清楚一所年轻大学在正确制度和环境下，能够成长到什么程度。香港科技大学本身就是一个非常典型的例子，它成立只有二十多年，但已经能做到世界一流。我在港科大工作过，对这件事有非常直接、切身的认识。</p><p>南科大当时正处在一个必须要成长起来的阶段，而且是深圳市明确要重点支持、重点打造的一所大学。我们当时内部有一句很响亮的话：“叫醒南科大学生的不是闹钟，而是中国高校改革的号角。”这并不是一句口号，而是一种真实存在的状态，大家是以一种创业的心态在办大学。</p><p>我进入南科大的时候，学校甚至还没有计算机系，是从零开始搭建的。我们找系主任、建学科方向、定培养方案，一步一步把计算机系做起来。到现在为止，计算机系每年大约培养 200 名学生，十年下来接近 2000 人。虽然不能说已经非常强，但至少体系完整、规模稳定，这对一所年轻大学来说并不容易。</p><p>AI 科技评论：如果把南科大当成一家创业公司来看，您是否更像创始人型的角色？</p><p>张进：某种程度上确实是这样。这种参与感会让你对学校产生完全不同的情感。学生怎么培养、课程怎么设计、学科方向怎么布局，这些都不是既定规则，而是你亲自参与制定的。</p><p>我现在不仅是计算机系的副系主任，负责研究生培养和科研工作，同时也是致仁书院的副院长。书院制是南科大非常有特色的一部分。再加上去年我们成功拿到了博士点，整个计算机系从 2014 年开始先做本科培养，再到后来逐步完善研究生培养体系，这一整套结构，都是我们一起搭建起来的。</p><p>正因为是从无到有参与建设，这种感情和责任感是非常不一样的。</p><p>AI 科技评论：除了学校本身，深圳这座城市对您来说意味着什么？</p><p>张进：很多人一提深圳，第一反应是很富裕，但我觉得深圳的优势绝不只是有钱。美国也有钱，硅谷也有钱，但硅谷很多硬件最终还是要回到深圳来做。</p><p>深圳真正厉害的地方在于，它拥有非常完整的产业链配套，同时又具备高密度的人才储备和真实存在的市场需求。这三件事叠加在一起，是非常罕见的。</p><p>港科大的很多毕业生，最后都会选择来深圳，要么创业，要么做科研。我们希望做的是那种真正能改变世界、并且能和产业紧密结合的研究方向，而深圳正好处在一个高速成长的阶段。在这个阶段进入，而不是等它已经到顶了再进去，会有更大的空间。</p><p class=\"heading-2 ace-line old-record-id-Mbx5d8KwOoocxJxkAsDcvdyhnSe\">从通信到无线感知的「自然递进」</p><p>AI 科技评论：您的研究方向跨度非常大，最早是从哪里开始的？</p><p>张进：我的研究方向确实经历了多次变化。硕士阶段在清华，我做的是 3G/4G 的无线移动通信系统，到港科大读博士后，进入计算机系，研究方向转向无线网络，主要关注 WiFi 多基站之间的协同部署。</p><p>后来又进一步做认知无线电，也就是让通信系统具备一定智能，能够自动判断频段占用情况，并进行动态切换。博士毕业之后，我开始尝试把无线信号用于智慧医疗场景。</p><p>一开始只是感知数据、传输数据，但很快我意识到，无线信号本身就可以用来感知人的健康状态。这是一个非常重要的转折点。</p><p>AI 科技评论：您在智慧医疗方面具体做过哪些探索？</p><p>张进：博士毕业后，我在港科大做了几年创业，和深圳市人民医院、深圳市第二人民医院有非常深入的合作。我们一起做了移动健康监测系统，包括网络医院的管理系统，用来管理几万名曾经看过病的患者，同时也做了脑卒中的筛查等工作。</p><p>从现在回头看，我们当时做得非常早。像 Fitbit、Jawbone 这些手环产品，当时都还没有出现。也正因为太早，技术条件、产业环境和市场认知都还没准备好，很多事情最终没能真正规模化落地。</p><p>这让我意识到，一些真正前沿、周期很长的事情，可能还是更适合回到学术界持续做。</p><p>AI 科技评论：您后来是如何系统性地进入感知这一方向的？雷峰网</p><p>张进：回到学术界之后，我并没有放弃对健康和环境感知的关注，而是开始从非视觉的角度重新思考这个问题。 2014 年我到南科大之后，开始系统研究毫米波雷达，到 2018、2019 年左右，又逐步引入声波感知，同时继续推进毫米波方向。</p><p>技术路径上，我们从最早的信号处理，逐步引入机器学习、深度学习，再发展到现在的大模型。这是一个非常自然的递进过程。我们这个方向的一个天然优势在于，我们既有扎实的信号处理背景，又有计算机和人工智能的背景，所以能够把物理信号和AI模型很好地结合起来。</p><h2>让设备「看不见」却「懂得更多」</h2><p>AI 科技评论：那您如何理解声波感知和毫米波感知？能否用通俗的方式解释？</p><p>张进：声波感知其实非常直观。你可以把手机、电脑、耳机想象成一只蝙蝠：扬声器发出人耳听不到的声波，声波打到周围环境后反射回来，再由麦克风接收，通过这些反射信号来感知环境和人体状态。</p><p>它可以用来检测呼吸、心跳，感知房间布局，识别手势姿态，甚至帮助设备之间判断相对位置关系。最大的好处是，它不需要额外增加新的传感器，成本低、体积小，而且感知能力并不弱。</p><p>毫米波感知大家最熟悉的是汽车前面的毫米波雷达，用来检测前方是否有车辆。但在生活场景中，它同样可以用来监测室内是否有人、人数多少、人的位置、心跳状态、是否发生跌倒等。同时它又看不到具体形象，在隐私保护方面比摄像头更友好。</p><p>AI 科技评论：您认为大众对感知技术最大的误解是什么？</p><p>张进：我觉得感知技术本身并不需要被大众理解。最好的技术，往往是你感觉不到的技术。</p><p>就像耳机，你戴上就能连上，这是最好的体验，如果你还得点来点去才能连上，你就会非常不爽。感知技术的核心目标，是让设备在具备环境理解能力之后，自然地完成交互，而不是让用户不断去告诉设备现在发生了什么。</p><p>AI 科技评论：在您看来，感知技术在推动 AI 和科学发展中有什么不可替代的作用？</p><p>张进：现在大家都在谈“空间智能”，但仅靠视觉、语音和图像是远远不够的。图像很难精确获取距离和真实空间结构，而要真正理解和交互物理世界，必须引入物理感知模态。</p><p>人类最早发展的智能并不是语言智能，而是空间智能。智能机器如果要成为真正的智能体，也必须具备对物理空间的理解和交互能力。这时候，声波、毫米波以及其她新型感知模态就变得不可或缺。</p><h2>当感知真正进入现实世界</h2><p>AI 科技评论：那感知结果是否可信？是否会被攻击？</p><p>张进：这是我们近两三年重点关注的问题。尤其是毫米波雷达已经大量应用在汽车上，对安全性的要求极高。如果感知系统被攻击，可能会让车辆看不到真实存在的车，或者凭空看到不存在的障碍物，从而引发严重事故。</p><p>因此我们不能假设世界上所有人都是好人。感知系统在信号设计、模型结构和整体系统层面，都必须具备抵御攻击的能力，才能真正做到可信。</p><p>AI 科技评论：从开始到现在，您的研究方向跨度这么大，如何看科研中的得与失？</p><p>张进：我觉得科研的本质是好奇心。如果你每天都在做已经会的事情，其实是没有太大意义的。方向会随着世界在发生什么、社会需要什么而变化，但科研的内核是不变的，发现问题、理解前沿、解决别人没解决的问题。</p><p>我也经常跟学生说，你们找工作的时候，不用只看公司要的技术是不是你博士或硕士期间做过的东西。真正重要的是你有没有系统性分析问题、构建解决方案的能力。一个成功的博士，就应该具备进入任何新领域的能力。</p><p>AI 科技评论：那您如何看待“女生不适合学工科”的说法？</p><p>张进：我完全不认同这种说法。我不认为女生的逻辑能力比男生差，很多时候是被反复暗示“你不行”，才真的不自信。</p><p>在我看来，女生学计算机反而有很多优势：稀缺性高、沟通能力强、共情能力强、更细心、抗挫折能力强、韧性更好。在需要团队协作的大型系统性研究中，这些都是非常重要的能力。</p><p>我培养过很多非常优秀的女学生，其中就包括南科大第一个拿到美国教职的本科生。所以女生完全可以、也非常适合选择计算机和硬核理工科。</p><p>AI 科技评论：如果让您描述未来三年内的感知世界，您会怎么说？</p><p>张进：我觉得感知领域未来一定是高度多样化、碎片化的，不会有一种技术可以解决所有问题。不同场景、不同设备约束、不同需求，会对应不同的技术组合。雷峰网</p><p>但最终目标是一致的：技术要真正落地到产品中，让产品变得足够智能，让用户不需要额外输入信息，设备就能理解物理世界。只要能做到这一点，不管用什么技术手段，都是好的感知技术。</p>",
    "link": "https://www.leiphone.com/category/yanxishe/dy4ahf8zgzT6wHDx.html",
    "source": "雷锋网",
    "published": "Thu, 18 Dec 2025 11:11:00 +0800",
    "category": "AI通用",
    "quality_score": 3,
    "collected_at": "2025-12-18T07:41:20.934533"
  },
  {
    "title": "摩尔线程王华：万卡训练中，最危险的往往是「不报错」｜GAIR 2025",
    "summary": "作者｜包永刚编辑｜林觉民2025年12月12-13日，第八届GAIR全球人工智能与机器人大会在深圳·博林天瑞喜来登酒店正式启幕。作为AI 产学研投界的标杆盛会，GAIR自2016年创办以来，始终坚守“传承+创新”内核，始终致力于连接技术前沿与产业实践。在人工智能逐步成为国家竞争核心变量的当下，算力正以前所未有的速度重塑技术路径与产业结构。13日举办的「AI 算力新十年」专场聚焦智能体系的底层核心——算力，从架构演进、生态构建到产业化落地展开系统讨论，试图为未来十年的中国AI产业，厘清关键变量与发展方向。王华在「AI算力新十年」论坛发表了主题为《基于国产GPU集群的大规模训练实践》的演讲。当海外头部公司已经建设十万卡、甚至二十万卡规模的 GPU 集群，万卡训练正在从“前沿探索”转变为大模型研发的基础设施能力。模型参数规模进入万亿级之后，真正拉开差距的，已不再只是单卡性能，而是训练周期能否被压缩、系统是否长期稳定、工程效率能否支撑高频迭代。在这样的背景下，万卡训练所面临的挑战也发生了根本变化。节点故障、性能抖动、通信与存储瓶颈，在集群规模被放大之后都会成为常态问题，很多在千卡规模下可以容忍",
    "raw_summary": "<p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251217/694250838c579.png?imageView2/2/w/740\" /></p><p>作者｜包永刚</p><p>编辑｜林觉民</p><p>2025年12月12-13日，第八届GAIR全球人工智能与机器人大会在深圳·博林天瑞喜来登酒店正式启幕。</p><p>作为AI 产学研投界的标杆盛会，GAIR自2016年创办以来，始终坚守“传承+创新”内核，始终致力于连接技术前沿与产业实践。</p><p>在人工智能逐步成为国家竞争核心变量的当下，算力正以前所未有的速度重塑技术路径与产业结构。13日举办的「AI 算力新十年」专场聚焦智能体系的底层核心——算力，从架构演进、生态构建到产业化落地展开系统讨论，试图为未来十年的中国AI产业，厘清关键变量与发展方向。</p><p>王华在「AI算力新十年」论坛发表了主题为《基于国产GPU集群的大规模训练实践》的演讲。</p><p>当海外头部公司已经建设十万卡、甚至二十万卡规模的 GPU 集群，万卡训练正在从“前沿探索”转变为大模型研发的基础设施能力。模型参数规模进入万亿级之后，真正拉开差距的，已不再只是单卡性能，而是训练周期能否被压缩、系统是否长期稳定、工程效率能否支撑高频迭代。</p><p>在这样的背景下，万卡训练所面临的挑战也发生了根本变化。<strong>节点故障、性能抖动、通信与存储瓶颈，在集群规模被放大之后都会成为常态问题，很多在千卡规模下可以容忍的风险，在万卡场景中都会被大幅放大。</strong></p><p>王华在演讲中将结合摩尔线程在国产 GPU 万卡级真实集群上的训练实践，系统拆解这一过程中遇到的关键难题，以及相应的工程解法。从并行策略选择、训练前的模拟与起飞检查，到异步 Checkpoint、慢节点治理，再到静默数据错误、Hang 以及 Inf/NaN 等稳定性问题的应对，<strong>他重点分享如何通过软件栈、自动化与可观测体系，把万卡训练从“能跑”推进到“可持续稳定地跑”。</strong></p><p>这些经验并非实验室结论，而是来自真实生产环境中反复验证后的工程积累，他希望摩尔线程的经验能够给想要做万卡训练的公司和机构一些借鉴。</p><p><span style=\"font-size: 16px;\"><strong>以下是王华演讲的精彩内容，雷峰网作了不改变原意的整理与编辑：</strong></span></p><p>我是王华，负责摩尔线程的AI与云计算相关业务。今天主要和大家分享，我们在大规模训练实践中遇到的一些问题，以及对应的解决方案。</p><p>万卡训练我们已经讨论和推进了一段时间。从去年开始到今年，我们陆续在真实集群上推进相关工作，中间确实遇到了大量问题。客观来看，大规模训练的技术挑战很大，但在这个过程中，我们也逐步把问题解决，并积累了很多经验，今天与大家分享。</p><p class=\"heading-1 ace-line old-record-id-doxcn3VZNuD1D7SOV4eTtZzYEUe\"><strong><span style=\"font-size: 24px;\">万卡训练为何成为大模型的必要条件？</span></strong></p><p>首先需要回答的是，为什么万卡，甚至更大规模的集群已经成为必要条件？</p><p>从模型算力需求趋势来看，主流模型，像DeepSeek或国产的万亿模型，基本都到了10的24次幂的量级。而国外一些大的模型，虽然没有公开资料明确给出规格，但根据市面上流传的消息，像比较大的Grok4、GPT-5或者比较新的Gemini3，基本都会达到10的25~26次幂的算力需求，这是非常巨大的算力需求。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251217/694250838e15a.png?imageView2/2/w/740\" /></p><p>在国内，当前已经开源的两个万亿参数模型，一个是 Kimi K2，另一个是蚂蚁的百灵，它们的总计算量主要由两个因素决定：一是模型参数规模，对于 MoE 模型来说，核心是激活参数；二是训练数据量。</p><p>Kimi K2 的计算量大约是3×10的24次幂FLOPs，激活参数规模是 32B，训练数据是15T；百灵的计算量大约是6×10的24次幂FLOPs，激活参数规模是50B，训练数据是20T。</p><p>如果以我们当前这一代训练卡做一个估算，对于3×10的24次幂FLOPs的算力需求来说，大概需要半年的时间；如果扩大到5000卡，需要40天；到了万卡，就只需要23天。对于百灵来说，因为算力翻了一倍，对应的时间也翻了一倍。<strong>对大模型来说，训练时间非常关键，现在模型的竞争非常激烈，而且我们经常会有一些新模型算法的实验，希望快速看到结果，所以训练时间越短越好，最好不要超过一个月。</strong></p><p>在海外，头部公司已经建设了十万卡甚至二十万卡规模的集群，更大规模的集群也在规划中了，这一方向在未来基本是确定性的趋势。</p><p class=\"heading-1 ace-line old-record-id-doxcnzghhg4XDpowPMQPZMWsmhd\"><strong><span style=\"font-size: 24px;\">如何把万卡训练集群「跑起来」？</span></strong></p><p>围绕大规模训练，摩尔线程从底层到顶层系统性地研发了软件栈。</p><p>在最底层，除了硬件，主要是集群调度的部分；向上是MUSA平台，它与CUDA兼容性，使得我们可以快速地迁移和运行模型；再往上是训练套件，针对摩尔线程的平台，我们对 MegatronLM、DeepSpeed、PyTorch、TransformerEngine 等主流框架进行了适配和优化，并且全部开源，在GitHub上就可以找到；更高一层，是Model Studio以及一系列自动化训练和部署工具。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251217/694250839419e.png?imageView2/2/w/740\" /></p><p><strong>在整个训练过程中，我们关注的核心是训练效率。</strong></p><p>从流程上看，大规模训练通常包括起飞检查、训练拉起（建立通信组、加载数据等）、正式训练、故障定位和处理、以及故障处理后进入下一个周期。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251217/69425083a25f2.png?imageView2/2/w/740\" /></p><p>过去在千卡规模下，集群可能连续运行半个月甚至一个月都不出问题。<strong>但万卡集群，单个节点出问题的概率会显著上升。</strong>早期即便是英伟达的万卡集群，也曾出现几小时就出一次错误的情况，我们在实践中同样经历了这一阶段。</p><p>因此，在万卡训练中，要提升整体效率，一方面必须提升正常训练阶段的性能，另一方面则要尽可能压缩所有非训练环节的时间，包括起飞检查、checkpoint、故障定位与恢复。只有把这些环节的时间压到足够短，训练效率才有实质性提升。</p><p>在性能优化层面，在起飞训练前，需要确定并行策略和超参。一种方法是可以通过实际拉起训练反复尝试不同配置，但在万卡规模下，每一次拉起试验的成本都非常高。为了降低成本，我们采用了模拟的方式。</p><p>我们开发并开源的SimuMax软件（可以在GitHub上找到），用于对不同模型和不同集群规模下的训练性能进行估算，帮助判断策略的合理性，并预估整体训练时间。这一模拟基于一系列理论计算，可以帮助判断当前训练是否已经达到速度上限。如果达到，说明性能基本到位；如果没有达到，则意味着仍然存在优化空间。围绕这一目标，我们在SimuMax中做了很多特性的支持，包括不同模型结构、并行策略、优化技术等。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251217/69425083a4096.png?imageView2/2/w/740\" /></p><p>在万卡集群中，起飞检查是非常有用的特性。训练启动时，调度系统会分配资源，而节点的故障、亚健康状态，以及系统层面的网络或存储异常，都会导致训练无法启动。</p><p>因此，我们在训练启动前，会先运行一组特定的benchmark（基准测试），对计算节点、网络、存储以及调度节点进行全面检查。更重要的是，当检测出问题后，起飞检查会自动剔除异常节点，不再依赖人工介入，实现真正的无人值守训练启动。</p><p>Checkpoint 是另一个对效率影响很大的环节。如果采用同步写的方式，checkpoint 往往需要数分钟时间，这期间无法进行训练，整个集群处于闲置状态。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251217/69425083ae5d5.png?imageView2/2/w/740\" /></p><p>为此，我们实现了异步checkpoint：先将checkpoint写入本地内存，后续再异步写入存储系统，将checkpoint时间压缩到秒级。这么做对于几千亿参数规模的模型来说，checkpoint 写入只需几秒即可，训练可以立即继续执行。</p><p>在DP并行策略的情况，并不需要每个节点都写checkpoint，我们对checkpoint进行切片，由不同节点负责不同分片，避免重复写入和资源浪费。如果某个负责分片的节点发生故障，则会分配其他节点完成写入任务。在读取阶段，如果某个节点挂掉，完全从后端存储读取会非常慢，我们采用了P2P机制，直接从其他节点的内存中加载checkpoint，将加载时间压缩到半分钟以内。有了这些优化，我们可以用非常高的频率来做checkpoint，例如每十分钟做一次。</p><p class=\"heading-1 ace-line old-record-id-doxcnpSHQxPmdii14sxUaKwH88d\"><strong><span style=\"font-size: 24px;\">万卡训练的挑战：稳定性与可控性</span></strong></p><p><strong>慢节点检测在大规模训练中同样非常关键，因为慢节点会拖慢整个集群的训练速度。</strong>慢节点的发现通常有两个来源：一类是节点或卡本身处于亚健康状态，在起飞检查阶段可以发现；另一类是在运行过程中出现亚健康状态，需要运行时的检查。</p><p>我们的解决方案是在训练过程中引入了整体监控机制。训练包含前向传播和反向传播，中间包括多个通信与计算步骤，我们会监控这些步骤的执行时间。计算和通信步骤的执行时间整体上符合统计分布规律，但不能拿绝对值去看每个步骤的快慢，不同的模型时间不一样，我们通过聚类分析识别某些异常的慢节点，并自动剔除，整个过程完全自动化。</p><p><strong>静默数据错误也是一个棘手的问题。</strong>与引起训练报错甚至中断的问题不同，静默数据错误不会触发异常，也不会中断训练，数值看起来“正常”，但实际上已经发生错误。造成静默数错误有几种原因，一种是计算硬件有一定的故障率，在一定概率下可能会算错，就会造成静默数据；另外，内存或显存上的ECC特性对性能的影响比较大，在训练的过程可能没有开启；在传输的过程中，也会出现纠错码失效的情况，导致误码没有被发现。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251217/694250845e28c.png?imageView2/2/w/740\" /></p><p>对于轻微的数值错误，在万亿参数规模下往往会被其他数值平均掉，影响不明显，可以继续训练。有一类是严重错误，可能导致Loss值或梯度出现一个非常大的偏差，Loss曲线会出现异常尖峰，频繁出现时会影响模型精度。如果这种问题经常发生，会导致训练精度的下降。<strong>还有一种致命错误，数值异常传递并最终导致出现NaN 或Inf，导致训练中断，只能回退到之前的checkpoint进行回训。</strong></p><p>因为非常难检查，整个业界也还在探索，我们一方面在硬件验收阶段和训练起飞检查阶段进行压力测试，尽早识别“体质较弱”的卡；另一方面，压测要多算子覆盖，除了GEMM、Attention外，还会用一些执行较少的算子，因为不同算子会用到卡的不同部件，达到全面压力测试的目的。同时，我们重点监控温度、电压等关键硬件指标，这些异常往往与错误高度相关。</p><p><strong>Hang 问题同样是万卡训练中较为棘手的一类问题。</strong>一旦发生Hang，往往整个集群都会被Hang住。如果所有节点都Hang住，定位源头非常困难。我们通过分布式分析的方式，结合通信库的日志，对所有参与节点的Hang原因进行记录和比对，从而定位异常节点。</p><p>一般情况下，Hang通过重启即可恢复，但如果某个节点经常Hang，会导致训练非常不稳定，此时需要将该节点剔除。解决Hang问题后，整体训练稳定性会有明显提升。</p><p>Inf（Infinity） 和 NaN（Not a Number）问题是业内普遍存在的难点，其难点在于传播性， Inf加减任何正常值，都会把正常值“吃掉”。因此，我们重点关注 Inf/NaN 最早出现的位置和时间点，定位那些频繁触发异常的算子或阶段。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251217/6942508455202.png?imageView2/2/w/740\" /></p><p>在集群洞察方面，我们会持续监控前向传播和反向传播中的计算和通信时间，慢节点检测正是基于这些数据做的分析。同时，我们引入了更全面的 Profiling 能力，可以在不中断训练的情况下，一键启动或停止性能分析器，按需采集训练数据，并进行火焰图等算子级分析，甚至可以将多个节点的数据汇聚后进行联合分析。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251217/6942508427396.png?imageView2/2/w/740\" /></p><p>最后，是统一的可观测系统。我们的可观测平台覆盖了大量系统与训练指标，即便前面的机制遗漏了问题，也可以在这里通过指标异常检测和联合分析被捕获。此前我们也通过这一平台，快速定位过由于个别节点超温导致的异常问题，并进一步追溯到散热层面的原因。</p><p>以上是我们做的一部分工作，在过去的时间里，我们积累了很多经验，很多都落到来我们产品里。现在我们也在万卡级别的集群上做一些训练工作，<strong>这方面的经验以及积累的内容我们分享给大家，希望对于后续想做大规模训练的公司和机构有一定的借鉴意义。</strong></p><p>感谢大家。</p>",
    "link": "https://www.leiphone.com/category/chips/GzQbwUjfbsaBdJmu.html",
    "source": "雷锋网",
    "published": "Thu, 18 Dec 2025 10:21:00 +0800",
    "category": "AI通用",
    "quality_score": 3,
    "collected_at": "2025-12-18T07:41:20.934538"
  }
]