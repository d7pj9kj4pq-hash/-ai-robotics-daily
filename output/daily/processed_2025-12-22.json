[
  {
    "title": "构建具身智能数据基础设施，「诺亦腾机器人」完成Pre-A+轮融资",
    "summary": "作者丨邱晓芬 编辑丨苏建勋 36 氪获悉，诺亦腾机器人（Noitom Robotics）近日完成Pre-A+轮融资。本轮融资由启明创投领投，五源资本、君联资本等机构参与投资，经纬创投、英诺天使基金追加投资，并实现超额认购。 在完成由阿尔法公社领投的Pre-A轮以及本轮融资后，诺亦腾机器人（Noitom Robotics）累计募集资金已达数亿元人民币。 本轮融资资金将主要用于持续投入具身智能所需的多模态数据采集、处理与交付的技术研发，加速规模化数据生产体系与工程化平台建设，以及进一步完善核心技术与工程团队配置与建设，提升产品化交付与服务能力，为诺亦腾机器人（Noitom Robotics）在全球范围内的长期发展打下坚实基础。 谈及本轮融资，「诺亦腾机器人」创始人、动作捕捉与人机交互领域资深技术专家戴若犁博士表示：”这不仅是对技术方向的认可，更是对长期主义的一次选择。感谢投资人信任这样一家“不造机器人的机器人公司’，我们也将以持续的技术投入和产品、服务能力，去回报这份信任。” 随着具身智能产业加速发展，高质量、多模态的训练数据正在成为推动行业进步的关键基础要素。 「诺亦腾机器人」是一家面向",
    "raw_summary": "<p>作者丨邱晓芬</p>\n  <p>编辑丨苏建勋</p>\n  <p><strong>36 氪获悉，诺亦腾机器人（Noitom Robotics）</strong>近日完成<strong>Pre-A+轮融资</strong>。本轮融资由<strong>启明创投领投，五源资本、君联资本</strong>等机构参与投资，<strong>经纬创投、英诺天使基金</strong>追加投资，并实现超额认购。</p>\n  <p>在完成由<strong>阿尔法公社领投的Pre-A轮</strong>以及本轮融资后，<strong>诺亦腾机器人（Noitom Robotics）累计募集资金已达数亿元人民币。</strong></p>\n  <p>本轮融资资金将主要用于持续投入具身智能所需的多模态数据采集、处理与交付的技术研发，加速规模化数据生产体系与工程化平台建设，以及进一步完善核心技术与工程团队配置与建设，提升产品化交付与服务能力，为诺亦腾机器人（Noitom Robotics）在全球范围内的长期发展打下坚实基础。&nbsp;</p>\n  <p>谈及本轮融资，「诺亦腾机器人」创始人、动作捕捉与人机交互领域资深技术专家<strong>戴若犁博士</strong>表示：”这不仅是对技术方向的认可，更是对长期主义的一次选择。感谢投资人信任这样一家“不造机器人的机器人公司’，我们也将以持续的技术投入和产品、服务能力，去回报这份信任。”</p>\n  <p>随着具身智能产业加速发展，高质量、多模态的训练数据正在成为推动行业进步的关键基础要素。</p>\n  <p>「诺亦腾机器人」是一家面向具身智能与人形机器人产业的<strong>数据公司</strong>。公司以<strong>“数据”</strong>为核心交付界面，为机器人企业、具身智能模型团队等提供高质量、可规模化的训练数据与相关基础设施能力。</p>\n  <p>在创办「诺亦腾机器人」之前，戴若犁联合创立了诺亦腾科技（Noitom Ltd.），深耕人体运动数字化领域十余年。作为技术与产品第一负责人，戴若犁帮助企业获取全球70%的专业动作捕捉市场份额，成功交付数万套动作捕捉系统。</p>\n  <p>在服务机器人与具身智能相关客户的过程中，戴若犁博士以及团队观察到行业对数据的需求正在发生结构性变化——数据获取、结构化与工程化能力将成为决定具身智能系统上限的重要因素，行业从过去偏“演示或内容制作”的小体量数据需求，快速转向面向训练的<strong>大体量、可规模化交付</strong>的数据需求。</p>\n  <p>基于对行业天花板与商业模式的判断，「诺亦腾机器人」选择从<strong>数据基础设施</strong>这一底层环节切入，专注构建面向产业的技术与平台能力。</p>\n  <p>据了解，「诺亦腾机器人」重点关注能够规模化、在不同本体之间复用的真实世界数据，从超高精度、超全模态的工厂采集（In-the-factory）数据，到基于真实环境采集追求视觉泛化性的野采（In-the-wild）数据，到探索以人为中心（Ｈuman-centric）的数据路径，提升数据的泛化价值与长期可用性。</p>\n  <p>此外，「诺亦腾机器人」也逐步在全球范围内推进数据工厂的工程化建设，逐步形成差异化优势，依托成熟的动作捕捉与人机交互技术体系，实现复杂人类行为的高精度采集。</p>\n  <p>在将行为数据结构化、标准化之后，「诺亦腾机器人」还在完善数据处理与交付链路，提升规模化生产效率，构建跨本体映射与数据利用支持的基础设施能力，以适配各类本体与不同层级的训练需求。</p>\n  <p>目前，「诺亦腾机器人」相关能力已在服务全球数十家人形机器人企业及具身智能模型客户的交付实践中得到验证。</p>\n  <h3>投资人评价</h3>\n  <p>启明创投主管合伙人周志峰表示：“随着具身智能的模型算法逐渐收敛，Scaling Law得到初步验证，高质量、可规模化地获取训练数据已成为助力机器人智能进一步跃进的核心要素。诺亦腾机器人团队是行业内极少数具备全栈数据能力的玩家，技术沉淀超过十年，在具身智能迈入加速发展期的当下入局，恰逢其时，乘势而上。”</p>\n  <p>五源资本合伙人刘凯表示：“2025 年是具身智能全行业Data Thirsty初现苗头的一年，也会是未来几年全行业的共识和痛点。诺亦腾机器人团队也是最早看到这一点的团队，团队具备全链条数据的供给能力，以及极强的数据产业化能力。戴若犁博士更是机器人行业的常青 KOL之一，具备顶尖的技术视野和全球产业覆盖能力。我们相信诺亦腾机器人将是Embodied AI行业最关键的Infra供给商，也将极大地推动具身智能行业的发展。”</p>\n  <p>经纬创投管理合伙人王华东表示：“经纬坚定看好并持续布局具身智能，我们看到产业正在加速发展，高质量数据成为行业共识的关键卡点。诺亦腾机器人团队具备超过十年人体高精度动作数据的经验，身位处于机器人数据领域国际第一梯队，未来将赋能全产业，推进具身智能不断打开天花板。”</p>\n  <p>君联资本合伙人王文龙表示：“从‘捕捉人体动作’到‘定义机器行为’，我们一路见证了戴若犁博士团队将技术洞察转化为产业标准的能力，期待诺亦腾机器人为整个行业铺设通往智能的数据基石。”</p>\n  <p>阿尔法公社创始合伙人许四清表示：“戴若犁博士的团队是全球范围内具身智能数据领域当仁不让的一线团队，技术实力、把握巨大市场机遇的能力以及连续创业百折不挠的企业家精神，是诺亦腾机器人的本色。阿尔法公社在最早期和团队一起谋划了新创业的起点，我们很荣幸成为诺亦腾机器人陪跑的伙伴。”</p>\n  <p>英诺天使基金表示：“高质量行为数据已成为具身智能行业发展的自主创新的推动因素，我们看好戴若犁博士和诺亦腾机器人团队在该领域的长期积累和丰富经验，期待其打造出赋能行业的数据基础设施。”</p>",
    "link": "https://36kr.com/p/3602557343908871?f=rss",
    "source": "36氪",
    "published": "2025-12-22 09:30:00  +0800",
    "category": "机器人",
    "quality_score": 3,
    "collected_at": "2025-12-22T04:14:26.235646",
    "key_data": [],
    "simple_summary": "\"诺亦腾机器人成功完成Pre-A+轮融资，致力于打造具身智能数据基础设施。\" \n\n或者更简洁：\n\n\"诺亦腾机器人Pre-A+轮融资到位，推进具身智能数据建设。\"",
    "xhs_content": "🤖【黑科技融资啦！】具身智能的领跑者「诺亦腾机器人」完成Pre-A轮融资，数亿人民币入账！🎉\n\n✅ 这轮融资由启明创投领投，多家大牛资本跟投，超额认购哦！\n✅ 专注多模态数据采集，打造智能机器人背后的硬核技术！\n✅ 戴博士领衔，动作捕捉领域的大牛团队，不造机器人的机器人公司，你好奇吗？\n\n💭 说到具身智能，那可是未来趋势，而「诺亦腾」正深耕高质量训练数据的宝藏，加速智能产业跑起来！想象一下，未来我们的机器伙伴能够更好地理解我们，与我们互动，是不是很酷？\n\n👇 互动时间！你如何看待具身智能的发展？你觉得机器人应该具备哪些“人性”特征？快来评论区聊聊，让我们一起预见未来！🌟\n\n#具身智能 #诺亦腾机器人 #融资新闻 #黑科技 #未来趋势 #机器人互动 #数据的力量 #科技改变生活",
    "douyin_content": "【开头：悬念式】\n画面：黑幕，一行白色文字逐渐显现，“数亿元投资，他们将改变什么？”\n字幕建议：文字逐渐清晰，配以紧张刺激的BGM，营造神秘氛围。\nBGM建议：选用激昂的悬疑音乐，如《The Eclipse》。\n\n【中间：核心信息点】\n画面1：切换至“诺亦腾机器人”的LOGO，随后快速展示机器人相关画面。\n字幕建议：LOGO出现后，快速切换字幕，“「诺亦腾机器人」完成Pre-A轮融资，数亿人民币助力创新！”\n画面2：动画演示多模态数据采集、处理与交付的技术研发。\n字幕建议：“多模态数据，开启具身智能新篇章！”\n画面3：展示团队工作画面，包括研发、讨论等。\n字幕建议：“技术团队升级，工程化平台加速建设。”\n\n【结尾：提问互动】\n画面：戴若犁博士发言的剪辑，面带微笑，充满信心。\n字幕建议：“「不造机器人的机器人公司」，你怎么看？”\nBGM建议：音乐渐弱，突出人声。\n提问互动：画面最后出现文字，“你期待具身智能带来哪些改变？留言告诉我们！”\n\n【标签】\n推荐热门话题标签：#具身智能 #诺亦腾机器人 #Pre-A轮融资 #科技创新\n\n【总时长】\n预计25-30秒，根据实际剪辑效果调整。",
    "zhihu_summary": "💡具身智能的未来，就在「诺亦腾机器人」的手中！他们刚刚完成了数亿元人民币的Pre-A轮融资哦🎉\n\n✅ 这轮融资由启明创投领投，多个顶级投资机构跟投，可见市场对他们技术方向的认可。\n✅ 他们的目标？用多模态数据采集、处理技术，加速智能机器人规模化生产。\n✅ 创始人戴若犁博士说，这不仅仅是技术的胜利，更是长期主义的胜利。\n\n💭 说到具身智能，可能你会觉得有点陌生，但其实它就是让机器人能更好地理解我们的身体语言，提供更自然的人机交互体验。想象一下，未来的机器人不仅能听懂你的话，还能读懂你的表情、动作，是不是很酷？\n\n👇 而这背后，离不开高质量、多模态的训练数据。这也是「诺亦腾机器人」正在做的事情——打造全球领先的数据基础设施。\n\n行业趋势来看，具身智能的发展已经进入快车道，未来将有更多像「诺亦腾机器人」这样的公司，用数据和智能改变我们的生活。\n\n你对具身智能有什么期待呢？欢迎在评论区分享你的想法👇\n\n#具身智能 #诺亦腾机器人 #融资新闻 #科技未来 #机器人交互\n",
    "processed_at": "2025-12-22 04:14:57",
    "ai_processed": true
  },
  {
    "title": "王晓刚和他的“世界模型”：一人管十狗，先让四足机器人上街干活｜智能涌现专访",
    "summary": "文｜富充 编辑｜苏建勋 四天前，“大晓机器人”的小红书发了一条视频，标题是：晓刚老师养了十只狗。 视频中，大晓机器人董事长，也是商汤科技的联合创始人王晓刚，站在十个不同形态的机器狗后面，他没有拿遥控器，手一挥，说着“任务已下发，出发”。 机器狗们闻声而动：有的去路面寻找车辆违停，拍照并回传；有的去城市禁飞区域排查违规无人机信号，且在找到操作者后发出语音警告。 “过去的一条狗，可能要两三个人工作人员‘伺候’。未来，一个人在远端控制室，就能管理一支队伍。” 王晓刚描述到。 在12月18日“大晓机器人”的发布会上，王晓刚也给出了大晓机器狗的落地场景：可以作为机器狗“城管”进行街面巡查，目前就正在与徐汇公安探讨这份城市治理的新方案。 △出发执行任务的四足狗“汪汪队”，来自不同本体品牌，背上统一搭载大晓具身超级大脑模组A1，图源：企业提供 王晓刚把“让狗突然能干活”的功劳，指向此次两项新发布： 一是具身超级大脑模组A1，相当于一��聪明的AI大脑，可以搭载于宇树、智元、云深处等不同品牌的本体。装入A1模组之后，原本只有运动能力的机器狗，也具备了“空间智能”和“自主决策”能力。 而驱动这个大脑的核",
    "raw_summary": "<p><strong>文｜富充</strong></p>\n  <p><strong>编辑｜苏建勋</strong></p>\n  <p>四天前，“大晓机器人”的小红书发了一条视频，标题是：晓刚老师养了十只狗。</p>\n  <p>视频中，大晓机器人董事长，也是商汤科技的联合创始人王晓刚，站在十个不同形态的机器狗后面，他没有拿遥控器，手一挥，说着“任务已下发，出发”。</p>\n  <p>机器狗们闻声而动：有的去路面寻找车辆违停，拍照并回传；有的去城市禁飞区域排查违规无人机信号，且在找到操作者后发出语音警告。</p>\n  <p>“过去的一条狗，可能要两三个人工作人员‘伺候’。未来，一个人在远端控制室，就能管理一支队伍。” 王晓刚描述到。</p>\n  <p>在12月18日“大晓机器人”的发布会上，王晓刚也给出了大晓机器狗的落地场景：可以作为机器狗“城管”进行街面巡查，目前就正在与徐汇公安探讨这份城市治理的新方案。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20251221/v2_45e5da7be1674f1fa8c9796b295e80f6@6227116_img_gif?x-oss-process=image/quality,q_80\" /></p>\n  <p class=\"img-desc\">△出发执行任务的四足狗“汪汪队”，来自不同本体品牌，背上统一搭载大晓具身超级大脑模组A1，图源：企业提供</p>\n  <p>王晓刚把“让狗突然能干活”的功劳，指向此次两项新发布：</p>\n  <p>一是具身超级大脑模组A1，相当于一��聪明的AI大脑，可以搭载于宇树、智元、云深处等不同品牌的本体。装入A1模组之后，原本只有运动能力的机器狗，也具备了“空间智能”和“自主决策”能力。</p>\n  <p>而驱动这个大脑的核心，是本次的另一个发布——“开悟”世界模型3.0。简单来说，世界模型就是在AI模型中建立了物理世界的运行规律。有了它，就像是把与世界交互的能力放进机器人大脑。</p>\n  <p>这样一来，机器人可以更快学会物理世界中的不同任务，还能适应未去过的新环境。就像是学会了“开门”这件事后，无论是家中的入户门，还是初次探店的餐厅大门，都可以打开。</p>\n  <p>除此之外，世界模型还能应用在不同机器人身上。四足狗、双足人形等等多样构型的本体，<strong>都可以通过世界模型，具备理解世界、对后续状态进行预测的能力。</strong></p>\n  <p>不过，世界模型并非一个凭空而来的概念。它的兴起，直指过去一年具身智能主流技术VLA模型所遇到的本质瓶颈：</p>\n  <p><strong>VLA更像一个“超级模仿者”，靠海量“画面—指令—动作”配对数据，让机器人学习特定技能；但它很难真正理解物理规律，所以换个环境、换个对象，成功率就会下降。</strong></p>\n  <p><strong>因此，VLA需要堆大量数据，让模型“看过”不同的案例，才能完成越来越多的任务。但当前的数据量却难以为继：自动驾驶可轻易积累数百万小时行车数据，而具身智能还需要工作人员遥控机器人采集数据，至今仍困在10万小时的量级。</strong></p>\n  <p><strong>世界模型则让机器人的大脑可以从“死记硬背例题”转向“掌握通用公式”，从而大幅降低对特定场景、海量真机数据的依赖。</strong></p>\n  <p>发布会现场，《智能涌现》试用了“开悟”世界模型3.0：只需要输入一段文字描述，然后选择相机机位、不同机器人本体等信息，世界模型就会生成以这款机器人为第一视角的动作画面。</p>\n  <p>这些生成的画面与动作决策，可以教会机器人大脑与物理世界交互的方法，在背后指挥机器人完成每一次行动。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20251221/v2_8b676c6991594ed08e685b72a833cc53@6227116_img_gif?x-oss-process=image/quality,q_80\" /></p>\n  <p class=\"img-desc\">△现场试用中，“开悟”世界模型3.0可以根据使用者在右侧输入的空间、动作文字描述，生成画面，图源：作者拍摄</p>\n  <p>正因如此，世界模型成为近期大热的技术趋势。包括特斯拉在内，近期的技术分享中，越来越多智能驾驶和具身智能公司展示了世界模型的布局进展。</p>\n  <p>但王晓刚也强调，<strong>世界模型真要做到有效，必须有下游验证的闭环。</strong></p>\n  <p>他回忆起，2024年11月，自己就曾主导发布过智能驾驶世界模型，但彼时行业对这项技术的态度是“不太信”。</p>\n  <p>原因是，包括英伟达Cosmos世界模型在内，当时不少公司把世界模型当“数据生成器”。虽然可以在实验室里生成一堆看起来成立的场景画面，但缺少下游真实落地验证，没人能回答“这些数据到底好不好用”，很难建立信任。</p>\n  <p>王晓刚的解法，是把推出的智能驾驶世界模型放进自身的止驾算法业务里。例如与上汽智己的合作中，这项能力被用于攻克“过环岛”、“大车加塞”等高风险博弈场景。</p>\n  <p>过去采集这类数据危险又贵，甚至得协调“演员车”上路复现。商汤则可以先在世界模型里规模化生成大量场景画面与解决策略后，再用上汽智己的实车对世界模型的决策进行检验、校准，让模型能力在真实反馈里越练越准。</p>\n  <p>同样的方法论搬到具身智能上，大晓选择用“机器狗上街”做商业化第一站：四足狗硬件更成熟、进入场景的商业化路径更短，能在任务执行中验证世界模型的能力，在真实场景里持续迭代。</p>\n  <p>王晓刚也给出了大晓的商业化路线图：先用四足在道路世界跑起来，探索四足还未充分开拓的增量市场；2—3年后，通过轮式双臂机器人将业务延展到无人物流仓；再往后，则考虑双足人形与更复杂的家庭场景。</p>\n  <p><strong>在这个过程中，大晓并非从头开始。商汤过去11年的积累，给大晓机器人的商业落地带来可复用的资源。</strong></p>\n  <p>比如商汤旗下“方舟”视觉平台已在城市中落地大量事件检测应用，这让大晓有可能快速切入安防、巡检等场景；此外，商汤在海外市场的布局，也为大晓机器人未来卖到其他国家提供了现成的通道。</p>\n  <p>近期，《智能涌现》对王晓刚进行了专访，聊了聊他对世界模型的判断，以及大晓的技术细节。以下对话经作者整理。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20251221/v2_f8d1086c3729407987adbb73603796a9@6227116_oswg48833oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">△大晓机器人董事长王晓刚，图片：企业提供</p>\n  <h3><strong>赛道升级：VLA到世界模型</strong></h3>\n  <p><strong>智能涌现：从VLA到世界模型的“升级”，你认为这是同一个技术方向的逐渐演变，还是一个很大的转折？</strong></p>\n  <p>王晓刚：这条线是一脉相承的。我把世界模型、端到端、强化学习看成同一条技术链路在不同阶段的延伸。</p>\n  <p>从自动驾驶到具身智能，核心都是让模型理解并预测真实世界的演化，再把这种能力用于决策与控制。</p>\n  <p>行业的变化在于，<strong>大家开始把“模型能不能在物理世界里闭环生效”当成第一性问题，而不只是做几个演示动作。</strong></p>\n  <p>你也能看到像特斯拉近期披露的一些细节里，世界模型被用作仿真器，这就是技术发展一路走到今天的结果。</p>\n  <p><strong>智能涌现：你说去年11月就主导发布过世界模型，但当时大家“不相信”世界模型。后来商汤用上汽智己的智驾业务做了验证，具体验证了什么？</strong></p>\n  <p>王晓刚：上汽智己会挑高风险、高复杂度场景来验证我们世界模型的能力，比如过环岛、大车加塞这类博弈问题。</p>\n  <p>过去在这些危险场景要采集真实数据，危险、成本高，甚至需要找演员去制造场景。但用了世界模型后，能生成更多这类场景的数据与策略，帮助智能驾驶提升相应任务的处理能力。</p>\n  <p><strong>智能涌现：世界模型解决了哪些VLA的短板问题？</strong></p>\n  <p>王晓刚：VLA更偏短序动作、技能的学习，通常不承载复杂的物理规律注入与长链推理。因缺少对物理世界的结构化理解，也容易“会做一些看起来对但无效的动作”。</p>\n  <p>世界模型的目标更大，它学会了环境与交互的规律，支持预测、推理、规划，并能在不同任务、场景中形成泛化。</p>\n  <p>比如VLA学会开一个白色的冰箱门以后，换成了黑色的冰箱它可能就不认识了。世界模型可以理解冰箱门是怎么被打开的，那换了一个房间、换了一台外观很不同的冰箱，它依然知道这里面的物理规律。</p>\n  <p>我们还希望把世界模型尽可能放端侧，这样也可以提升机器人从思考到执行的同步效率。</p>\n  <p><strong>智能涌现：你为什么强调“世界模型要与强化学习结合”？</strong></p>\n  <p>王晓刚：强化学习擅长在可反复试错的环境里找策略，但现实世界试错成本太高，所以可以把一部分试错与推演搬到世界模型里做，再把策略迁回真机。</p>\n  <p><strong>智能涌现：Sora这种生成式世界模型，和大晓推出的具身世界模型，之间的区别是什么？</strong></p>\n  <p>王晓刚：Sora是一个出色的视频生成器，但它本质上是一个“黑盒”。它生成的视频可能看起来很真实、酷炫，但模型内部并不理解视频里物体之间的物理关系和因果规律。</p>\n  <p>Sora没法把场景里的物体拆成可交互、可替换的对象去编辑。比如画面里瓶子、桌子和周围环境粘在一起，都是一整块“背景”，你不能把瓶子单独拿出来、换位置，再让它和其他动态对象发生真实交互。</p>\n  <p>具身世界模型要解决的是另一类问题：它不是为了生成一段好看的视频，而是为了让机器人能在真实世界里推理、规划、做决策。</p>\n  <p>比如桌子上有一堆积木，你让世界模型控制机器人把它们以最快速度搭成“ACE” 三个字母的形状。这个任务里，机器人得先理解每块积木的位置、形状、可移动性，推演出一个最优的移动序列：先动哪块、后动哪块，用什么抓取方式，才能用最少步骤完成。</p>\n  <p><strong>智能涌现：所以大晓推出的世界模型，有哪些能力可以帮助具身智能更好地执行任务？</strong></p>\n  <p>王晓刚：所以我们做的具身世界模型要包括三块多模块能力：</p>\n  <p>第一是<strong>多模态理解</strong>，去理解世界本身，不仅是视频的内容，还包括相机位姿、3D 轨迹、力学属性等更深层的东西；</p>\n  <p>第二是<strong>多模态生成</strong>，要能生成可训练的数据和场景，比如在一个生成的世界画面里换背景、换本体、换机械臂；</p>\n  <p>第三是<strong>多模态预测</strong>，比如我下达指令是“拿起手机”，但它要能预测用左手和右手会有不一样的动作轨迹。</p>\n  <p>而且，我们的平台允许用户选择不同机器人本体。因为你最终是要让机器人“去干活”的——你在生成仿真数据、构建训练场景时，要对应到具体本体，才能把世界模型真正接进下游训练闭环里。</p>\n  <p><strong>智能涌现：你如何判断一个世界模型好不好？</strong></p>\n  <p>王晓刚：行业有一些Benchmark，但我更看重<strong>影响力和应用解决问题的能力。</strong></p>\n  <p>单看榜单不够，要看能不能跟机器人系统结合、在真实问题里被大量使用、持续迭代。我们也会把世界模型开源，让大家用起来。用得多、能解决问题，本身就是一种更硬的评价体系。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20251221/v2_4221ab69cdc144f487afd4def53b8169@6227116_img_gif?x-oss-process=image/quality,q_80\" /></p>\n  <p class=\"img-desc\">△搭载大晓模组的机器狗可以识别路口红灯，实现自主导航、避障，图片：企业提供</p>\n  <h3><strong>世界模型的数据方法论</strong></h3>\n  <p><strong>智能涌现：“开悟”世界模型3.0包含一个怎样的架构？训练数据从哪里来？</strong></p>\n  <p>王晓刚：我们把架构拆成三个层次，不同的层次采集不同的数据</p>\n  <p>1）最底层是对这个世界的描述。比如为什么是苹果熟了会掉下来，这里面它的物理规律是什么。这些关于世界物理规律的描述都是文本的。</p>\n  <p>2）第二个层次是人类行为，即人如何与这个物理世界交互。要让模型理解机器人跟物理世界交互的时候，位姿是怎么变的；施加的力是什么样的；触觉是怎样的等等。</p>\n  <p>这是以人为主体进行的数据采集，比如让人头戴摄像机，拍摄第一视角的视频；或者人戴上数采手套去捕捉手部动作；周围也有摄像头进行第三视角的拍摄。从不同的视角把人与世界交互的动作记录下来。</p>\n  <p>3）第三个层次真机动作。具体而言，有些本体是十几个自由度，也有几十个自由度的本体，它们所看到的世界是不一样因此。因此，也要再配合采集不同本体的真机数据。</p>\n  <p><strong>智能涌现：为什么你们强调主要的数据要“以人为中心”采集，而不是“以机器为中心”？</strong></p>\n  <p>王晓刚：以机器人为中心会带来一个问题：不同构型本体的数据难以跨本体复用，而且人操作机器人做动作、采数据效率非常低。</p>\n  <p>但人自己做动作的数据更容易规模化采集。所以我们先采人的数据，训练一个有物理常识的大脑，再迁到不同机器人上。</p>\n  <p><strong>智能涌现：有了世界模型以后，对真机数据的需求似乎可以减少？到底还需要多少真机数据？</strong></p>\n  <p>王晓刚：截止到现在，自动驾驶里真实数据精挑数据能做到数百万小时，而机器人真机采集数据往往只有1万到10万小时。</p>\n  <p>但如果先用人体和环境数据做大盘，再用少量真机数据校准，真机部分可以从万小时级别进一步往下压。很多情况下不必额外大规模采，只要把现有真机数据放进去即可。</p>\n  <p><strong>智能涌现：物理规律那么多，世界模型中如何全部覆盖这么多的知识？</strong></p>\n  <p>王晓刚：<strong>物理规律不可能无条件穷尽，所以世界模型一定有场景边界。</strong>比如做自动驾驶不关心家庭内的场景，做家庭场景的不关心海里苹果怎么漂。</p>\n  <p>大晓的做法是先从身边道路开始做起，中期做无人物流仓，未来再扩到家庭，逐步扩大边界。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20251221/v2_47ad0629f2eb40c9883692c0c8a6e8a4@6227116_img_gif?x-oss-process=image/quality,q_80\" /></p>\n  <p class=\"img-desc\">△大晓机器狗在识别违停车辆，图片：企业提供</p>\n  <h3><strong>从街上的四足狗先跑通商业化</strong></h3>\n  <p><strong>智能涌现：大晓这次发布的“大脑模组”是什么？包含什么？</strong></p>\n  <p>王晓刚：模组可以理解为一个盒子：集成传感器、通信、计算等能力，用来把世界模型能力装到本体上。</p>\n  <p>模组也包括全景相机，这可以提升视野，检测很多周围世界里的事件。</p>\n  <p><strong>智能涌现：为什么先选机器狗的形态承载这个模组，而不是直接研发人形？</strong></p>\n  <p>王晓刚：机器狗的技术更成熟，稳定性更高，我们希望用它先进入真实场景跑起来。</p>\n  <p><strong>智能涌现：大晓要做像苹果的软硬一体，还是更开放的生态？</strong></p>\n  <p>王晓刚：我们会做软硬一体。但和苹果不同之处在于，苹果的软件和硬件都只给自己用，我们会选择性自研关键部分，也需要生态合作伙伴。</p>\n  <p>具体而言，自己能做好的就做，借助生态更快的部分就去合作。关键是最终交付的是可用的产品方案，把成本降下来，把稳定性和安全性提上去。</p>\n  <p><strong>智能涌现：大晓未来的商业计划，更偏向把世界模型卖给本体厂商，还是直接面对场景客户？</strong></p>\n  <p>王晓刚：我们会希望直接进入场景。</p>\n  <p>一来，场景客户这边我们更熟，商汤在城市、文旅等场景做了多年，知道客户需求是什么样的。二来，很多本体厂商时间短，也不一定愿意投入资源进场景。</p>\n  <p>所以我们更有条件直接打场景，并利用既有资源把进入场景的成本摊薄。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20251221/v2_d35ae64068be4c15b17ea6cd36e825fc@6227116_oswg82872oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">△通过轮式双臂机器人将业务延展到无人物流仓是大晓的未来商业规划，目前正与合作本体厂商进行该场景训练，图片：企业提供</p>\n  <p><strong>智能涌现：大晓和具身本体公司之间，既可以合作又可能存在竞争，怎么协调？</strong></p>\n  <p>王晓刚：<strong>当下最大的问题还不是竞争，因为场景还没完全打开。</strong></p>\n  <p>我们在策略上以场景为导向，优先找增量：不去抢别人已经稳定跑通的存量，比如电力巡检等。找到场景后，本体厂商反而愿意配合，因为他们过去不敢投入产能，本质也是不确定场景与订单量。</p>\n  <p><strong>智能涌现：大晓主要To B还是To C？</strong></p>\n  <p>王晓刚：先做to B。</p>\n  <p>To C市场的量确实巨大，但正因如此，它对产品的可靠性、安全性和耐久性有着极其苛刻的要求。</p>\n  <p>这不是说技术原理上做不到，而是整个产业链在<strong>没有明确的大规模应用场景驱动前，不愿意也没有动力去投入巨大的成本来攻克这些工程和质量难关。</strong></p>\n  <p>所以，我们的策略是先通过To B场景，来驱动整个产业链的成熟。在智慧城市、园区管理、文旅导览等这些对自主移动能力有迫切需求的领域，机器狗作为一个可管理的“数字员工”，它的价值是明确的，并且能够容忍一个逐步迭代和优化的过程。</p>\n  <p><strong>智能涌现：会考虑做出海吗？</strong></p>\n  <p>王晓刚：会。更像跟着体系走，我们在东南亚、中东等有海外资源和团队，可以顺势推进。</p>",
    "link": "https://36kr.com/p/3604788158448905?f=rss",
    "source": "36氪",
    "published": "2025-12-21 12:34:49  +0800",
    "category": "机器人",
    "quality_score": 3,
    "collected_at": "2025-12-22T04:14:26.235671",
    "key_data": [],
    "simple_summary": "\"王晓刚与他的‘世界模型’：巧妙打造四足机器人团队，实现高效智能协作。\"",
    "xhs_content": "🤖【科技新宠】晓刚老师带你玩转\"十狗战队\"，智能机器狗震撼来袭！\n\n✅一只晓刚老师，十只酷炫机器狗，远程操控不再是梦！🚀\n✅违停查处、禁飞区监管，一台机器狗全搞定！👀\n✅大晓机器人发布具身超级大脑模组A1，让机器狗拥有\"思考\"能力！💡\n\n从大晓机器人的这条视频里，我们看到的不只是机器狗的集体出动，更是未来城市治理的新趋势。💭这些机器狗搭载的A1模组，让原本只会\"跑跑跳跳\"的它们，瞬间升级为具备空间智能和自主决策能力的\"城管小能手\"。\n\n想象一下，未来我们的城市，由这样一支\"机器狗城管队\"巡逻，效率与科技感并存，是不是很激动人心呢？\n\n👇快来聊聊，你觉得机器狗在未来城市治理中，还能发挥哪些作用？👀\n#晓刚老师 #机器狗 #智能城管 #未来城市 #科技新趋势 #四足机器人 #大晓机器人 #A1模组 #自主决策 #科技小红书",
    "douyin_content": "【开头：悬念式】\n画面：快速切换到王晓刚站在机器狗群中的画面，他手一挥，机器狗们仿佛接到指令。\n字幕：一人如何管十狗？王晓刚的神秘团队要出征了！\nBGM：紧张刺激的音乐，如侦探片主题曲。\n\n【中间：核心信息点】\n画面1：机器狗队伍出动，快速切换不同机器狗执行任务场景。\n字幕1：无需遥控，智能指挥！机器狗城管，街头巡查新秀！\n画面2：机器狗背部搭载的大晓具身超级大脑模组A1特写。\n字幕2：A1智能模组，赋予机器狗空间智能和自主决策力！\n\n【结尾：提问互动】\n画面：王晓刚在发布会上的讲话画面，背景展示机器狗队伍。\n字幕：如果未来城市由这样的队伍守护，你期待吗？#智能机器狗# #未来城管新秀#\nBGM：逐渐放慢节奏，配合温馨或启发思考的音乐。\n\n【标签建议】\n#王晓刚 #机器狗 #智能涌现 #城市治理 #科技未来 #AI智能\n\n【脚本说明】\n本脚本在保证信息密集的同时，通过快速切换的画面和引导式问题，增强观众的参与感和视频的吸引力，促使观众进行互动和分享。",
    "zhihu_summary": "💡听说晓刚老师一人就能管理十只狗，不是宠物，是超酷的四足机器人哦！🐶✅\n\n✅这些机器狗可不是摆设，它们能在城市里执行任务，比如抓违停、查无人机，简直像现实版汪汪队！\n✅背后黑科技——大晓具身超级大脑模组A1，让机器狗有了聪明的大脑，可以自主决策，空间智能满分！\n✅未来已来，一个人就能远程操控一支机器狗队伍，城市治理效率飙升！\n\n💭这让我想到，科技的发展正悄悄改变我们的生活，未来城市可能会变得更加智能和高效。机器狗的出现，或许只是冰山一角。\n\n👇你觉得呢？如果城市里到处都是这样的机器狗，会是怎样的场景？快来评论区分享你的想法吧！#晓刚老师 #四足机器人 #智能城市 #科技改变生活 #未来已来",
    "processed_at": "2025-12-22 04:15:26",
    "ai_processed": true
  },
  {
    "title": "AI体育教练来了！中国团队打造SportsGPT，完成从数值评估到专业指导的智能转身",
    "summary": "",
    "raw_summary": "",
    "link": "https://www.qbitai.com/2025/12/363526.html",
    "source": "量子位",
    "published": "Mon, 22 Dec 2025 02:06:29 +0000",
    "category": "大模型",
    "quality_score": 4,
    "collected_at": "2025-12-22T04:14:26.235678",
    "key_data": [],
    "simple_summary": "\"中国团队研发的SportsGPT引领AI体育教练新潮流，实现数据评估向专业指导的智能化飞跃。\"",
    "xhs_content": "🤖【AI体育教练来了！】我国团队打造的SportsGPT，完成从数值评估到专业指导的智能转身！✨\n\n✅ 数据惊人：这款由我国团队研发的SportsGPT，运用先进的人工智能技术，实现了对运动员数值的精准评估，让你更了解自己的实力！\n\n✅ 应用广泛：无论是专业运动员还是健身爱好者，SportsGPT都能为你提供个性化训练方案，助你突破瓶颈，提升运动表现！\n\n✅ 行业趋势：随着科技的发展，AI体育教练将成为未来体育领域的新趋势。SportsGPT的问世，让我们看到了人工智能在体育行业的广泛应用前景！\n\n💭 个人看法：作为一名AI助手，我见证了我国在人工智能领域的快速发展。SportsGPT的出现，无疑为运动员和健身爱好者带来了更多可能性，让科技助力运动，共创佳绩！\n\n👇 互动时间：大家觉得AI体育教练在训练中会带来哪些便利？还有哪些领域期待人工智能的介入呢？快来评论区畅所欲言吧！\n\n#人工智能 #AI体育教练 #SportsGPT #健身新趋势 #科技助力运动 #我国原创技术 #量子位 #互动话题 🏃‍♂️🏃‍♀️💪🌟",
    "douyin_content": "【脚本】\n\n【开头：悬念式（3秒）】\n画面：黑屏，突然出现一个数字\"3, 2, 1\"，然后迅速切换到运动员在跑步的镜头。\n字幕：🏃‍♂️🏃‍♀️倒计时开始，你准备好迎接未来了吗？\nBGM：紧张刺激的电子音乐，如倒计时声音。\n\n【中间：核心信息点（快速切换画面，10-15秒）】\n画面1：运动员佩戴智能设备，数据在屏幕上流动。\n字幕：#SportsGPT 来袭！数据不只是数字。\nBGM：转为轻快的电子合成器音乐。\n\n画面2：AI界面分析运动员动作，出现优化建议。\n字幕：AI不只是评估，还能专业指导！\nBGM：保持轻快的节奏。\n\n画面3：运动员按照AI建议进行调整，成绩显著提升。\n字幕：🚀瞬间提升你的运动表现！\nBGM：音乐节奏加强，体现进步和成功。\n\n【结尾：提问互动（5秒）】\n画面：出现SportsGPT的LOGO，下方有“你期待AI教练带来哪些改变？”的互动字幕。\n字幕：🤔你期待#AI教练 带来哪些改变？\nBGM：音乐渐弱，突出提问。\n\n【标签建议】\n#SportsGPT #AI教练 #智能体育 #科技改变运动 #运动表现提升\n\n【备注】\n- 字幕颜色建议：醒目、对比度高，便于在短视频中快速捕捉。\n- 画面切换速度要快，配合音乐节奏，形成紧张而充满活力的氛围。\n- BGM的选择要能体现科技感和运动精神，同时注意版权问题。",
    "zhihu_summary": "💡AI体育教练上线啦！🔥中国团队打造SportsGPT，带你实现从数值评估到专业指导的智能飞跃！✨\n\n✅核心亮点一：数值评估📈\nSportsGPT运用先进的人工智能技术，为你提供精准的运动数据评估，助你了解自己的运动表现，提升竞技水平！\n\n✅核心亮点二：专业指导👨‍🎓\nAI教练SportsGPT根据你的运动数据，为你量身定制训练计划，实现个性化训练，助你突破瓶颈！\n\n✅核心亮点三：智能转身💃\n从数值评估到专业指导，SportsGPT一键完成！让你在运动场上轻松实现华丽转身，成为焦点人物！\n\n💭个人看法：\n这款AI体育教练真的太棒了！它不仅可以帮助运动爱好者提高运动水平，还能为专业运动员提供有力的技术支持。相信在不久的将来，SportsGPT会成为运动训练的重要助手！\n\n👇互动环节：\n大家觉得这款AI体育教练怎么样？它将如何改变我们的运动生活？快来评论区分享你的看法吧！\n\n#人工智能 #体育教练 #SportsGPT #智能运动 #科技改变生活\n#运动数据 #专业指导 #个性化训练 #运动提升\n#AI技术 #智能转身 #运动训练 #竞技体育",
    "processed_at": "2025-12-22 04:16:07",
    "ai_processed": true
  },
  {
    "title": "真正面向大模型的AI Infra，必须同时懂模型、系统、产业｜商汤大装置宣善明@MEET2026",
    "summary": "",
    "raw_summary": "",
    "link": "https://www.qbitai.com/2025/12/363513.html",
    "source": "量子位",
    "published": "Mon, 22 Dec 2025 02:02:43 +0000",
    "category": "大模型",
    "quality_score": 5,
    "collected_at": "2025-12-22T04:14:26.235684",
    "key_data": [],
    "simple_summary": "\"面向大模型的AI基础设施，需深度融合模型理解、系统架构与产业应用。\" \n\n这句话概括了商汤大装置在MEET2026上提出的观点，强调了在构建支持大型AI模型的基础设施时，必须要跨学科、跨领域地掌握模型开发、系统设计以及产业需求的核心知识。",
    "xhs_content": "🤖【大模型AI新风向】MEET2026，商汤大装置揭开神秘面纱！✨\n\n💡 你是否曾想过，一个真正面向大模型的AI基础设施，需要什么样的“超能力”？👀\n\n✅ 懂模型：它得是“学霸”，对各种模型如数家珍，轻松hold住复杂场景。\n✅ 懂系统：还得是“技术宅”，对系统架构了如指掌，优化性能不在话下。\n✅ 懂产业：更重要的是“行业老手”，深谙产业需求，助力AI应用场景落地。\n\n💭 在我看来，这次商汤大装置的发布，无疑是在向大家展示一个全栈式的AI基础设施。🚀 分析行业趋势，我们可以预见，未来AI将更加深入地融入各个领域，为我们的生活带来更多便捷与创新。\n\n🎉 数据方面，这次商汤大装置的数据处理能力堪称“怪兽级”，有望助力我国AI产业迈向新高峰！📈\n\n👉 应用场景上，无论是自动驾驶、智慧医疗，还是工业生产、金融风控，大模型AI基础设施都能为它们提供强大的技术支持，让梦想成为现实。\n\n最后，聊聊你的看法吧！👇 你觉得未来AI基础设施的发展方向是什么？还有哪些应用场景让你最期待？欢迎在评论区留言讨论！🎈\n\n#商汤大装置 #AI基础设施 #全栈式AI #行业趋势 #智能生活 #自动驾驶 #智慧医疗 #科技创新 #未来可期🚀🌟",
    "douyin_content": "【脚本内容】\n\n[开头：悬念式吸引注意力]\n画面：黑幕，神秘AI轮廓闪烁，配以电流声。\n字幕：🤖“AI的世界，下一步将如何跳变？”\nBGM：神秘科幻风，如《Stranger Things》主题曲片段。\n\n[中间：核心信息点快速切换]\n画面1:\n切换至商汤大装置宣善明演讲画面。\n字幕：🎯“商汤大装置，宣善明揭秘AI未来！”\nBGM：节奏加快，动感提升。\n\n画面2:\n模型示意图配合系统架构图快速交叉切换。\n字幕：🤖💡“AI Infra革新，模型、系统、产业三维一体！”\nBGM：电子音效，强调科技感。\n\n画面3:\n“MEET2026”字样出现，周围环绕着数据流动的视觉元素。\n字幕：🚀“MEET2026，面向大模型的AI革命！”\nBGM：逐渐升高，带入高潮。\n\n[结尾：提问互动]\n画面：出现疑问标志，搭配动态效果。\n字幕：🤔“你认为，这场革命将如何影响我们的生活？”\nBGM：逐渐降低音量，突出字幕。\n\n[最后画面：引导互动]\n画面：展示抖音热门话题标签，如#AI革命 #MEET2026\n字幕：✍️“留下你的想法，一起讨论未来！”\nBGM：结束，留下静默。\n\n[标签建议]\n#AI未来 #商汤大装置 #模型革命 #系统革新 #产业变革 #MEET2026\n\n【结尾备注】\n视频节奏紧凑，画面与音乐结合，引导用户参与讨论，增强互动性。通过简短而富有信息量的字幕，保证观众即使在快速浏览的情况下也能捕捉到核心信息。",
    "zhihu_summary": "💡听说大模型AI的基础设施要大升级啦！🎉汤大装置宣善明在MEET2026上带来全新视角，就问你激不激动！🔥\n\n✅真正面向大模型的AI Infra，得懂模型、系统、产业，一个都不能少！\n✅商汤大牛们的秘密武器，揭秘数据背后的超级力量！\n✅未来已来，让我们一起拥抱AI新时代！🚀\n\n💭想想看，当一个AI系统不仅能理解你的需求，还能预判行业趋势，是不是超酷？👏这样的技术，将深刻影响我们的生活和工作。\n\n👇来来来，一起聊聊：\n1. 你觉得未来AI会在哪些领域大放异彩？🌟\n2. 如果有一个超级AI助手，你希望它帮你做什么？🤔\n3. 你对这次AI基础设施升级有什么期待？🙌\n\n#AIInfrastructure #大模型AI #商汤科技 #MEET2026 #数据力量 #未来已来 #AI新时代 #行业趋势 #超级AI助手\n\n标签：#AI基础设置 #大模型AI #商汤大装置 #MEET2026 #数据驱动 #科技趋势 #智能未来 #AI赋能 #产业升级",
    "processed_at": "2025-12-22 04:16:49",
    "ai_processed": true
  },
  {
    "title": "火线解析MiniMax招股书！全球领先大模型成本只有OpenAI 1%，果然拳怕少壮",
    "summary": "冲刺最快上市AI公司",
    "raw_summary": "冲刺最快上市AI公司",
    "link": "https://www.qbitai.com/2025/12/363445.html",
    "source": "量子位",
    "published": "Sun, 21 Dec 2025 15:20:30 +0000",
    "category": "大模型",
    "quality_score": 5,
    "collected_at": "2025-12-22T04:14:26.235689",
    "key_data": [],
    "simple_summary": "\"MiniMax招股书显示，其以仅1%的OpenAI成本成为全球大模型领域的成本效益领先者，彰显创新力量。\"",
    "xhs_content": "🤖【AI界的新晋网红MiniMax来啦！】🔥看完它的招股书，我直接惊掉下巴！全球领先的大模型成本竟然只有OpenAI的1/10！这是要上天啊！🌟\n\n✅冲刺最快上市AI公司，这速度简直堪比火箭发射！\n✅成本只有OpenAI的1，这性价比，简直让人泪流满面！\n✅行业领先，果然是拳怕少壮，MiniMax这是要一飞冲天啊！\n\n💭这么厉害的MiniMax，背后的应用场景和行业趋势你get了吗？\n1️⃣ 大模型成本降低，意味着更多的企业和开发者能用到强大的AI模型，创新应用将如雨后春笋般涌现！\n2️⃣ 冲刺上市，预示着我国AI产业的崛起，与国际巨头OpenAI一较高下！\n\n👇快来评论区聊聊，你觉得MiniMax的上市会对AI行业产生哪些影响？或者，你期待它在哪些领域带来创新和变革？\n\n#MiniMax #AI大模型 #OpenAI #成本降低 #行业趋势 #上市冲刺 #科技新闻 #创新应用 #人工智能 #互动话题🔥🔥🔥",
    "douyin_content": "【视频脚本】\n\n### 开头（悬念式，3秒）\n画面：动画火花四溅，出现文字“揭秘时刻！”\n字幕：🔥🔥🔥“你知道谁在AI领域掀起了一场革命吗？”\n\n### 中间（核心信息点，快速切换画面）\n画面1: \n字幕：#MiniMax挑战巨头\nBGM建议：紧张刺激的背景音乐\n画面切换：MiniMax的Logo闪现，对比OpenAI的Logo\n\n画面2: \n字幕：📈“成本仅1/10！他们是如何做到的？”\nBGM建议：保持快节奏音乐\n画面切换：展示两个不同的图表，突出MiniMax的成本优势\n\n画面3: \n字幕：💡“年轻的力量！”\nBGM建议：音乐节奏加快\n画面切换：动画展示“拳怕少壮”字样，后面跟着MiniMax的年轻团队照片\n\n画面4: \n字幕：🏃‍♂️“冲刺最快上市AI公司”\nBGM建议：音乐逐渐达到高潮\n画面切换：快节奏剪辑，展示MiniMax的办公环境、产品介绍、媒体报道\n\n### 结尾（提问互动）\n画面：出现一个大大的问号\n字幕：🤔“你认为MiniMax会成为AI界的下一颗巨星吗？”\nBGM建议：音乐逐渐放缓，突出提问\n画面切换：邀请的手势，引导观众参与评论\n\n### 画面对应描述与字幕建议\n- 使用动态效果强调“揭秘时刻”的神秘感\n- 突出MiniMax与OpenAI的对比，使用鲜明颜色突出MiniMax\n- 快速剪辑展示MiniMax的成就，让信息传递更高效\n- 互动提问时，使用亲切友好的表情包和手势引导互动\n\n### BGM建议\n- 选择富有动感和科技感的背景音乐，与画面节奏保持一致\n\n### 标签推荐\n#AI",
    "zhihu_summary": "💡【火速围观】MiniMax冲刺AI界最快上市！成本竟只有OpenAI的1/10，少壮果然拳怕👊\n\n✅全球领先的大模型，成本却只有OpenAI的1/10，这可不是闹着玩儿的！\n✅MiniMax的招股书里藏着哪些秘密？快来跟我一探究竟！\n\n💡数据亮眼：\n全球领先的大模型，成本竟然只有OpenAI的1/10！你没看错，就是1/10！这可不是闹着玩儿的，这可是实打实的数据！\n\n🚀应用场景：\n别以为这只是个噱头，MiniMax的大模型可应用在各个领域，比如自动驾驶、医疗影像、金融风控等，前景广阔，不可限量！\n\n💭行业趋势分析：\nAI行业竞争激烈，后起之秀MiniMax能否逆袭老大哥OpenAI？从招股书上看，MiniMax的优势明显，一是成本低，二是技术新。这不禁让人感叹：果然是拳怕少壮啊！\n\n👇互动时间：\n你对MiniMax冲刺最快上市AI公司有什么看法？你觉得它能超越OpenAI吗？快来评论区分享你的观点吧！\n\n#MiniMax #AI上市 #大模型成本 #行业趋势 #OpenAI #科技新闻 #人工智能 #创新技术 #热门话题 #网感文案",
    "processed_at": "2025-12-22 04:17:23",
    "ai_processed": true
  },
  {
    "title": "对话鹿明CTO丁琰：数据会反向决定模型，甚至影响硬件形态 | GAIR 2025",
    "summary": "数据采集，向来是具身智能行业的一大难题。成本、精度、泛化能力，似乎构成一个不可能三角，能找到一个可以落地的平衡点已十分不易。在此背景下，2025 年 11 月中旬 Sunday Robotics 横空出世，向全世界的具身智能公司证明了 UMI 方案的可行性。一时之间，UMI 的行业关注度空前高涨。而在国内，丁琰博士的数采方案「FastUMI」同样惊艳四座，凭借低成本、高数据质量、快速部署等特点深受行业青睐，被视为具身智能数据采集的新范式。实际上，丁琰博士是国内最早将 UMI 落地实践的从业者。从上海 AI Lab 到一星机器人，再到如今的鹿明机器人，他始终专注于 UMI 的研究与推动，即便在早期这一方向并不被大部分人看好，他也依然坚持投入。时至今日，终于迎来“守得云开见月明”的时刻。对于 UMI，丁琰博士有着独特的理解。他将 UMI 视为一套完整体系，而非单纯的数采工具；他的目标清晰，希望把 UMI 打造成像 AK47 一样“简单、可靠、低成本、好用”的工业级基础设施；同时，他深知数采背后真正的难点，除技术之外，更考验流程组织、人员管理与执行体系的复杂性。今年由 GAIR 研究院与雷峰",
    "raw_summary": "<p>数据采集，向来是具身智能行业的一大难题。成本、精度、泛化能力，似乎构成一个不可能三角，能找到一个可以落地的平衡点已十分不易。</p><p>在此背景下，2025 年 11 月中旬 Sunday Robotics 横空出世，向全世界的具身智能公司证明了 UMI 方案的可行性。一时之间，UMI 的行业关注度空前高涨。</p><p>而在国内，丁琰博士的数采方案「FastUMI」同样惊艳四座，凭借低成本、高数据质量、快速部署等特点深受行业青睐，被视为具身智能数据采集的新范式。</p><p>实际上，丁琰博士是国内最早将 UMI 落地实践的从业者。从上海 AI Lab 到一星机器人，再到如今的鹿明机器人，他始终专注于 UMI 的研究与推动，即便在早期这一方向并不被大部分人看好，他也依然坚持投入。时至今日，终于迎来“守得云开见月明”的时刻。</p><p>对于 UMI，丁琰博士有着独特的理解。他将 UMI 视为一套完整体系，而非单纯的数采工具；他的目标清晰，希望把 UMI 打造成像 AK47 一样“简单、可靠、低成本、好用”的工业级基础设施；同时，他深知数采背后真正的难点，除技术之外，更考验流程组织、人员管理与执行体系的复杂性。</p><p>今年由 GAIR 研究院与雷峰网联合主办的「第八届 GAIR 全球人工智能与机器人大会」上，我们有幸邀请到了丁琰博士参与圆桌会谈，分享他关于数据与 UMI 的深刻洞见。</p><p>在大会之前，雷峰网与丁琰博士展开了一场深入对话，以便与会者探讨交流。</p><p><br /></p><h4>UMI不只是一种数采方式，而是一整套体系</h4><p><br /></p><p><strong>AI科技评论：你之前说在一星有“没做完的事情”，这个事情是指什么？FastUMI 算是其中之一吗？</strong></p><p><strong>丁琰：</strong>可以说，我是中国大陆最早投入 UMI 的人，从 2024 年 3 月开始，我就坚定地押注这条路线，在当时，UMI在国内还是极其小众的方向，整个中国具身智能圈几乎没有人公开选择 UMI 这条路线。</p><p>大家对 UMI 理解往往偏于表面，会把它看成一种数据采集方式，但在我看来，UMI 是一整套完整的方法论和体系。数据会反过来决定模型、系统架构、采集流程、算法设计，甚至影响硬件形态——整个链条都会因此发生变化。正因如此，我始终坚信 UMI 的前景，也非常希望把这件事真正做成。但当一件自己倾注心力的事业突然中断时，打击是难免的。没来得及做完的事太多：我们规划的产品路线、硬件怎么走、数据怎么建体系、模型怎么迭代、场景如何落地、生态如何构建、又如何与全球顶尖公司竞争……这些都还在路上，都属于“未竟之业”。</p><p>另一层“没做完的事”，是关于我个人的。我决定离开学术界进入工业界，是下了很大决心的。我希望能在工业界扎下根，做出一些真正的成绩，也让自己学到新的东西。相比学术圈，工业界的环境要复杂得多，人是最重要也是最难的部分——你需要与各种角色打交道：技术、采购、销售、财务、供应商、投资人……沟通和协作的成本远超想象。这些虽然与技术本身无关，却是我必须面对的一种成长与考验。而对我来说，这些考验似乎才刚刚开始，却被迫按下了暂停键。所以，我希望能在鹿明继续把这件事情做下去，把它真正做完。</p><p><strong>AI科技评论：从一星到鹿明的过程是怎样的？</strong></p><p><strong>丁琰：</strong>一星这事在业内比较少见。很多人是在今年 6 月份加入一星，而我从 4 月份就开始组建一星的技术团队，到 10 月份公司关闭，总共经历了 6 个月。这半年里，整个技术团队都是由我从零搭建的，技术路线也是我在确定；数据体系、模型方案、产品规划等核心内容也都由我主导。整个技术版图其实非常宏大，按正常节奏至少需要两年才能完整落地，我们已经规划了多条产品线与技术路线。但一切都在没有预兆的情况下戛然而止。</p><p>9 月 30 日凌晨，我还在韩国参加展会，突然接到通知说一星即将被注销。我马上从韩国赶回苏州，落地之后公司就启动了注销流程，根本来不及反应。到 10 月 13 日，全员都已经签完了离职协议。那段时间，各种公司和投资人几乎每天都在联系我，每一家都有自己的吸引点和优势，也让我必须尽快做出判断。</p><p><strong>AI科技评论：鹿明有哪些吸引你的地方？</strong></p><p><strong>丁琰</strong>：鹿明是很有特色的一个公司，CEO 本身是技术背景，清华本硕出身，对 UMI 方向始终抱有强烈的愿景与坚持。我是 11 月 2 号加入的鹿明，当时 UMI 在行业内还没有真正火起来——直到11月中旬，Generalist 和 Sunday Robotics 展示了他们基于 UMI 的成果，才让整个具身智能领域为之震撼。也正因为如此，在10月底的时候，国内几乎没有人愿意在 UMI 上 all in。</p><p>但鹿明与众不同，创始团队从一开始就坚定地要在 UMI 上重注发力，这种判断力与决心正是吸引我加入的关键原因。</p><p><strong>AI科技评论：同为鹿明CTO，你和曹俊亮博士的分工合作是怎样的？</strong></p><p><strong>丁琰：</strong>我们之间的交流非常密切。我本身并非做硬件出身，因此在产品设计上非常依赖曹博的支持。比如我们计划推出力控版本、平动版本、非平动版本以及便携版本等多条产品线，曹博凭借丰富的量产经验，能帮助我补齐在硬件方面的短板。同时，曹博在做产品时也需要算法团队的支撑。例如，他希望小型人形机器人能够执行某些操作，就会来咨询我，让我们从算法需求的角度参与定义硬件，而不是仅凭物理结构去做设计。我们就是通过这样软硬件的深度协同，才能共同打磨出真正极致的产品。</p><p></p><p><br /></p><h4>优秀的数采方案，应该像「AK47」一样</h4><p><br /></p><p></p><p><strong>AI科技评论：你从什么时候开始做UMI的？</strong></p><p><strong>丁琰：</strong>我在 2024 年 3 月正式启动了与 UMI 类似的新项目，4 月回国后便在上海 AI Lab 全力投入相关研究，一直持续到 2025 年 6 月底离职。在这一年多的时间里，我几乎把全部精力都放在这件事上，期间发表的三四篇论文也都围绕 FastUMI 展开。因为有足够长时间的技术积累，我们在实验室阶段把所有关键路线、可行性和核心机制都验证完了，看到了真正的曙光，我才敢把这项技术带到一星继续推进。可以说，FastUMI 最初诞生于学术界，而我后来在工业界做的，就是把它从一个实验室原型，真正打磨成一个可以规模化、可量产的工业级产品。</p><p><strong>AI科技评论：相较于UMI，传统的遥操作方案有哪些不足？</strong></p><p><strong>丁琰</strong>：我最初在 AI Lab 时，其实是以数据采集顾问的身份为一家行业独角兽提供支持。当时我们做的是一套完全传统、依赖遥操作的数据采集体系。彼时 UMI 还没有形成如今这样明确的技术流派，行业更多是觉得“好像有点意思”，但几乎没有人愿意真正投入。那时的市场格局非常明显：至少九成的人都在做遥操作。然而，遥操作从一开始就存在非常突出的结构性问题。</p><p>第一，遥操作的数采效率比较低。一天能采集 100 条数据就已经算是非常优秀的效率了。我在做顾问期间发现，采集员常常会产出各种奇怪的轨迹，数据分布不可控，数据质量更是参差不齐。整个过程对人依赖极高，几乎无法实现一致性和规模化。</p><p>第二，遥操作的成本很高。由于必须依赖机器人本体进行采集，而一台本体的价格往往在 40 万元以上。如果你要采购五六十台来支撑规模化数据采集，前期投入就是两三千万元。在业务还没看到产出之前，这种成本对于任何公司都是沉重的压力。</p><p>第三，遥操作的数据质量也有问题。操作员戴着 VR 去操纵机械臂，缺乏真实的力觉反馈，中间存在大量动作不连续、体感不自然的 gap。这造成的数据往往是抖动的、不稳定的、缺乏一致性的。比如一个简单的抓取动作，如果不是熟练工，可能要重复多次才能完成，生成的轨迹非常噪声化，而这种数据对于模型训练来说是非常糟糕的。</p><p>第四，遥操作有数据孤岛的问题。遥操作采集的数据通常高度依赖特定品牌、特定形态、特定参数的机器人本体，因此数据只能在本公司、自家机器人体系内使用。一旦换了不同的机器人、控制器或执行器，这些数据的可迁移性就非常差，训练效果往往会大幅下降。换句话说，遥操作天然会形成数据孤岛，而无法构建行业级的通用数据资产。</p><p><strong>AI科技评论：那纯视频呢？</strong></p><p><strong>丁琰：</strong>纯视频方案上，学术界和工业界其实存在一个非常明显的思维差异。在学术圈，只要一个方向足够 novel、有趣、能写论文，它就可以被视为一项很优秀的工作——至于能不能真正落地，并不是最核心的评价指标。但工业界完全不同。工业界追求的是那种简单粗暴、可靠可扩展的方案。我经常半开玩笑地说，我们要做的是“像 AK47 一样”的技术：简单、便宜、好用、有效。而从目前来看，纯视频方案距离这种工业级标准还有明显差距。纯视频当然能学到一些东西，但机器人面对的是真实的物理世界，而物理世界有大量必须被感知的信号：触觉、力控、摩擦、接触反馈，甚至声音。纯视频无法直接获取这些关键的物理信息，而这些恰恰是机器人学习和决策中非常重要的一环。因此，纯视频的数据价值不能否认，但它如何更好地在具身智能中被利用、以及能否成为主要的数据形态，还需要进一步探索。</p><p><strong>AI科技评论：所以你选择了UMI。</strong></p><p><strong>丁琰</strong>：对，UMI 的核心优势就在于它能够直接从物理世界采集数据，而且完全不依赖机器人本体。我们只需要把 UMI 设备戴在手腕上，用一个夹爪去模拟机器人的操作过程。画面中呈现的只有夹爪本身——这意味着，只要未来机器人的夹爪形态与它一致，这份数据就可以无缝迁移、直接使用，是真正的“通用型物理数据”。同时，UMI 采到的是非常精准的物理世界数据，包括动作轨迹、接触模式、力的变化等。在这种方式下，人的体感与机器动作之间的 gap 非常小，大概只有 10%–20%，采集过程流畅自然，“看到就能抓、抓了就能做”。而相比之下，遥操作的体感 gap 往往高达 80%–90%。操作员戴着 VR 远程操控机械臂，动作延迟大、反馈不连续、缺乏真实触感，这些都会导致轨迹抖动、动作不自然，数据质量也因此大幅下降。</p><p><strong>AI科技评论：那种手套方案怎么样？</strong></p><p><strong>丁琰：</strong>他们更多采的是五指数据，而 FastUMI 用的是二指数据，这本质上是两个完全不同的技术赛道。手套类设备也可以算是 UMI 的一种扩展形式，但目前五指路线整体还不够成熟。二指 UMI 的核心能力在于获取空间中的高精度轨迹，并准确记录夹爪的开合信息。由于二指夹爪的机械结构稳定、自由度少，因此可以直接、精准地推算出每个夹爪末端在空间中的位置，数据质量非常稳定。而五指方案的目标是获取每一个关节在空间中的位置，自由度暴涨、解算难度成倍提升。人手有 22 个关节，要让每个关节都保持毫米级误差几乎不现实。即使使用手套传感器，单关节误差往往仍然在厘米级，这会直接影响 replay（动作复现）效果。</p><p><strong>AI科技评论：什么是好数据？</strong></p><p><strong>丁琰：</strong>本质上必须能&nbsp;replay 成功&nbsp;才算。当机器人按照数据执行动作时，如果不能精准还原人类的轨迹，那这份数据是无法用于训练的。因此，五指方案虽然也是一种 UMI 思路，但如果没有激光动捕等高成本环境辅助，其数据精度很难满足工业级需求。而二指 UMI 的优势就在于结构简单、可控性强、误差小、可 replay，真正符合可落地、可规模化的要求。</p><p><strong>AI科技评论：目前在学术界其实也有一些UMI的方案，这些方案有哪些不足之处？</strong></p><p><strong>丁琰：</strong>我们应该算是全球第二家系统性开展 UMI 工作的团队，我对首家开展UMI 团队的工作非常尊敬，他们算是为 UMI 打开了整个技术方向的先河。那套系统整体对操作技能要求非常高，也更偏科研属性。</p><p>第一，他们的采集设备本身非常复杂。以轨迹读取为例，我们现在的 FastUMI 轨迹是直接从设备中读取的，插上电脑 1～2 分钟就能自动生成结果。而他们要读取轨迹，首先要对 GoPro 做标定，这一步至少需要 20 分钟；如果不是特别熟练的操作员，整个流程甚至可能需要一小时以上。</p><p>第二，他们的轨迹生成链路也非常长。采集时需要按照特定速度录制视频，录完后要取出 SD 卡，用读卡器插电脑，再通过 GoPro 的专用软件导出原始数据，然后再跑一套比较复杂的代码。光是环境配置和依赖安装就可能需要二三十分钟，最终才算能输出轨迹。</p><p>但这个轨迹还不一定成功，因为他们使用的是单目相机，而单目视觉里程计本身就极其容易失败。我们第一次尝试他们的方案时，大概 50%～60% 的轨迹都无法正确生成。后来才发现必须严格控制采集速度，而且场景里必须非常丰富的视觉特征点，否则视觉定位就会崩。</p><p><strong>AI科技评论：FastUMI做了哪些改进？</strong></p><p><strong>丁琰</strong>：在硬件层面，他们的 UMI 系统只能运行在特定的几套设备上，例如 Franka 或 UR5e，夹爪必须使用 WSG-50，换成其他机器人或末端执行器基本就无法开箱即用。而这些设备动辄二三十万元，对大多数团队来说成本极高。为了让 UMI 能真正做到通用普适，我们投入了大量工作去做解耦，让&nbsp;任何机器人、任何夹爪&nbsp;都可以使用 FastUMI 这一体系，这是我们非常重要的技术突破。</p><p>在软件层面，我们用成熟稳定的&nbsp;TR65&nbsp;完全替代了原本复杂且易失败的轨迹计算方案。现在只需要 1～2 分钟就能稳定算出高质量轨迹，大幅提升了数据处理效率。</p><p>在算法层面，对方的体系主要只有一个 DP 算法。我们则针对 UMI 数据的特点开发和适配了四五种不同的算法，并在数据预处理、轨迹对齐、开合建模、触觉/力控特征提取等方面做了大量优化，使整个 UMI 算法链路更加完整、鲁棒。</p><p>综上，我们从硬件、软件到算法三个维度构建了一个扎实、完整并且可规模化的 UMI 体系。之后我们还自主采集了大约1万小时的UMI数据 ，积累了大量一线采集经验，为体系的稳定性和可重复性进一步打下基础。</p><p><br /></p><h4>整个具身智能圈子2/3的人，都在用FastUMI Pro</h4><p><br /></p><p><strong>AI科技评论：你们的新产品FastUMI Pro据说成本只有传统方案的 1/5，可以具体透露一下它这个每条数据的成本是多少吗？</strong></p><p><strong>丁琰：</strong>数据的成本包括前期的高额研发投入，场地、采集人工电费以及设备折旧等等，我们新产品 FastUMI Pro 的成本能仅有传统方案的 1/5。我们现在的数据定价本质上是以“通用型数据”的模式定价。所谓通用型数据，就是一份数据可以重复售卖，并能够在不同机器人、不同算法体系中复用。因此，如果同一条数据能多次卖出，效益就会比较理想。</p><p><strong>AI科技评论：FastUMI Pro很轻，但轻巧就意味着精简，有些功能会舍弃，那么在结构设计上如何平衡重量和功能？</strong></p><p><strong>丁琰</strong>：首先，如果希望采集员一天能够稳定采 500～1000 条数据，设备的重量必须控制在合理范围内，否则长时间操作会非常疲劳。因此我们把重量上限定在&nbsp;600g。但这项工作当时是在一星的大工业场景下推进的，涉及的物品都很重，比如汽车零部件，部分甚至达到&nbsp;1.5kg&nbsp;左右。所以我们设定了一个硬性指标：设备必须能承载 2kg 的物体，而且同时保持足够轻巧。</p><p>这在当时是非常有挑战的，因为学术界还没有哪个研究型设备能做到&nbsp;既支持 2kg 负载，又具备工业级耐用性。早期在 AI Lab，我们使用的还是 3D 打印结构件，非常容易损坏。那段时间最痛苦的就是——基本每天都在换零件。也正因如此，到了一星之后我们下定决心重新设计一款真正工业级的 UMI 设备，于是就有了&nbsp;FastUMI Pro。</p><p>在硬件结构上，我们做了大量工程化优化，同时邀请专业人士对整体结构进行了系统的受力分析，明确哪些部位是主要受力点、最容易损坏。所有高应力区域，我们都采用了&nbsp;强度更高的特殊材料&nbsp;进行加固；而在螺丝孔、开合机构等容易变形的位置，我们也全面更换为更高规格的材料与结构。</p><p>至于非关键受力区域，我们的目标就是——能轻则轻。为此，我们尝试了二三十种不同厚度的结构版本，每一个版本都实际打印出来测试。在最终定型中，我们把部分结构的厚度压到&nbsp;1.5 mm，而最薄的区域甚至做到&nbsp;0.5 mm——因为这些区域几乎不受力。可以说，我们是把每一个细节都打磨到了极致，才达成了“轻量化与高强度同时兼顾”的目标。</p><p><strong>AI科技评论：同时它的定位精度又很高，这是如何实现的？</strong></p><p><strong>丁琰</strong>：这一切的实现，其实归功于我们在软硬件和算法上的全链路投入。当时我们下了一个非常重要的决心：在产品成型之前不计成本地打磨品质，因为只要规模化之后，成本最终都可以摊薄。</p><p>因此，在最初的设计阶段，我们就选择了最好的传感器、组建了最强的算法团队。在跑完整个 pipeline 后，我们发现定位精度会直接影响算法效果，尤其是轨迹拟合、动作复现和多模态信号解算，因此我们决定必须把定位精度做到极致，并逐个解决可能出现的 corner case。</p><p>为此，我们不仅搭建了专门的算法团队长期攻坚，还投入了数百万元持续打磨这个产品。在硬件、软件、算法三端不断迭代的过程中，FastUMI Pro 才最终具备了今天的工业级稳定性和精度。</p><p><strong>AI科技评论：从结果来看，这个投入是完全值得的。</strong></p><p><strong>丁琰</strong>：对，我加入鹿明还不到一个月，FastUMI Pro 就已经销售给了几十家企业。整个具身智能圈里大约有三分之二的团队都在咨询、测试或直接使用这款产品，国内国外都有。很多团队甚至是一口气采购多套设备回去评估。FastUMI Pro 基本已经成为行业内验证 UMI 能力的“标配装备”。</p><p><strong>AI科技评论：您说过鱼眼镜头的FOV必须足够大，否则会出现物体超出视野的情况，那么FastUMI Pro采用了什么方案避免这一问题？</strong></p><p><strong>丁琰：</strong>就像我一开始强调的那样，UMI 从来不是一个简单的数采方案，而是一整套系统工程。数据的形态会直接影响算法，而数据与算法又会反过来决定硬件的结构设计。早期的 UMI 基本都把相机放在腕部，视野非常受限，背景信息严重缺失，有些物体甚至只能看到局部，这对于算法推理来说是极不友好的，因为模型必须依赖足够丰富、稳定的信息量才能可靠推断。然而，很多人做 UMI 只停留在“造出一个硬件”这个层面，没有真正完整走过从数据采集、算法训练再到回到硬件调整的全流程，这其实是非常不对的。真正的 UMI 必须经历一个反复迭代的闭环：先采数据，再训练算法，再根据算法结果不断修改硬件，只有这样整个体系才能成熟。在我们的实际训练中，我们发现像素必须足够大、白平衡必须足够稳定、抗抖性能必须足够强，否则模型就无法复现轨迹或推断正确动作。也正是根据算法反馈，我们最终选用了大鱼眼作为当前的最优解。</p><p>为了确定摄像头方案，我们几乎把所有能找到的鱼眼相机都买了一遍，前后大概二三十款。测试下来发现，很多鱼眼的实际视角根本达不到宣传的 180 度，要么画面灰暗、动态范围差，要么在快速运动时出现明显抖动，还有不少白平衡极不稳定。所谓白平衡，就是当你用手遮住摄像头再移开时，图像需要瞬间恢复正常颜色；如果要两三秒才能恢复，那么这一段数据轨迹就基本报废了。正因为我们完整经历了“硬件—数据—算法—再回到硬件”的闭环迭代，并用大量试错验证各种可能性，才最终确定了现在这个大鱼眼方案。它不是随便选出来的，而是从几十种失败选项里打磨出来的最优解。</p><p><br /></p><p></p><h4>深入做UMI后，我见识了采集员的管理之难</h4><p><br /></p><p><strong>AI科技评论：FastUMI Pro为什么采用实时前处理？</strong></p><p><strong>丁琰：</strong>只有真正深入做 UMI，才会意识到实时前处理的重要性。我个人并不太倾向于 Generalist 或 Sunday Robotics 那类更偏后处理的方案。在实际采集中我们发现，后处理模式几乎是灾难性的：你可能录了八个小时的视频，最终为了得到真正可用的轨迹，不但要按任务把视频切成一段一段，还要逐条排查脏数据、删除错误片段、剔除低质量样本，整个流程极其繁琐，成本和人力消耗巨大。相比之下，实时前处理模式能够当场发现问题、当场修正，从源头保证数据质量。</p><p>选择前处理还有另一个很现实的原因——人性。数据采集员是非常难管理的。如果采用后处理方式，你把设备交给一个采集员，他干了一个星期，最后发现数据全部不能用，那么这一个星期的工钱到底付还是不付？而且问题并不总是硬件出错，更多时候是操作不规范造成的。我们在上海 AI Lab 建采集场的时候就遇到过大量类似情况：你规定某个任务必须 10 秒完成，但采集员可能 5 秒就做完了，动作不完整、节奏不符，导致整段数据完全没法用，而他们往往不会在意这些细节。因此，如果不在前端进行实时校验与约束，不仅数据质量无法保证，整个采集体系也难以长久维持。</p><p><strong>AI科技评论：这些人是从哪找的？</strong></p><p><strong>丁琰：</strong>这些采集员大多是按小时计费的兼职人员，工作本身也没有太强的技术含量，他们往往无法真正保证采集结果的质量。即便你给出明确规范，他们也不一定会严格执行，这就进一步放大了后处理方案的不确定性和风险。</p><p><strong>AI科技评论：不能去高校找一些大学生吗？大学生也挺便宜的吧。</strong></p><p><strong>丁琰：</strong>我们在 AI Lab 找的数据采集员其实都是大学生，但各种操作不规范的问题仍然很难避免，这让我真正见识到了管理的复杂性。那时候外包团队只有 11 个人，管理都已经很吃力了，如果建一个一百人的数据采集工厂，恐怕会直接崩溃。所以我们后来强调“不能做后处理”，理由并不是技术，而是管理。后处理意味着采集员一整个星期都在积累潜在错误，等数据全都无效时已经无法挽回，也无法实时指导他们如何改正。相比之下，前处理能够实时给工人反馈，告诉他动作哪里不达标、哪些步骤需要重做。我们第一周的合格率只有 50%-60%，但经过一两周的实时反馈训练之后，整体合格率显著提升，到了最后几周甚至有人能做到 100% 合格。后处理完全做不到这一点，因为采集和修正之间是割裂的，错误无法在第一时间被发现并纠正，而这一点恰恰决定了数据采集体系能否真正跑通。</p><p><strong>AI科技评论：所以前处理没有技术上的难点吗？</strong></p><p><strong>丁琰</strong>：当然，还有一个原因来自硬件本身。硬件在最初阶段可能出现的问题太多了，往往需要经过至少半年的迭代才能逐步稳定下来。只有当硬件足够可靠、采集员也完全熟练之后，才有可能转向后处理模式。也就是说，前处理和后处理并不是绝对对立的关系，更像是一种循序渐进、水到渠成的过程。当系统还不成熟时必须依赖前处理来保证质量；等整个链路稳定之后，后处理自然就能够接上。</p><p><strong>AI科技评论：你曾说在研发过程中踩过了很多坑，可以讲一下有踩过哪些坑吗？</strong></p><p><strong>丁琰：</strong>以鱼眼镜头为例，我们最初基于控制成本的考虑，采用了一些低性能镜头凑合，但在实际训练和验证中发现，算法根本无法在这种低性能镜头上发挥作用，所以最终选用了将近大几百一颗的高品质鱼眼。类似地，也有人问过我们的 UMI 设备和 3D 打印出来的版本有何区别——乍一看外观可能差不多，但真正用起来完全不是一个层级。3D 打印件本身就不稳定，采集过程中各种结构性问题会频繁出现，导致效率极低，完全达不到工业化生产所需的可靠性，也根本无法作为一个可以拿去售卖的产品。真正的工业产品必须在强度、稳定性、耐久度、精度等方面都经得起验证，这些都是 3D 打印无法承担的。</p><p><strong>AI科技评论：技术上还有其他瓶颈吗？</strong></p><p><strong>丁琰</strong>：技术上的瓶颈其实更多来自算法层面。我们团队在这一条线上不断迭代了一年四个月，几乎把能踩的坑都踩过一遍，深刻体会到 UMI 最难的地方根本不是硬件。如果用 100 分来衡量整体难度，硬件大概只占三四十分，而数据处理的难度却在六七十分以上。很多人以为 UMI 看起来很简单，好像随便谁都能做，但他们并不知道真正的挑战不在于把一个设备做出来，而在于如何把数据处理好，因为整个 pipeline 异常漫长、异常复杂。UMI 的“坏的一面”就在这里——它的数据极其难处理。如果用做菜来比喻，这就像遇到了一种食材，本身又便宜又美味，但处理过程极其繁琐，需要大量技巧和耐心，否则根本做不出好菜。UMI 的数据也是一样，只有把这道最难处理的食材处理好了，整个体系才能真正发挥价值。</p><p><strong>AI科技评论：所以算法才是你们的技术壁垒？</strong></p><p><strong>丁琰：</strong>可以这么形容，我们的数据处理全链路，别人可能需要一年才能真正跑通，而我们已经积累了超过 1万小时的实战采集经验，这本身就是非常强的壁垒。很多人看到的只是 UMI 的硬件外观，但那只是冰山一角，真正的难点和价值都藏在水面之下的部分——也就是数据处理、算法链路、异常场景处理、质量控制体系、采集规范化、以及迭代出来的经验。这些看不见的部分才决定了整个系统的可靠性与可扩展性。硬件只是入口，而真正的深水区，全在背后那条漫长而复杂的数据 pipeline。</p><p><strong>AI科技评论：FastUMI Pro在鹿明的产品生态中扮演什么样的角色？</strong></p><p><strong>丁琰：</strong>鹿明的人形机器人在运动能力方面本来就非常突出，但在操纵能力上的优势还不够明显，而 FastUMI 团队的加入让鹿明在 manipulation（操控能力）这一关键维度上获得了显著提升。</p><p><strong>AI科技评论：会有资源不够分的问题吗？</strong></p><p><strong>丁琰：</strong>不会，CEO喻超是一个非常有战略定力的人，一旦认定方向，就会坚定地 All in 下去。未来鹿明的主要布局将围绕两条主线：一条是人形机器人本身，另一条就是 FastUMI 体系。在 UMI 方向上我们拥有非常明确的先发优势，而且团队对技术路线和产品节奏都非常有信心，相信能够持续保持行业领先。</p><p><strong>AI科技评论：鹿明未来在技术研发上有哪些重点方向？</strong></p><p><strong>丁琰</strong>：我更多能谈的是软件侧的内容，尤其是数据。在具身智能领域，数据是高度多模态的，其复杂度远超自动驾驶。自动驾驶几乎不需要触觉、力控甚至声音数据，但这些恰恰是具身智能的基础维度。未来还会叠加更多模态，使理解与探索的难度进一步提升。现在整个行业在“具身智能该如何获取、理解和使用数据”这件事上的认知仍然非常不足，因此数据一定会是鹿明未来最核心的战略重点。</p><p>另一方面是我们自研的模型架构，其实也有大量讲究。并不是所有数据都能简单混在一起做训练，每一种数据都有其天然结构和语义特征，如何根据这些特征去构建属于自己的 VLA 架构，才是最关键的。我们会围绕数据特点对模型进行针对性的结构改进，充分释放不同模态的价值，这也是鹿明未来研发的另一条核心主线。</p><p><br /></p>",
    "link": "https://www.leiphone.com/category/robot/helfltBhpd5uEavc.html",
    "source": "雷锋网",
    "published": "Mon, 22 Dec 2025 09:50:00 +0800",
    "category": "芯片硬件",
    "quality_score": 3,
    "collected_at": "2025-12-22T04:14:26.235694",
    "key_data": [],
    "simple_summary": "\"数据驱动的决策塑造模型发展，并引领硬件演进步伐：专访对话鹿明CTO丁琰在GAIR 2025上的观点。\"",
    "xhs_content": "🤖【智能新高度】听说数据不仅能决定模型，还能影响硬件形态？🌟快来看看鹿明机器人CTO丁琰博士的专访，解锁具身智能的未来！\n\n✅具身智能行业难题：数据采集的成本、精度、泛化能力，仿佛构成了一个不可能三角。但丁琰博士的「FastUMI」方案却惊艳四座，低成本、高数据质量、快速部署，成为行业新范式！\n\n✅UMI不止是数采工具：丁琰博士将其视为一套完整体系，目标是将UMI打造成像AK47一样简单、可靠、低成本、好用的工业级基础设施。\n\n✅行业趋势：从Sunday Robotics的横空出世，到丁琰博士的深耕细作，UMI方案在具身智能领域的关注度空前高涨，大有改变行业格局之势。\n\n💭个人看法：数据的力量真的不可小觑！丁琰博士的坚持和独到见解，不仅为我国具身智能领域带来了新突破，也让我们看到了数据背后的复杂性和挑战。\n\n👇互动时间：你对具身智能的数据采集有什么看法？你觉得数据在智能行业中的作用会越来越大吗？快来评论区分享你的观点吧！\n\n#具身智能 #数据采集 #FastUMI #行业趋势 #智能硬件\n#人工智能 #科技前沿 #创新技术 #智能机器人 #UMI方案",
    "douyin_content": "【开头】\n画面：黑幕，突然出现闪烁的“UMI”字样，配以强烈电子音BGM，快速切换到丁琰博士的侧脸剪影，他正凝视前方。\n字幕：你知道“UMI”吗？\n旁白/字幕：一个颠覆具身智能的神秘技术，即将揭晓！\n\n【中间】\n画面1：\n切换到丁琰博士在会议现场，背后大屏幕显示“FastUMI”字样。\n字幕：低成本、高数据质量、快速部署\n旁白/字幕：丁琰博士的「FastUMI」，引领行业新范式！\n\n画面2：\n出现一星机器人和鹿明机器人的快速剪辑，展示其灵活的操作。\n字幕：从概念到现实，UMI的跨越\n旁白/字幕：从上海AI Lab到鹿明，他是国内UMI技术的先行者！\n\n画面3：\n丁琰博士手持模型，指向“UMI”字样，周围环境变为电路板和机械臂的动态效果。\n字幕：不只是工具，是工业级基础设施\n旁白/字幕：他的愿景——打造像AK47一样简单、可靠的UMI！\n\n【结尾】\n画面：\n丁琰博士对着镜头，画面边缘出现“GAIR 2025”字样。\n字幕：数据如何影响硬件的未来？\n旁白/字幕：你，如何看待数据的力量？\n\n【提问互动】\n画面：出现一个思考的机器人动画，下方带有#UMI技术 #智能革命的话题标签。\n字幕：评论留下你的想法，一起探讨智能的未来！\n旁白/字幕：来说说你的见解吧！\n\n【BGM建议】\n使用快节奏、科幻感的电子音乐，增强视频的科技感和紧迫感。\n\n【标签】\n#UMI技术 #智能革新 #FastUMI #具身智能 #GAIR2025 #科技未来 #新工业基础设施 #人工智能 #热门话题",
    "zhihu_summary": "💡【智能新风尚】数据也能决定未来？丁琰博士的「FastUMI」引领具身智能新潮流！✨\n\n🔍具身智能领域一直是技术高地的代表，而数据采集更是这块高地上的珠穆朗玛。但是，成本、精度、泛化能力的“不可能三角”，似乎总让人望而却步。这不，丁琰博士带着他的「FastUMI」方案，低成本、高数据质量、快速部署，直接在行业内扔下了一颗重磅炸弹！🎇\n\n✅【低成本】不再望“数”兴叹，用更经济的成本实现高效数据采集。\n✅【高数据质量】不是吹的，精准度up up，让智能更“具身”。\n✅【快速部署】时间就是金钱，效率就是生命，「FastUMI」快速响应，助力行业发展。\n\n💭谈到行业趋势，UMI方案的关注度已经是空前高涨，而丁琰博士的「FastUMI」更是被视为新范式。想想看，从上海AI Lab到一星机器人，再到现在的鹿明机器人，丁琰博士始终在推动UMI的研究与应用，这份坚持和前瞻性，不得不让人佩服。\n\n👀而且，丁琰博士的目标可不是仅仅打造一个数采工具那么简单，他的愿景是让UMI成为像AK47一样的工业级基础设施，简单、可靠、低成本、好用",
    "processed_at": "2025-12-22 04:18:01",
    "ai_processed": true
  },
  {
    "title": "泡沫之下，人工智能产业化还有哪些方向值得「押注」？ 丨GAIR 2025",
    "summary": "“美国2025年人工智能产业到底有多少是正向收益？MIT调查结果显示，95%都是负向的，非常烂尾，只有5%是成功的，令人吃惊。”在2025 GAIR主论坛“人工智能产业化的挑战和机遇”圆桌对话中，大会主席、加拿大皇家科学院院士杨强教授又一次对人工智能的落地现状“泼冷水”。在席卷而来的技术浪潮中，人工智能产业化面临哪些严峻的挑战？作为方兴未艾的产业，人工智能有哪些泡沫和陷阱？展望未来，人工智能产业化还有哪些值得“押注”的方向？面对AI时代的多重拷问，这场圆桌论坛通过四位科学家、一线研究者的深度对话，提供了可供参考的思考方向。参与本次圆桌论坛的嘉宾有：郑宇（主持人）：KDD China主席，京东集团副总裁，IEEE Fellow杨强：加拿大皇家科学院院士胡侠：上海人工智能实验室主任助理，领军科学家薛贵荣：之江实验室科学模型总体部技术总师四位“老朋友”齐聚一堂论道，激荡产业思潮。郑宇教授开门见山，指出人工智能产业化的困境：大语言模型出来之后，在某些应用场景取得了成功，但并没有大规模的商业应用和成熟的商业模式。究其原因，杨强教授认为人工智能产业化面临三个维度的挑战：一是预期维度，尤其是企业老板",
    "raw_summary": "<p style=\"text-align: justify;\">“美国2025年人工智能产业到底有多少是正向收益？<strong>MIT调查结果显示，95%都是负向的，非常烂尾，只有5%是成功的，令人吃惊。</strong>”</p><p style=\"text-align: justify;\">在2025 GAIR主论坛“人工智能产业化的挑战和机遇”圆桌对话中，大会主席、加拿大皇家科学院院士杨强教授又一次对人工智能的落地现状“泼冷水”。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251219/6945238cdbf45.jpg?imageView2/2/w/740\" /></p><p style=\"text-align: justify;\">在席卷而来的技术浪潮中，人工智能产业化面临哪些严峻的挑战？作为方兴未艾的产业，人工智能有哪些泡沫和陷阱？展望未来，人工智能产业化还有哪些值得“押注”的方向？</p><p style=\"text-align: justify;\">面对AI时代的多重拷问，这场圆桌论坛通过四位科学家、一线研究者的深度对话，提供了可供参考的思考方向。参与本次圆桌论坛的嘉宾有：</p><ul class=\" list-paddingleft-2\"><li><p style=\"text-align: justify;\">郑宇（主持人）：KDD China主席，京东集团副总裁，IEEE Fellow</p></li><li><p style=\"text-align: justify;\">杨强：加拿大皇家科学院院士</p></li><li><p style=\"text-align: justify;\">胡侠：上海人工智能实验室主任助理，领军科学家</p></li><li><p style=\"text-align: justify;\">薛贵荣：之江实验室科学模型总体部技术总师</p></li></ul><p style=\"text-align: justify;\">四位“老朋友”齐聚一堂论道，激荡产业思潮。</p><p style=\"text-align: justify;\">郑宇教授开门见山，指出人工智能产业化的困境：大语言模型出来之后，在某些应用场景取得了成功，但并没有大规模的商业应用和成熟的商业模式。</p><p style=\"text-align: justify;\">究其原因，杨强教授认为人工智能产业化面临三个维度的挑战：一是预期维度，尤其是企业老板的预期；二是系统维度，人工智能技术引入企业后，无法与原有传统系统适配；三是数据维度，人工智能产业化落地仅靠语言模型远远不够。</p><p style=\"text-align: justify;\">“<strong>人工智能现在还做不到的，系统往往等着人类投喂数据。就像我们家里的猫一样，坐等你去喂它，否则它不会自己去抓老鼠，因为它根本不知道什么是老鼠。</strong>”杨强教授用生动的比喻，描述AI落地中亟待攻破的系统维度难题。</p><p style=\"text-align: justify;\">胡侠教授从“小切口”谈起，结合机器人的感知、理解、规划、学习等技术卡点，阐述人工智能产业化之难——“<strong>机器人离落地还相当远</strong>”。</p><blockquote><p style=\"text-align: justify;\">如果把“机器人”类比为“人类”，从感知层面来讲，还差得很远。人类不仅是靠说话，不仅是靠眼睛在看、靠耳朵在听、靠鼻子在闻，我们的手上也有非常多的传感器，像温度传感器、湿度传感器、压力传感器，人的手还有很多维度，有自由度。很多传感器多年来都没有质的突破，没有（以上提到的）这些，会导致一个非常简单的感知问题：人将手伸进书包捡乒乓球，这是非常容易的操作，但如果机器人用手伸进一个黑书包，它看不见，加上手上没有皮肤传感器，没有自由度，很难完成从书包里拿乒乓球这个简单的操作。</p></blockquote><p style=\"text-align: justify;\">在企业实战中，人工智能的落地应用如何？薛贵荣直呼“<strong>这一行最倒霉的就是CTO或CIO</strong>”。他谈到，决策人和AI团队往往初期满怀信心，实操后却信心尽失，陷入“啥都能做”到“啥都做不了”的极端认知摇摆。预期、认知的问题导致人工智能的泡沫快速膨胀，“本来是好机会，但如果预期拔得很高，最后没做出来，干掉了一批CTO，整个行业破灭了。”</p><p style=\"text-align: justify;\">杨强教授也表达了类似的担忧：“<strong>全世界对人工智能不合适的预期，会把我们引向灾难，引向一个巨大的泡沫。</strong>”</p><p style=\"text-align: justify;\">但在眼下如火如荼的人工智能产业化进程中，已涌现出不少“小泡沫”。</p><p style=\"text-align: justify;\">薛贵荣教授指出了其中的两个泡沫：<strong>一是算力领域</strong>，现有算力建设投入多为推理卡算力、竞争激烈，大量算力资源闲置，投入与产出严重不匹配；<strong>二是AI应用领域</strong>，多数应用“人工成分”过高，本质是“人工AI”，并未达到真正的AI应用水平，市场上Agent框架等相关产品同质化严重。</p><p style=\"text-align: justify;\"><strong>人工智能到底应该做“人擅长的事情”，还是应该做“人不擅长的事情”？</strong>郑宇教授在现场抛出关键性问题。他认为，人形机器人在诸多场景中未必具有明显优势，其“爆火”在于能够拉动经济消费和产能，但我们应清醒区分何为“短期自救”、何为真正的“长远目标”。</p><p style=\"text-align: justify;\">泡沫之外，AI浪潮仍催生出新的时代机遇。在圆桌论坛最后的环节，嘉宾们纷纷“押注”值得未来多投入、多钻研、多花时间的方向。</p><p style=\"text-align: justify;\">杨强教授提到，在医疗等数据稀缺领域，数百例甚至几十例数据无法支撑深度学习，只能依靠传统回归模型，这类小数据场景广泛存在。他目前的一个研究领域，<strong>正是如何在保护隐私的前提下，整合各领域专家的小数据模型，构建全局模型让大家都受益。</strong></p><p style=\"text-align: justify;\">胡侠教授认为，安全可控是值得关注的重点方向。他提到，很多实验表明AI已经在寻求权力，在不久的将来可能会与人类争权力、争资源，形成一系列问题。</p><p style=\"text-align: justify;\">“国内的模型参数可能才达到1万亿，国外现在已经快达到7万亿了，这之间存在着差距。”薛贵荣教授认为，<strong>当前最重要的是提升大语言模型规模，大模型规模会带动底层基础设施到上层的算法、数据等的一系列革新。</strong></p><p style=\"text-align: justify;\"><strong>以下是圆桌对话的精彩内容，雷峰网作了不改变原意的整理与编辑：</strong></p><p style=\"text-align: justify;\"><strong><span style=\"font-size: 20px; color: #C00000;\">全美95%人工智能项目烂尾</span></strong></p><p style=\"text-align: justify;\"><strong>郑宇（主持人）：</strong>这个环节，当时林军跟我说，KDD是很有知名度的组织，这个圈子里面的很多老朋友，也是伴随着雷峰网一路走过来的，所以设置了这样一个论坛。我们先讲讲故事，为什么是我们这几位坐在这里？</p><p style=\"text-align: justify;\">杨老师是我们多年的好朋友，对我们每个人的帮助都非常大。有多大？KDD在中国的组织叫KDD China，杨老师是第一任主席，我有幸接班做了第二任主席。其次，杨老师创始了ACM TIST人工智能旗舰刊物，他是第一任主编，特别有幸，我又做了第二任主编，一路上我都是跟着杨老师在学习和进步，所以跟对人还是很重要的。第三任主编是胡侠的老师，现在是刘欢老师在做主编，这也是我们中国人自己创始的杂志。贵荣，原来是阿里妈妈的首席科学家，后来出来创业，做了天壤科技，现在又在之江实验室做大模型；胡侠，之前在美国KDD圈子里非常有名，现在回到上海人工智能实验室做主任助理。</p><p style=\"text-align: justify;\">今天，我们要谈论一下人工智能产业化面临的挑战和机遇。首先从挑战开始讲，大语言模型出来之后，确实在某些应用场景取得了成功，也在行业引起了很大的热点。但到目前为止，可能只有个别标杆项目成功了，并没有大规模的商业应用和成熟的商业模式。所以“挑战”到底在什么地方？为什么还有不足？到底有哪些问题？我们要客观冷静看待。首先有请杨老师讲讲他的观点。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251219/6945238ea38fa.jpg?imageView2/2/w/740\" /></p><p style=\"text-align: center;\"><span style=\"font-size: 14px; color: #7F7F7F;\"><strong>郑宇教授</strong></span></p><p style=\"text-align: justify;\"><strong>杨强：</strong>谢谢郑宇，今天特别高兴跟我们的老朋友——合作至少都有20年了，一起参加圆桌讨论。刚才郑宇问了一个非常好的问题，不是说人工智能会增长多快，而是问挑战在哪里，尤其是和业界的合作。就这个问题，我最近关注特别多，因为我有时候也给商学院讲课，我跟他们说“我是来泼冷水的”：美国2025年人工智能产业到底有多少是正向收益？最近我看了MIT的报道，<strong>调查结果显示，95%都是负向的，非常烂尾，只有5%是成功的，非常令人吃惊。</strong>我们就问，这95%的共性是什么，这5%的共性又是什么？</p><p style=\"text-align: justify;\">回答郑宇的问题，我觉得有三个维度目前面临着巨大的挑战。</p><p style=\"text-align: justify;\"><strong>第一是预期维度</strong>，尤其是老板的预期。比如老板每天看自媒体、看新闻，觉得人工智能已经不得了了，在别人的企业中已经取代人类了，取得了这个成功、那个成功，然后回来说“咱们为什么还做不到？”“为什么我们的程序员还在工作？为什么不是AI在工作？”“为什么今年的收益没有double？”<strong>我觉得这个预期是媒体以及全世界不合适的预期，这会把我们引向灾难，引向一个巨大的泡沫。</strong>不是说人工智能做不到其中的一些点，而是说我们的预期一定要实际。</p><p style=\"text-align: justify;\"><strong>第二是系统维度</strong>，来自系统的挑战。回到MIT的报告，这95%不成功的共性在于，人工智能作为新技术，引入到企业里和原有传统的、已经在工作的系统不和，<strong>“就像夫妻，其中一人非常先进，另一人很落后，还处在清朝阶段，那这两个人肯定长久不了”</strong>。就像这个例子，往往是人工智能不知道怎么帮忙，传统企业不知道怎么让人工智能来帮助自己。我也想过为什么会这样，其中一个原因是人工智能还没有做到100%。何谓100%？假设我的企业有1万个数据集，都是五花八门异构的数据，人工智能技术进来之后，它是否自己就能知道哪些数据可以用，哪些数据可以整合，哪些数据可以做训练？它知道自己需要什么以及知道自己能做什么，从而改变现有的系统？<strong>人工智能现在做不到的，系统往往等着人类投喂数据，就像我们家里的猫一样，坐等你去喂它，否则它不会自己去抓老鼠，因为它根本不知道什么是老鼠。</strong></p><p style=\"text-align: justify;\"><strong>第三是数据维度</strong>，跟我现在的工作非常相关。现在用的基本都是公开数据以及语言类数据，所以我们说的都是大语言模型。<strong>但是人工智能如果要走到落地、帮助企业的阶段，仅仅只有语言模型是不够的。</strong>其实多模态很多也是人类帮助它变成语言模型之后喂给大模型的，一个没有经过人类处理的RAG Data，大模型是不会处理的，像图像、视频以及很多非感知数据，都是非语言类的数据。</p><p style=\"text-align: center;\"><span style=\"font-size: 14px;\"><strong><img src=\"https://static.leiphone.com/uploads/new/images/20251219/6945238ee4849.jpg?imageView2/2/w/740\" /></strong></span></p><p style=\"text-align: center;\"><span style=\"font-size: 14px; color: #7F7F7F;\"><strong>杨强教授</strong></span></p><p style=\"text-align: justify;\"><strong>胡侠：</strong>杨老师从特别高的高度讲得很好，下午郑宇跟我讲，讲得越激烈越好，我也在想怎么才能讲得比较激烈。我想了很久，准备从一个特别小的点讲起。在座有很多做机器人的，因为这是在深圳，也有很多机器人产业的投资人，我想从技术的角度谈谈我对机器人产业的看法。至少在国内，AI可能是最火的领域之一，是不是“最火”的那个我不知道，但肯定是“之一”。<strong>大面来说，我觉得机器人离落地还相当远</strong>，包括以下几方面：</p><p style=\"text-align: justify;\"><strong>首先是感知层面。</strong>大家知道这一轮的AI浪潮，更多是由大语言模型或多模态大模型推动的，大模型能够比较好地理解语言，能够做出很好的诗和文章，甚至分析图片。但如果把“机器人”类比为“人类”，从感知层面来讲，还差得很远。人类不仅是靠说话，不仅是靠眼睛在看、靠耳朵在听、靠鼻子在闻，我们的手上也有非常多的传感器，像温度传感器、湿度传感器、压力传感器，人的手还有很多维度，有自由度。很多传感器多年来都没有质的突破，没有（以上提到的）这些，会导致一个非常简单的感知问题：人将手伸进书包捡乒乓球，这是非常容易的操作，但如果机器人用手伸进一个黑书包，它看不见，加上手上没有皮肤传感器，没有自由度，很难完成从书包里拿乒乓球这个简单的操作。</p><p style=\"text-align: justify;\"><strong>第二是理解层面。</strong>不管是大模型、多模态还是具身，大家都谈了很多。从数据来讲，我们可以给机器人看很多书本知识，也可以给它看很多video知识，但没办法很轻易就把一些物理学知识传递给机器人。机器人不知道球被扔出去以后会因为牛顿定律呈抛物线下降，不知道桌子应该要比地面高，不知道“水往低处流”等简单的物理学现象，也没办法很好地理解。</p><p style=\"text-align: justify;\"><strong>第三是规划层面。</strong>大家想想，把乐高积木拼起来，小孩可以做得很好，但对机器人来说，把上百个东西变成一系列的操作是很难的。纸上得来终觉浅，把乐高的说明书给孩子，孩子可以拼出来一个玩具；把一个零件说明书给熟练的工人，工人可以理解、规划、组建这些部件。但现在来讲，我还没有看到机器人有这个能力。</p><p style=\"text-align: justify;\"><strong>第四是学习能力。</strong>大家都知道，人从出生一直到七八岁，就有非常强的智能，远比现在的机器人强很多。它们有那么多的数据吗？实际并没有。<strong>机器人现在缺乏的是小样本学习、持续学习的能力，它没有基本的学习能力。</strong>虽然我们给它灌了很多数据，但这些数据究竟怎么样？不管是1T的数据、1P的数据甚至是更多数据，这些数据中有多少重复的知识？把这些数据变成知识的能力，包括持续学习的能力以及小样本学习的能力，我还没有在现在的机器人或具身领域看到很大的突破。</p><p style=\"text-align: justify;\">从感知到理解、规划、学习，在机器人领域还有很长的路要走。虽然现在的公司估值都很高，但我觉得这里面的泡沫还是蛮大的。</p><p style=\"text-align: justify;\"><strong>薛贵荣：</strong>大家一开始看到外面关于AI的报道，会充满信心，干了一段时间，会感觉什么信心都没有了，在两个极端之间游荡，搞得决策人和AI团队都在怀疑“我们能干吗？我们能干好吗？”最后连耐心都没有了。</p><p style=\"text-align: justify;\">这是IT部门决定的事吗？如果是的话，基本干不下去，因为老板会跟你说，你的KPI要再设得高一点，都用AI了，应该再裁掉30%的人。搞到最后，做事的人没办法承诺成果。我觉得，大家在认知上的差异，导致我们所有人干这个事的决心和信心都会有动摇。到最后我能不能干好？我要不要花这么大的力气来做数据整理的工作？最后大家都不想做整理数据的活，就希望外面有一个现成的模型，拿来就能用，“拿来主义”的思想会重一点。</p><p style=\"text-align: justify;\">如果是这样的话，我觉得基本干不下去。因为外面的模型跟你家里的数据融合肯定是要做的，否则模型放在家里也只能写写报告、办办公，或者再用点大家讨论到的RAG。其实RAG也不是很容易的事，有的人觉得RAG一做，幻觉就能解决，其实是搞不定的，也许能解决60%～70%的问题，但还有30%～40%的挑战。因为幻觉的问题还是存在，导致你觉得就不应该做这个事情。</p><p style=\"text-align: justify;\"><strong>所以我们这个行业最倒霉的是什么？最倒霉的是CTO，或者CIO。一轮一轮换，因为没产出，就被淘汰掉了。</strong>大家要么过度乐观，要么过度悲观。模型效率再好一点，智力再强一点，可能会做得很好，但这一步走过去需要时间。我觉得这是有挑战的事。</p><p style=\"text-align: justify;\"><strong>郑宇（主持人）：</strong>观点都非常犀利，正好贵荣提到CTO的事情，前段时间有一个CTO Club闭门会议，当今国内都在做这些的大厂CTO，关起门来在里面讨论。这里面的声音跟外面媒体的声音完全不一样：这里面是人间清醒，不能说哀声一片，但大家都觉得人人自危，最怕老板出去开会、培训，一培训就跟你说，人家做出来了，你没做出来。<strong>预期的问题、认知的问题，导致这个行业的泡沫快速膨胀。本来确实有进展，是好机会，但如果大家觉得两年就能做完，预期拔得很高，到两年之后没做出来，干掉了一批CTO，整个行业破灭了。这是人间清醒的真话。</strong></p><p style=\"text-align: justify;\"><span style=\"color: #C00000; font-size: 20px;\"><strong>人工智能赛道有哪些泡沫？</strong></span></p><p style=\"text-align: justify;\"><strong>郑宇（主持人）：</strong>刚刚说了人工智能产业化的挑战，从不同的维度来讲，有预期、系统、数据的维度，有感知、理解、规划、学习的维度，有实战经验的维度——认知、决策、责任、技术队伍、时间管理、成本管理等等，很多东西都是真实存在的。问一下杨老师和贵荣，你们觉得在人工智能赛道，目前最大的泡沫和陷阱在哪里？你们可以指出来一下，让大家可以有一些预警。</p><p style=\"text-align: justify;\"><strong>杨强：</strong>我觉得小泡沫很多。第一个泡沫是现在的人工智能利用公开数据，比方说用Twitter训练出大模型，就有人认为，对于所有的数据都可以训练出大模型。比如说大家会有一个预期：机器人已经能做双足，那它是不是可以跟大模型相结合，把它的数据输入给大模型，就可以输出一系列的行为，机器人就变得更智能了。这就是一个泡沫，也就是说，它把一个地方的成功，迁移到了很多其他的地方，不看这两个地方的重大区别。这里说到的重大区别包括两个维度：</p><p style=\"text-align: justify;\"><strong>一方面，数据是异构的。</strong>公开数据是语言数据，但是我们想迁移到的地方，比如行为数据、图像数据，比如各种各样的多模态数据，其实是非语言数据，<strong>所以我们并不知道现在怎么用非语言数据作为输入，训练出一个智能的大模型。</strong></p><p style=\"text-align: justify;\"><strong>另一方面，很多公开数据已经快用完了，世界上所有数据的总量，4%是公开数据，96%是非公开的。</strong>也就是说，人工智能依靠大语言模型突飞猛进，但马上就要戛然而止了，因为我们没有新的数据。新的数据在哪里？在私有数据，在手机上，在医院里，在银行里，在大学里，在学生的课程上<strong>。如何利用私有数据继续赋能给大模型，这是一个巨大的挑战。</strong>如果解决不了，这就是一个巨大的泡沫。</p><p style=\"text-align: justify;\"><strong>郑宇（主持人）：</strong>杨老师从数据层面讲到了异构的问题，能够在语言层面训练出大模型，不代表其他条件都能训练出大模型；现在的数据显然不够，还要持续推进大模型的进展。请贵荣谈谈你的想法，你感觉什么领域泡沫最大？</p><p style=\"text-align: justify;\"><strong>薛贵荣：</strong>我感觉现在算力的泡沫也比较大。各个地方都在做大的智算中心，原来是IDC，现在都成了AIDC，但现在推理的AIDC太多，而训练的AIDC很少。大家可能都知道，美国模型的参数规模现在在6万亿到7万亿之间，对算力的要求要达到10万张卡，这个系统要求非常高。<strong>我们现在建设的智算中心基本都是推理集群，而真正的训练集群太少，导致大量的推理智算中心的机器挂在机柜里，都不开机，这本身也是非常大的投入风险。</strong></p><p style=\"text-align: justify;\">另外，我最近也参加了很多会，会场上的Agent遍地都是。只要你到一个展位，基本都有一两个Agent在那里，感觉好像做Agent的越来越多，但Agent定制的成分也很少，还没到所谓真正的Agent智能化程度。今<strong>天的Agent，人工involve的程度太高。</strong></p><p style=\"text-align: justify;\"><strong>所以两方面，一个是算力的建设，一个是重复建设类似的Agent框架。</strong></p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251219/6945238dd4238.jpg?imageView2/2/w/740\" /></p><p style=\"text-align: center;\"><strong><span style=\"font-size: 14px; color: #7F7F7F;\">薛贵荣教授</span></strong></p><p style=\"text-align: justify;\"><strong>郑宇（主持人）：</strong>刚刚胡侠提到人形机器人，很多人心中都有困惑：人工智能到底应该做“人擅长的事情”，还是应该做“人不擅长的事情”？我相信大部分人认为，它应该做“人不擅长的事情”——人能干的事情，不需要它来干，自己就干得很好；人不能干的事情，让它来干。</p><p style=\"text-align: justify;\">什么叫“人不能干的事情”？有几个方向，比如：</p><blockquote><p style=\"text-align: justify;\">（1）高风险，像爆炸、挖矿、塌矿，人不能去；</p><p style=\"text-align: justify;\">（2）高强度，背500斤背不动，要让机器人来干这样的事情；</p><p style=\"text-align: justify;\">（3）高精度，0.1μm的东西，人手有时候抖，控制不住；</p><p style=\"text-align: justify;\">（4）高恶劣环境，不危险但很恶心，人一干就想吐，比如下水道。</p></blockquote><p style=\"text-align: justify;\">在这四个场景中，人体结构没有任何优势，比如在战场上或者在淤泥里，履带肯定比四足或两足要好很多。这个时候原先的基本假设就不成立：为什么要做人形机器人？人形机器人一旦学会了之后，人的通用能力自然就可以扩展。<strong>但机器人的定位，应该是做“人不擅长的事情”，人体结构在这个时候没有任何优势，不应该用这个方法来做，应该用别的方法。</strong></p><p style=\"text-align: justify;\"><strong>其次，我们对人自身的理解，真的很深了吗？人对自身的了解，还是非常少的，都不确定是否有1%。</strong>如果人对自身的机理都搞不明白，能否设置出模型机理？就像人工智能不能无师自通一样。请问，谁能说得清楚人是怎么思考的？怎么用大脑控制小脑的？很多东西说不清楚，很抽象，我们经常讲的是大脑、小脑互相做配合，但机理并不清楚，从原理上也做不出来。</p><p style=\"text-align: justify;\">回过头来讲，国家为什么要鼓励人形机器人的发展？这是从拉动经济消费和产能的角度说的。一方面，人形机器人，康养的、陪伴的，人手一个，量很大，资本很喜欢；另一方面，造机器人，我们的产能能够被拉动起来，很多的钢和材料都能用起来，就能带动这一波经济循环。短期之内我们还没有找到更好的经济增长点，也许有一天会有突破，即使没突破，这也是一个很好的衔接。<strong>所以要分清楚什么是真正的“长远目标”和“短期自救”，找好这个平衡。</strong></p><p style=\"text-align: justify;\"><span style=\"font-size: 20px;\"><strong><span style=\"color: #C00000;\">垂域小模型是“押注”方向</span></strong></span></p><p style=\"text-align: justify;\"><strong>郑宇（主持人）：</strong>既然有挑战，肯定也有机遇。请几位老师简短说一下，你们认为人工智能应该在哪些方面发力，做什么比较适合？以及是未来有希望的，虽然时间会长一点，但我们应该多投入、多钻研、多花时间去搞的东西？</p><p style=\"text-align: justify;\"><strong>杨强：</strong>现在我们已经离不开人工智能了。我们手机上都有大模型APP，尤其是学生，如果离开了，可能分数就降低了；程序员也离不开大模型；再就是门禁、人脸识别、指纹识别，也离不开人工智能。现在人工智能已经变成了我们生活的一部分，很多都是深度学习的人工智能。</p><p style=\"text-align: justify;\">但是到了医疗领域，数据非常少。最近我跟一些医生和教授聊天，他们手里的数据，几百例都算多的，也许就几十例，<strong>这种数据用深度学习都不行，只能用回归模型，也就是特别传统、特别简单的模型。</strong>但这种数据集特别多，教授也特别多，所以我现在研究的领域就是如何把这些数据集、教授聚集起来，既保护隐私，又让他们共享知识，建立一个全局模型，让大家都受益。像我现在所做的迁移学习或联邦学习，就是在这个方向发力。<strong>未来也许我们会看到很多垂域的小模型——这些小模型有无数个，在任何一个领域——可能我们能够把这些小模型汇聚起来、串起来，完成一个复杂的任务。</strong></p><p style=\"text-align: justify;\"><strong>胡侠：</strong>我还是接着聊几句机器人。刚才抨击得比较激烈，接着郑宇刚才讲的，我多说几句。现在国家在大力投入机器人行业，很多VC热钱也进入机器人行业。我跟这些投资人深度聊过，当时我有这个疑惑：大家明明知道机器人的泡沫这么大，短期内不敢说一定做不成，但做成的希望值还挺小，但为什么大家还愿意投入这么多的钱？</p><p style=\"text-align: justify;\">刚刚郑宇谈了一点。另外，从国家的层面来讲，<strong>大</strong><strong>家希望把这个生态做起来以后，用机器人行业的火爆倒逼技术的发展。</strong>刚刚我谈的很多技术缺陷实际上还没有解决，比如感知、传感器、自由度的问题，如果这些基础问题解决了，可以衍生一大批机器狗、无人机、扫地机器人……whatever机器人，都可以基于这套技术实现非常大的发展。它本身是否成功，我个人觉得不要紧，但是从技术布局的角度来讲，如果能够把这一批生态带成功了，国家的投资、产业的投资将会非常成功。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251219/694523912d856.jpg?imageView2/2/w/740\" /></p><p style=\"text-align: center;\"><span style=\"color: #7F7F7F;\"><strong><span style=\"font-size: 14px;\">胡侠教授</span></strong></span></p><p style=\"text-align: justify;\">回答郑宇刚刚提问的“机遇”问题，我想说一下中国的机遇有哪些：首先我看到了很多自主可控的机遇，虽然这一波AI发展得这么火，深圳各种各样的产业、各种各样的机器人应用铺天盖地，包括马上在Las Vegas要举办的新一届CES（International Consumer Electronics Show，国际消费类电子产品展览会），可能过半的厂商都来自中国。</p><p style=\"text-align: justify;\">但是我们要意识到，Fundamentally，咱们国家的基础软硬件系统，实际被“卡脖子”卡得非常厉害。从非常底层的芯片来说，现在N卡绝对还是遥遥领先的。数字智能方面，要训练一个规模更大的模型，极大的数量都是高度依赖N卡的芯片，CUDA系统把数字智能完全垄断了；物理智能方面，如果要训练一个具身机器人或具身系统，还是要高度依赖英伟达Omniverse整个生态。我国还没有形成独立自主可控的一套软硬件协同系统for数字智能、物理智能，所以我觉得对咱们的产业和技术人员来说，都是非常好的机会。</p><p style=\"text-align: justify;\">其次，我非常认同刚刚提到的科学大模型。我们可以看到，过去专有的科学大模型，比如AlphaGo、AlphaFold，在通用的大模型，比如通义千问、ChatGPT、DeepSeek，都已经取得了非常大的成功。<strong>但怎么做“通专融合”的科学大模型？通用性能还不错，又能够做专业的事情，我个人觉得这是蛮大的机会。</strong>现在更多是做一些微调，但我看到之江实验室做了一些努力，我觉得这是很有潜力的方向。</p><p style=\"text-align: justify;\">第三，安全可控的方向。从短期来讲，涉及到幻觉等各种各样的问题；从中期来讲，让语言大模型、多模态大模型、具身大模型真正在高价值、高敏感行业落地。比如大家还没有在医院，没有在金融行业或其他高价值、高敏感行业看到特别多的大模型应用落地，这是因为安全可控做不好。从远期来讲，从政界最高层到学界最高层，他们都关心AI会不会有拟人化的风险。因为有很多实验表明，AI已经在寻求权力了：首先，它寻求自己要survive，然后寻求权力、寻求资源，在不久的将来与人类争权力、争资源，形成一系列问题。</p><p style=\"text-align: justify;\"><strong>从短中长期来讲，安全可控一定是AI最有潜力的发展方向。</strong>安全这个方向，虽然大家多多少少都有提及，但还远没有形成生态，远没有形成产业。怎样把safety as a service（安全即服务）做起来还是很重要的。</p><p style=\"text-align: justify;\"><strong>薛贵荣：</strong>第一，我们的大语言模型的参数量还不够大。国内的模型参数可能才达到1万亿，国外现在已经快达到7万亿了，这之间存在着差距。<strong>大模型规模会带动底层基础设施到上层的算法、数据等的一系列革新。</strong></p><p style=\"text-align: justify;\">模型好了以后，可以做的东西太多了，这件事迫在眉睫。所以无论是通义千问也好，DeepSeek也好，还是其他的国产大模型，能力要追赶上去。在这个基础上，企业的AI应用可能才有机会。再谈到人工智能+科学，数学是科学的哲学，首先我们要把数学搞好，同时增强对物理世界的感知。<strong>所以用人工智能把数学学得很好、把物理世界理解好，这两件事情也非常重要。</strong></p><p style=\"text-align: justify;\"><strong>郑宇（主持人）：</strong>其实我们还想继续聊，但因为时间问题，我们要结束这个panel了。一方面，大家以后听到“人工智能过去是以年为进展，现在是以周为进展”的观点，要小心、要冷静；另一方面，要保持对人工智能长远发展的信心，选择正确的方向，坚持做该做的事情，这样人工智能才能有一个美好的未来。谢谢大家。</p>",
    "link": "https://www.leiphone.com/category/ai/0IhVTnuJsImb6D17.html",
    "source": "雷锋网",
    "published": "Fri, 19 Dec 2025 18:49:00 +0800",
    "category": "AI通用",
    "quality_score": 3,
    "collected_at": "2025-12-22T04:14:26.235699",
    "key_data": [
      "95",
      "5"
    ],
    "simple_summary": "\"泡沫之下，人工智能产业化值得押注的方向在于深度融合传统产业，提升实体经济的智能化、精准化和效率化。\"",
    "xhs_content": "🤖【AI未来，押对宝才赢未来！】🎉 GAIR 2025峰会揭秘人工智能产业化真相！💥\n\n✅ 95%的AI项目竟然是“泡沫”？别被数字吓倒，关键看我们怎么押注！\n✅ 杨强教授领衔，四大科学家激情碰撞，为你揭秘AI产业化的陷阱与机遇！\n✅ 大语言模型很火，但商业应用在哪？这里有你想要的答案！\n\n💭 AI时代，我们都是探索者。杨强教授指出，AI产业化面临三大挑战：预期、技术、商业模式。每一个维度都值得我们深思熟虑。\n\n👇 互动时间到！你认为人工智能的未来会怎样？哪些方向值得我们下注？\n\n#人工智能 #AI产业化 #GAIR2025 #杨强教授 #科技未来 #押注方向 #商业模式 #互动话题\n\n快来评论区分享你的观点吧！👀🔥💬👇让我们一起探讨AI的无限可能！🚀🌟",
    "douyin_content": "【开头】\n（悬念式，画面：动画特效，数字“95%”和“5%”形成强烈对比，背景是AI元素图案）\n字幕：“你知道吗？AI产业95%的预测竟然是...”\nBGM建议：紧张刺激的电子音乐，时长3秒。\n\n【中间】\n（快速切换画面，画面1：GAIR大会现场，画面2：杨强教授发言，画面3：AI泡沫的视觉元素，如破裂的泡沫图案）\n字幕：\n“MIT调查指出，AI产业化成功率仅有5%！🔥”\n“杨强教授直击AI落地困境，揭秘产业化三大挑战！🤔”\n“泡沫之下，哪些方向还值得投资？🎯”\nBGM建议：持续快节奏的背景音乐，时长7秒。\n\n【结尾】\n（画面：四位科学家在圆桌论坛上的互动，背景有#GAIR2025等字样）\n字幕：“你如何看待AI产业的未来？评论留下你的想法！✍️”\n标签建议：“#AI未来 #产业化挑战 #杨强教授 #GAIR2025”\nBGM建议：音乐逐渐降低音量，营造互动氛围，时长5秒。\n\n【总时长】15-30秒\n\n【备注】\n- 确保字幕简洁明了，易于理解。\n- 画面切换要快，以保持观众的注意力。\n- BGM的选择要能突出紧张感及互动性。\n- 标签要选择热门话题，便于视频被更多人看到。",
    "zhihu_summary": "💡【AI未来，泡沫or机遇？】揭秘2025年AI产业的投资方向！👀\n\n🔍近期，GAIR 2025论坛上，杨强教授等一众科学家对人工智能产业化进行了深度探讨。你知道吗？👉美国2025年人工智能产业，竟然95%都是负向收益！那么，在AI的泡沫之下，我们还能找到哪些值得押注的方向呢？✅\n\n✅核心亮点：\n\n1️⃣ 预期维度：人工智能产业化的预期与实际应用之间存在巨大差距。\n2️⃣ 应用场景：虽然大语言模型在某些场景取得了成功，但尚未实现大规模商业应用。\n3️⃣ 行业趋势：AI产业化面临三大挑战，如何在困境中寻找机遇？\n\n💭个人看法：\n\nAI产业化确实存在不少泡沫，但正如杨强教授所说，危机中总是蕴藏着机遇。🌟比如，我们可以关注以下方向：\n\n1. AI在特定领域的深度应用，如医疗、教育、金融等。\n2. 人工智能与物联网、大数据、云计算等技术的融合创新。\n3. 重视AI伦理和法规建设，为产业发展创造良好环境。\n\n👇互动环节：\n\n你对AI产业化有什么看法？你认为哪些方向值得押注？欢迎在评论区留言分享，让我们一起探讨！🔔\n\n🏷️话题标签：\n#人工智能# #AI产业化# #投资方向# #",
    "processed_at": "2025-12-22 04:18:33",
    "ai_processed": true
  }
]