[
  {
    "title": "「视频世界模型」新突破：AI连续生成5分钟，画面也不崩",
    "summary": "",
    "raw_summary": "",
    "link": "https://www.jiqizhixin.com/articles/2025-12-31-9",
    "source": "机器之心",
    "published": "Wed, 31 Dec 2025 17:48:45 +0800",
    "category": "AI通用",
    "quality_score": 5,
    "collected_at": "2026-01-01T04:36:39.053966",
    "key_data": [],
    "simple_summary": "\"视频世界模型取得新突破，AI能连续5分钟生成高质量、稳定的视频画面。\"",
    "xhs_content": "🤖AI大牛又放大招啦！你敢信？「视频世界模型」竟然能连续生成5分钟视频，而且画面稳如老狗！这不就是妥妥的短视频神器吗？🎉\n\n✅核心亮点一：5分钟！你没听错，是连续5分钟的高质量视频，AI助手帮你一次性搞定！\n\n✅核心亮点二：画面不崩！再也不会出现尴尬的卡顿和模糊，每一帧都清晰得像大片！\n\n💭个人看法：这技术一出，感觉短视频创作要被颠覆啦！想象一下，以后拍Vlog、做教学视频，甚至拍个小电影，都不用担心画面质量和时长问题，全部交给AI就搞定！🎥\n\n👇结尾互动：你觉得这项技术会给短视频行业带来哪些变革？快来评论区讨论吧！还有，如果你有更多关于AI短视频的想法，也欢迎分享哦！👀\n\n#AI黑科技 #短视频神器 #视频生成 #技术突破 #Vlog必备\n#AI助力创作 #未来已来 #科技改变生活 #机器之心报道 #行业趋势分析",
    "douyin_content": "【脚本】\n\n【开头：悬念式】\n（画面：黑幕，突然出现一个眼睛的特写，瞳孔逐渐放大，充满期待）\n字幕：“你准备好迎接未来了吗？”\nBGM：紧张刺激的电子音乐\n\n【中间：核心信息点】\n（画面：快速切换至AI生成视频的精彩片段，显示连续生成的5分钟视频，画面流畅不崩）\n字幕：\n“AI新突破！”\n“视频世界模型，5分钟连续生成！”\n“画面流畅，毫无破绽！”\n\n【结尾：提问互动】\n（画面：显示疑问的表情包）\n字幕：\n“你觉得这样的AI技术，将如何改变我们的生活？”\n“留言讨论，等你来！”\nBGM：逐渐降低音量，突出字幕\n\n【标签建议】\n#AI新突破 #视频世界模型 #5分钟连续生成 #科技改变生活\n\n【总时长】：约20-25秒\n\n【风格】：节奏快、信息密集、充满科技感，引发观众思考与讨论。",
    "zhihu_summary": "💡 AI界又双叒放大招啦！你敢信？「视频世界模型」竟然能连续生成5分钟视频，而且画面稳如老狗，一点不崩！🎥\n\n✅ 核心亮点一：5分钟！不是5秒，也不是5分钟片段，是整整5分钟的高清连续视频！\n✅ 核心亮点二：画面不崩，妈妈再也不用担心我被抖动的视频镜头弄晕啦！\n✅ 核心亮点三：AI智能生成，这可是技术大牛们熬夜秃头搞出来的黑科技！\n\n💭 个人觉得这技术太6了！想象一下，以后的网剧、电影是不是可以个性化定制？每个人都能成为导演，拍出自己心目中的大片！🎬\n\n👇 互动时间到！你觉得这项技术将来会应用到哪些场景？是短视频创作，还是电影制作？快来评论区一起聊聊吧！👀\n\n#AI黑科技 #视频生成 #个性化定制 #技术突破 #未来电影 #智能创作 #黑科技改变生活 #机器之心 #5分钟不崩视频 #网感话题 #技术大牛 #导演梦 #互动时间 #评论见真知",
    "processed_at": "2026-01-01 04:37:04",
    "ai_processed": true
  },
  {
    "title": "刚刚，稚晖君发布的人形机器人Q1，小到能塞进书包",
    "summary": "",
    "raw_summary": "",
    "link": "https://www.jiqizhixin.com/articles/2025-12-31-8",
    "source": "机器之心",
    "published": "Wed, 31 Dec 2025 16:39:00 +0800",
    "category": "机器人",
    "quality_score": 5,
    "collected_at": "2026-01-01T04:36:39.053983",
    "key_data": [],
    "simple_summary": "\"稚晖君全新推出的人形机器人Q1，迷你便携，小巧如书包之宝。\"",
    "xhs_content": "🤖💥【书包里的新伙伴！】稚晖君新发布的人形机器人Q1，小巧到让你惊喜！✨\n\n✅🔍【核心亮点】\n1️⃣ 只有手掌大小，轻松塞进书包！\n2️⃣ 智能互动，陪你看电影、学编程！\n3️⃣ 未来科技感十足，引领行业新趋势！\n\n💭【个人看法】\n这不仅仅是一款玩具，更是一种未来的生活方式！🚀当我们还在惊叹于手机的智能化，稚晖君已经将人形机器人做到了如此迷你，真是让人感叹科技发展的速度！\n\n👇【引导互动】\n你期待这样的人形机器人吗？它将给你带来哪些便利？快来评论区畅想一下吧！👇\n\n#科技改变生活 #迷你机器人 #智能时代 #未来趋势 #互动科技 #稚晖君Q1🤖🎒",
    "douyin_content": "【开头：悬念式】\n画面：快速闪烁不同大小的书包图片，最后定格在一个普通大小的书包上。\n字幕：#黑科技新发现 #机器人缩小了？\nBGM：神秘感的背景音乐，逐渐增强。\n\n【中间：核心信息点】\n画面1：迅速切换至稚晖君LOGO，随后展示机器人Q1的炫酷外形。\n字幕：稚晖君新发布！人形机器人Q1\nBGM：节奏加快，添加科技感音效。\n\n画面2：机器人Q1的演示，特写其精致细节，然后展示它轻松被放进书包。\n字幕：#超迷你机器人 #塞进书包带走\nBGM：维持快节奏，加强音效。\n\n【结尾：提问互动】\n画面3：展示机器人Q1从书包中跳出，做出一个可爱的动作。\n字幕：这样的机器人，你想拥有吗？#未来科技\nBGM：音乐渐弱，突出提问。\n\n【互动提问】\n画面4：出现选择题动画，左边是“想要”，右边是“太酷了！”\n字幕：评论告诉我你的答案！\nBGM：轻松愉快的背景音乐，引导观众参与互动。\n\n【标签建议】\n#科技新趋势 #机器人革命 #未来已来 #人形机器人 #稚晖君Q1\n\n【总时长】\n约25-30秒\n\n【脚本说明】\n该脚本在保持原文信息的基础上，进行了适合短视频平台节奏的调整，通过快速切换画面和紧凑的BGM，增强观众的观看体验，并在结尾设置互动问题，提高观众参与度。",
    "zhihu_summary": "💡哇塞，太大惊喜！稚晖君刚推出的超酷人形机器人Q1，竟然小到能直接塞进书包！🎒来看看这个黑科技小可爱的亮点吧！\n\n✅迷你身材，巨大潜能：不到一本书的大小，却能完成各种复杂动作，简直是小巧玲珑的代言机器人！\n\n✅应用广泛，无所不能：无论是教育、娱乐还是日常辅助，Q1都能轻松应对，未来的生活小助手就是它了！\n\n✅行业新趋势，未来已来：人形机器人的小型化意味着巨大的市场潜力，家庭机器人时代真的要来临啦！\n\n💭我个人觉得，Q1不仅仅是一个机器人，它更像是一个开启未来生活方式的钥匙。想象一下，带着它去上课、散步，甚至出差，是不是超有科技感的？\n\n👇大家对这种迷你人形机器人有什么期待或者想法呢？快来评论区交流一下吧！期待你们的精彩发言哦！\n\n#迷你机器人 #人形机器人 #黑科技 #未来生活 #科技趋势",
    "processed_at": "2026-01-01 04:37:32",
    "ai_processed": true
  },
  {
    "title": "AI终于学会在家“伺候人”！Hey Tuya，我躺了",
    "summary": "一个“操作系统级”AI生活助手",
    "raw_summary": "一个“操作系统级”AI生活助手",
    "link": "https://www.qbitai.com/2025/12/366334.html",
    "source": "量子位",
    "published": "Wed, 31 Dec 2025 08:38:14 +0000",
    "category": "AI通用",
    "quality_score": 4,
    "collected_at": "2026-01-01T04:36:39.053990",
    "key_data": [],
    "simple_summary": "\"AI技术实现家庭服务新突破，智能助手助力舒适居家生活。\" \n\n这句话概括了您提到的AI技术，如Tuya智能助手，为用户提供便捷居家服务的情景。\"Hey Tuya，我躺了\" 这句话似乎是在与智能助手互动，表明用户准备享受由AI辅助的舒适生活。",
    "xhs_content": "🤖【躺赢人生新伙伴！】\"Hey Tuya，我躺了\"——这不再是懒人的专利，而是AI时代的新潮流宣言！🏠✨\n\n✅操作系统级AI生活助手，实力诠释智能生活！\n✅从此家务无忧，享受被AI伺候的VIP体验！\n\n💭有没有想过，每天回家只需一声令下，灯自动亮起，空调已调至最舒适温度，甚至你喜爱的音乐已准备好舒缓你的疲惫。这就是AI带来的生活改变，而Tuya正是这场革命的领航者！\n\n🚀行业趋势分析：随着人工智能技术的不断突破，家居智能化已成为大势所趋。Tuya的操作系统级AI生活助手，正是这场智能风暴的急先锋！想象一下，未来家家户户都有一个贴心的AI管家，是不是超兴奋？！\n\n👇快来评论区告诉我，如果你有了这样一个AI助手，你希望它能帮你做些什么？是烹饪大餐？还是规划旅行？或者有更酷的想法？期待你的分享和讨论！🔥\n\n#智能家居 #AI助手 #智能生活 #躺赢人生 #Tuya智能\n",
    "douyin_content": "【视频脚本】\n\n### 开头（3秒）\n- 画面：黑屏，突然亮起，出现文字“你敢信？AI现在会这样做...”\n- 字幕：无\n- BGM：紧张的电子音乐起，突然停止\n\n### 中间（10-20秒）\n- 画面1: 快速切换到一个家庭客厅，一个人躺沙发上，手一挥，语音命令：“Hey Tuya，我躺了。”\n- 字幕：#黑科技 #AI助手\n- BGM：轻快科幻音乐\n\n- 画面2: 灯光自动调节，电视开启，窗帘缓缓拉上。\n- 字幕：#智能家居 #生活新方式\n- BGM：持续轻快音乐\n\n- 画面3: 画面快切至操作系统界面，显示“Tuya OS”字样，AI语音回应：“好的，已为您调整舒适模式。”\n- 字幕：#操作系统级AI #生活助手\n- BGM：音乐节奏加快，突出科技感\n\n### 结尾（5-10秒）\n- 画面：回到躺沙发上的人，舒适地微笑。\n- 字幕：“如果有个AI在家伺候你，你想让它做什么？”\n- BGM：音乐渐弱\n\n- 画面+字幕：弹出互动问题：“你会用AI生活助手来做什么？评论告诉我！”\n- 标签建议：#AI生活助手挑战 #智能生活\n\n### 整体建议\n- 时长控制：整个视频紧凑，不超过30秒\n- 画面切换：快速且流畅，每个画面不超过2秒\n- 字幕颜色：醒目，建议使用白色或亮色，确保清晰可见\n- BGM选择：使用流行的、有科技感的音乐，可以增加记忆点\n- 互动提问：鼓励观众参与，增加视频互动性\n\n这样一来，视频既符合抖音的短视频风格，又能吸引观众注意力和参与度",
    "zhihu_summary": "💡 家里蹲的福利来啦！AI生活助手Hey Tuya上线，懒人模式正式开启！🏠\n\n✅ 全新操作系统级AI生活助手，让你躺在家里也能享受智能生活！\n✅ 说出你的需求，Hey Tuya帮你搞定一切！\n✅ 不用动手，语音操控，享受科技带来的便捷！\n\n💭 说到AI，你可能想到的是高大上的技术，但现在它已经走进我们的生活，成为家庭的一员。👨‍👩‍👧‍👦 我觉得这不仅是技术的进步，更是生活方式的改变。想象一下，你躺在沙发上，只需要说一声“Hey Tuya，我渴了”，一杯鲜榨果汁就送到你面前，这是多么美妙的体验啊！\n\n👇 来聊聊吧，如果你有了这样一个AI生活助手，你最想让它帮你做什么？🤔\n\n#AI生活助手 #智能家庭 #懒人福音 #科技改变生活 #操作系统级AI助手 #HeyTuya #躺赢人生 #语音助手 #未来趋势 #智能家居必备",
    "processed_at": "2026-01-01 04:38:13",
    "ai_processed": true
  },
  {
    "title": "吴恩达年度AI总结来了！附带一份软件开发学习小tips",
    "summary": "“2025标志着新工业时代的到来”",
    "raw_summary": "“2025标志着新工业时代的到来”",
    "link": "https://www.qbitai.com/2025/12/366256.html",
    "source": "量子位",
    "published": "Wed, 31 Dec 2025 07:53:59 +0000",
    "category": "教育",
    "quality_score": 5,
    "collected_at": "2026-01-01T04:36:39.053995",
    "key_data": [],
    "simple_summary": "\"吴恩达发布年度AI总结，附赠软件开发学习小贴士，引领技术发展新潮流。\"",
    "xhs_content": "🤖【2025新工业时代来临！】吴恩达AI年度总结大揭秘！还有软件开发小tips等你get✅\n\n💡 开年最期待的AI大事件终于来了！吴恩达的年度AI总结，带你洞悉行业趋势，探索数据背后的秘密。\n\n✅ 2025，新工业时代的标志，你准备好了吗？\n✅ 软件开发学习小tips，让你在AI浪潮中稳站潮头！\n\n💭 从这份总结中，我看到了AI技术的飞速发展，也感受到了数据的力量。不禁让我思考，未来的我们又将如何与AI共舞？\n\n🔍 数据告诉你：\n- 2025，这个数字不仅仅代表着新工业时代的到来，更是AI技术迈向成熟的关键节点。\n\n🎯 应用场景一览：\n- AI助手将成为我们生活、工作中的得力助手，帮助我们解决各种复杂问题。\n- 自动驾驶、智能家居、医疗健康……AI技术将渗透到我们生活的方方面面。\n\n🚀 行业趋势分析：\n- 人工智能正在颠覆传统行业，未来将会有更多跨界合作和创新出现。\n- 数据驱动将成为企业发展的核心竞争力，抓住数据，就是抓住未来。\n\n👇 互动时间：\n你对吴恩达的AI年度总结有什么看法？在软件学习中，你有什么独到的见解或小技巧？快来评论区分享吧！等你哟~💬\n\n#吴恩达AI总结 #新工业时代 #人工智能 #软件开发 #数据驱动 #行业趋势 #跨界创新 #学习小tips",
    "douyin_content": "【开头：悬念式（3秒）】\n画面：黑底白字，出现大字“揭秘2025...”，突然切换成吴恩达头像，配以文字“吴恩达AI年度总结，你准备好了吗？”\n字幕：#吴恩达AI总结 #新工业时代即将来临\nBGM：紧张刺激的背景音乐，如电子合成器的上升音阶。\n\n【中间：核心信息点（快速切换画面）】\n画面1：\n切换至吴恩达的演讲片段，快节奏剪辑。\n字幕：2025，新工业时代里程碑！\nBGM：音乐节奏加快，增加鼓点。\n\n画面2：\n视觉呈现代码滚动的动画，突出软件开发元素。\n字幕：开发小贴士大放送！\nBGM：音乐保持快节奏，添加键盘敲击声效。\n\n【结尾：提问互动】\n画面3：\n屏幕出现文字“你准备好迎接AI未来了吗？”同时下方出现互动按钮，“评论分享你的学习计划！”\n字幕：#AI未来 #学习计划\nBGM：音乐渐弱，突出人声。\n\n【整体建议】\n- 画面切换要迅速，每个画面停留2-3秒。\n- 字幕字体要大且清晰，颜色对比明显。\n- BGM要能营造出紧张和激动的氛围，与画面节奏同步。\n\n【标签建议】\n#吴恩达 #AI年度总结 #新工业时代 #软件开发 #学习小贴士 #科技未来 #抖音科普\n\n【脚本总结】\n这个脚本在短时间内通过紧凑的画面和字幕，以及互动提问的方式，不仅传递了科技新闻的核心信息，还增加了用户的参与感，有助于提高视频的传播和互动效果。",
    "zhihu_summary": "💡🎉 吴恩达大神年度AI总结新鲜出炉！快来看2025新工业时代，我们能get哪些技能点？🔥\n\n✅ 标题党都让开，这可是真正的AI圣经！吴恩达带我们回顾过去，展望未来，连软件开发的小tips都打包送你！\n\n✅ 2025年，新工业时代的大门已敞开，是时候拥抱AI，走在科技前沿！\n\n✅ 吴恩达不仅总结过去一年的AI发展，还贴心附上学习小贴士，让你在软件开发的道路上越走越顺！\n\n💭 说到这里，我忍不住感叹：时代在变，技术在进步，我们也要跟上步伐啊！🏃‍♂️\n\n👇 评论区聊聊，你对新工业时代有哪些期待？或者，你已经在AI领域取得了哪些成就？快来分享你的故事，一起学习，一起进步！🌟\n\n#吴恩达 #AI总结 #新工业时代 #软件开发 #学习小贴士\n#人工智能 #科技前沿 #技能提升 #未来发展\n#拥抱变化 #共同进步 #故事分享 #互动时刻",
    "processed_at": "2026-01-01 04:38:59",
    "ai_processed": true
  },
  {
    "title": "财大气粗的老黄继续出手！20多亿美金收购以色列AI初创公司",
    "summary": "属实把“收购式招聘”玩明白了",
    "raw_summary": "属实把“收购式招聘”玩明白了",
    "link": "https://www.qbitai.com/2025/12/366314.html",
    "source": "量子位",
    "published": "Wed, 31 Dec 2025 07:53:16 +0000",
    "category": "AI通用",
    "quality_score": 5,
    "collected_at": "2026-01-01T04:36:39.053999",
    "key_data": [],
    "simple_summary": "\"财力雄厚的老黄再度重拳出击，耗资二十多亿美元鲸吞以色列AI新贵公司。\"",
    "xhs_content": "🤖【大动作来袭！老黄狂砸20亿美金】💰 你没看错，这次他看上的，是来自以色列的AI初创公司！属实是 把收购式招聘玩明白了呀！✨\n\n✅ 一次性20多亿美金，这手笔可不是一般的大！\n✅ 以色列AI公司，这可是全球创新的摇篮！\n✅ 老黄这波操作，无疑又引领了行业的新趋势！\n\n💭 老黄这一步棋，不仅让人看到了他对AI领域的重视，更让人惊叹于他对未来科技的洞察力。想想看，以色列的AI技术一旦应用到我们日常生活中，那将带来多么翻天覆地的变化呀！🌟\n\n👇 互动时间到！你如何看待老黄这波操作？你期待这项AI技术带来哪些改变？快来评论区畅所欲言吧！👇\n\n#老黄20亿收购AI公司 #以色列AI创新 #行业新趋势 #未来科技 #AI改变生活",
    "douyin_content": "【脚本】\n\n【开头：悬念式】\n画面：一张神秘人物剪影，模糊中出现“财大气粗”的字样。\n字幕：猜猜看，老黄这次又出手了多少钱？\nBGM：悬疑音效，逐渐增强。\n\n【中间：核心信息点】\n画面1：快速切换至新闻报道截图，“20多亿美金”数字放大闪烁。\n字幕：20亿+美金！壕气收购AI新秀！\nBGM：快节奏电子音乐。\n\n画面2：以色列国旗与AI初创公司logo组合出现，配合动态效果。\n字幕：以色列的AI小巨人，被老黄相中！\n\n画面3：钱币符号与人才图标结合，形成“收购式招聘”的视觉元素。\n字幕：这波操作，是招聘还是收购？\n\n【结尾：提问互动】\n画面：出现一个大大的问号，引导用户参与讨论。\n字幕：你觉得老黄这次是赚了还是亏了？#科技大事件\nBGM：音乐渐弱，突出字幕。\n\n【标签建议】\n#科技新闻 #老黄出手 #AI初创公司 #巨额收购 #科技大事件\n\n【备注】\n- 字幕建议使用鲜明的颜色，如金色或红色，以突出重点信息。\n- BGM选择快节奏且具有科技感的音乐，以配合视频风格。",
    "zhihu_summary": "💡【震惊！老黄再放大招】20亿美金🔥收购以色列AI初创公司，这是要上天啊！🌟\n\n✅ 财大气粗，说的就是老黄吧！这波操作简直6到飞起，收购式招聘了解一下？\n✅ AI领域再掀巨浪！以色列的这家初创公司，究竟有何魅力，让老黄不惜砸下重金？\n✅ 20亿美金啊朋友们！这可不是小数目，看来人工智能的赛道上，又要杀出一匹黑马了！\n\n💭 分析这波操作，老黄这是看中了AI技术的无限潜力，未来应用场景肯定广阔到不行🚀。不仅强化了自己的技术实力，更是走在了行业前沿，引领潮流！\n\n👇 互动时间到！你觉得这次收购会给AI行业带来哪些影响？快来评论区畅所欲言吧！👀\n\n#老黄收购AI公司 #人工智能 #科技巨头 #行业趋势 #创新无止境",
    "processed_at": "2026-01-01 04:39:26",
    "ai_processed": true
  },
  {
    "title": "从「工具」到「搭档」，AI4S 走过深水区 | 2025年终回顾",
    "summary": "在这一轮波澜壮阔的人工智能浪潮中，我们常被算力、模型规模和颠覆式叙事所簇拥。然而，真正值得记录的变化，往往发生在那些远离喧嚣的实验室里、发生在一行行代码与科学假设的碰撞中：AI 是如何从一种“使能技术”，演变为改变人类推进科研的基本范式的？2025年，AI4Science（AI4S）不再仅仅是论文中的愿景。它正以一种极其务实且具体的姿态，嵌入到每一位科学家的日常。在这一年里，我们看到 AI4S 呈现出多维度的进化：它是高效的“科研加速器”： 从润色论文到整理会议纪要，从自动化数据处理到启发科学假设，正如吴琦教授与许东教授所言，AI 正在将科学家从低效的试错中解放，让他们重新聚焦于“创造性思维”本身。它是认知的“破局者”： 无论是 AlphaFold 3 的持续震撼，还是 Noetik 的虚拟细胞模型，AI 开始突破传统学科的藩篱。樊隽轩教授与张清鹏教授都观察到，当数据被转化为 AI 可理解的要素，两个独立领域被真正贯通，认知的“红利”正加速转化为科研的“生产力”。它是未来的“自主探索者”： 尽管如张晓峰教授所指，AI Scientist 尚处初级阶段，但“自动化发现”（Automati",
    "raw_summary": "<p>在这一轮波澜壮阔的人工智能浪潮中，我们常被算力、模型规模和颠覆式叙事所簇拥。然而，真正值得记录的变化，往往发生在那些远离喧嚣的实验室里、发生在一行行代码与科学假设的碰撞中：AI 是如何从一种“使能技术”，演变为改变人类推进科研的基本范式的？</p><p>2025年，AI4Science（AI4S）不再仅仅是论文中的愿景。它正以一种极其务实且具体的姿态，嵌入到每一位科学家的日常。</p><p>在这一年里，我们看到 AI4S 呈现出多维度的进化：</p><p>它是高效的“科研加速器”： 从润色论文到整理会议纪要，从自动化数据处理到启发科学假设，正如吴琦教授与许东教授所言，AI 正在将科学家从低效的试错中解放，让他们重新聚焦于“创造性思维”本身。</p><p>它是认知的“破局者”：&nbsp;无论是 AlphaFold 3 的持续震撼，还是 Noetik 的虚拟细胞模型，AI 开始突破传统学科的藩篱。樊隽轩教授与张清鹏教授都观察到，当数据被转化为 AI 可理解的要素，两个独立领域被真正贯通，认知的“红利”正加速转化为科研的“生产力”。</p><p>它是未来的“自主探索者”： 尽管如张晓峰教授所指，AI Scientist 尚处初级阶段，但“自动化发现”（Automation）已成为杜沅岂等年轻学者眼中的确定未来。</p><p>正如李国杰院士在寄语中所指出：AI4S 正在让思维本身成为可工程化的对象。如果说 2024 年是 AI 获得科学界最高荣誉诺贝尔奖的加冕礼，那么 2025 年则是 AI 深入科研的“现场记录”。</p><p>步入 2026 年，我们不仅关注模型能力的突破，更期待“AI 专家”与“学科专家”的深度共融，期待鄂维南院士所构想的“超级实验室”与开源共享生态的落地。</p><p>为此，雷峰网邀请了来自顶级高校及一线科研机构的多位AI 专家与学科专家，通过他们的亲历与洞察，还原一个真实、诚恳且充满可能性的 AI4S 2025。这不仅是一次年度总结，更是一份通往“未来科学发现新模式”的航海日志。</p><h2 style=\"text-align: center;\">寄语</h2><p>AI4S 是人类认知的一场革命，让思维本身成为可工程化的对象。未来 10 年内 AI4S 将不只是“科研辅助工具”，而是会逐步演变为科研的必要模式。AI4S 的核心价值是将人类从低效的试错过程中解放出来，专注于创造性思维。未来科学发现将呈现“AI 提出候选方案-人类判定科学意义-协同优化”的螺旋上升模式。</p><p>AI 的本质是达到预期目标的优化技术，目前的人工智能主要还是一种使能（enable）技术，重点应放在把“认知红利”转化为“生产力红利”上。在可预见的 10 年内，AI4S 的最大潜力是成为“爱迪生”而非“爱因斯坦”。AI4S 能否真正见到成效，要看从研发到应用全流程的总成本是否足够低。要让广大的科研人员都能使用人工智能技术，必须提供丰富且使用方便的智能软件工具，大幅度降低AI的使用门槛。</p><p>AI4S 最适合的区域并不是“纯基础科学”，而是靠近工程一侧的领域，这也是国务院《人工智能+》行动意见中将“AI +科学技术”列为首要任务的原因。从问题结构出发，当前“AI +科学技术”最具突破潜力的应用场景主要集中在两大类：第一类是产品开发过程本身高度接近科学发现的问题域，即产品性能依赖于对物质结构、机理或规律的探索与建模，如制药、先进材料与化学工业等；第二类是高度依赖多学科协同、系统级权衡与复杂约束优化的问题域，即单一学科难以主导整体性能的工业产品制造或工程系统，如半导体与汽车产业等。</p><p style=\"text-align: right;\">——李国杰 中国工程院院士</p><p style=\"text-align: right;\">2025.12.27</p><h2>科学家和研究者们眼中的AI4S</h2><p>这一年我最大的感受是：AI 真正成了我科研工作的“加速器”。在日常研究中，它已经深入到各个环节：论文撰写时帮我理清思路、润色语言；准备演讲稿和 PPT 时一起打磨结构、凝练要点；会议之后自动整理纪要和待办事项；做项目总结、年度汇报、甚至繁琐的邮件回复，都能生成高质量初稿，极大节省了时间与精力。这样我可以把更多注意力放在要研究的问题本身上。站在 AI4S 的角度，今年大模型和多模态技术的进展，让“AI 作为科研搭档”真正落地，从辅助阅读文献到参与数据分析与结果解释，再到文档撰写和PPT生成，都与我的研究紧密相关，也慢慢改变了我开展科学研究的方式与节奏。</p><p style=\"text-align: right;\">——吴琦 阿德莱德大学副教授&nbsp;</p><p><br /></p><p>以智能体为代表的 AI 在 2025 年已经全面、广泛深入到我们的教学、科研场景，对学生自学学习、教师的授课方式都带来巨大挑战。AI4S 在 2025 年取得较多进展如 AlphaFold 3 及基础科学大模型，这些进展都非常振奋人心，我更关注的是斯坦福提出来的一个小工作 AI Scientist，简单理解，它可以快速组织科研议题、讨论、达成一致来快速构建有意义的科学新尝试，这意味着未来的科研范式会开始出现较大变革，科研人员可以用 AI 来辅助，甚至在 AI 帮助下启发思路，从而能更聚焦创造性工作自身，这极大提升了科研效率。目前这一工作还较为初级，还有很多具体认知能力是不能简单依赖智能体或大模型来提升，比如无监督环境下的认知正确性，创造性思路如何能高效、准确产生，我相信这些问题会在明年看到部分答案。</p><p style=\"text-align: right;\">——张晓峰 哈尔滨工业大学（深圳）教授</p><p><br /></p><p>二十多年前，互联网与在线知识分享的兴起，极大地提升了人类获取知识的效率。而最近两三年大语言模型的出现，则彻底改变了知识的传播与获取方式，解答复杂问题，甚至跨领域联想，有望进一步拓展我们所能触及的知识深度。</p><p>2025 年尚未出现如 2024 年诺贝尔奖同时垂青AI领域研究那样的里程碑事件，但以 DeepSeek、Gemini 为代表的大模型持续迭代，正在潜移默化地改变科学研究的方法。不过，我印象最深的仍是 AlphaFold，真正的研究范式变革，仍需要时间的积累。</p><p>在我看来，AI4S 可分为三个层次：一是用 AI 替代传统分析方法；二是用 AI 大幅提升原有分析效率，但逻辑未变；三是像 AlphaFold 那样，将蛋白质数据转化为自然语言处理的要素，真正贯通两个独立领域。AI4S 的发展需要这三个层次共同推进，但研究范式的根本变革，最可能源于第三种。</p><p style=\"text-align: right;\">——樊隽轩 南京大学地球与行星科学系副主任&nbsp;</p><p><br /></p><p>Automation 代表 AI4S 的未来方向。相比较于提升计算方法，Automate open-world discovery 是一个完全开阔的领域，之前从来没办法做到的。所以如何做 Automation，做怎样程度的 Automation，以及如何验证，有非常多的机遇和挑战。</p><p style=\"text-align: right;\">——杜沅岂 康奈尔大学博士生、AI4S弄潮儿&nbsp;</p><p><br /></p><p>对我来说，最大的改变是学习效率的提升。AI 帮助我快速梳理已有知识，构建系统化认知，过去需要花大量时间整理的内容，现在可以高效完成。今年最值得关注的不是多模态大模型本身，因为它更多是高质量数据驱动下的工程性演进，而非理论突破。我更看重 Science for AI 的理论进展，尤其是复杂系统理论在解释大模型行为方面的探索，以及智能涌现背后的物理规律。这些研究尝试用统计物理、网络科学和相变理论来刻画大模型的能力边界，解释为什么在参数规模和数据分布达到某个临界点时，会出现“涌现”现象。这类工作不仅提升了模型的可解释性，也为未来的架构设计和资源分配提供了理论依据，对推动可信 AI 和科学驱动的智能发展意义重大。</p><p>2025年最让我印象深刻的是“虚拟细胞”技术的突破。 通过多模态AI构建个体细胞以及肿瘤微环境的虚拟模型，实现了对细胞行为的精准模拟。这不仅突破了传统实验的局限，也让我们可以在虚拟空间中探索药物作用机制和患者差异，推动精准治疗和免疫疗法的发展。</p><p>展望2026年，我认为关键方向将是理论与应用的深度融合。一方面，复杂系统理论和智能涌现规律将继续指导模型设计和解释；另一方面，这类“生命系统世界模型”将逐渐成为科研的核心基础设施，结合真实世界的多模态数据，开启“虚拟实验室”时代，加速药物研发和个性化医疗。</p><p style=\"text-align: right;\">——张清鹏 香港大学数据科学研究院和药理药学系副教授</p><p><br /></p><p>过去一年，以 DeepSeek 的问世开局，全球人工智能发展格局发生了深刻变化。无论是技术路径还是应用场景，都呈现出前所未有的演进态势。对个人而言，AI 已深度渗透科研与生活的方方面面，从知识获取、整合到更新，全方位提升效率，大幅缩短科学发现周期，成为不可或缺的助手。但这一切，仅仅是伟大变革的序幕——未来，AI 将从日常工作、社会生活，延伸至生命健康乃至国家安全，引发结构性的深刻革命。与此同时，我们也看到，AI 发展正面临两大核心技术挑战：能耗问题与通用智能问题。唯有在这两个问题上取得根本性突破，AI 才能真正走向普惠，全面深度融入人类生活。</p><p style=\"text-align: right;\">——黄典 广东省智能科学与技术研究院副研究员</p><p><br /></p><p>2025年从Deep Research工程化角度看已经有了很好的基础；2026年随着模型科学能力的进一步提升，AI4S在数学、物理、化学、生命科学和材料科学等领域会全面开展并推动关键场景的突破性成果。</p><p style=\"text-align: right;\">——薛贵荣 之江实验室科学模型总体部技术总师&nbsp;</p><p><br /></p><p>对我而言，AI 最直接、最显著的改变是极大地提升了科研与管理工作的效率。在我们的课题组，AI 在编程辅助、科研流程自动化以及各类 AI 辅助科研平台中的应用，使整体研发效率至少提升了 20%。作为教授，我每年需要为数十人写推荐信、评估材料等，另外还有大量的邮件和学术文档。现在，我可以通过口述将自己的想法直接交给 ChatGPT 进行结构化整理，我再修改，内容完全来自我本人，但写作与编辑时间大幅缩短。此外，在论文写作方面，AI 显著减轻了语言和语法层面的负担，尤其对国际学生帮助很大，使他们能将更多精力投入到科学问题本身，也大大节省了我修改论文的时间。</p><p>2025 年给我留下最深刻印象的是以 Gemini 为代表的一系列进展，包括自动实验室、AlphaEvolve 等通用算法体系。即使仅从用 Gemini 本身来辅助提出假设、拓展科研人员思路的角度来看，这类系统已经展现出非常突出的价值。</p><p>展望 2026 年，我认为 AI4S 的关键发展方向将不再只是模型能力的单点突破，而是 AI 与各学科领域专家（Domain Scientists）的深度融合。目前，这种融合仍然明显不足：懂 AI 的研究者往往对具体应用领域理解有限，而具备深厚科学背景的研究者又未必熟悉 AI 方法。真正将这两类能力紧密结合，形成长期协同的研究模式，可能会带来远超单独技术进步的科学突破。</p><p style=\"text-align: right;\">——许东 密苏里大学电子工程和计算机科学系校董讲座教授</p><p><br /></p><p>AI对我日常最大的影响是文字材料处理更方便了，尤其是一些不重要的文字材料，AI能写的很好，其次是一些娱乐向的内容比如生成一些有趣的图片，PPT目前完全依赖AI还很难，这其实符合AI发展趋势，先语言单模态到多模态应用。</p><p>我个人觉得2025年整体上AI4S并没有革命性突破的工作，一些有特色和亮点的工作有：MatterGen、RFDiffusion2、AlphaEvolve、MAGE以及一些AI全自动科学实验平台等。2026年AI4S方向我保持着谨慎的乐观态度，我希望AI4S应该要从“AI读论文/做预测与分析”（Predictive AI）跨越到“AI做实验/搞发现”，目前的 AI4S 主要是“Copilot”模式（科学家想好idea，AI帮忙写代码、预测结构）。</p><p>我理想中的AI4S科学家应该是：自主提出假设到实验设计与规划，再工具调用或控制科学实验的物理设备，最后自我反思，比如实验失败后，AI 能像人类博士生一样分析“为什么失败”，修正假设并开启下一轮迭代，而不是只会报错。这条路还很漫长，链路中间需要解决的问题还非常多，道阻且长，谨慎乐观。</p><p style=\"text-align: right;\">——袁粒 北京大学科学智能学院助理教授</p><p><br /></p><p>AI 的引入显著改变了我的科研思维范式和工作方式。一方面，它从“工具”升级为科研合作者，帮助我更快地梳理问题、验证思路和探索设计空间；另一方面，大幅提升了文献阅读、方案推演和材料撰写的效率，使我能够将更多精力投入到核心科学问题和创新方向上。</p><p>在我看来，AI4S 最具代表性的标志性事件，是近一年多来诺贝尔物理学奖和化学奖都与 AI 深度相关，这在学术层面清晰地表明：AI 已经从工具层面上升为推动基础科学突破的核心方法之一。与我所在的计算机体系结构领域最为相关的是，AI4S 的快速发展对算力、能效和系统可靠性提出了前所未有的要求，使计算机体系结构从“性能支撑角色”转变为“科学发现基础设施”。</p><p>给我留下最深刻印象的是 DeepSeek 的相关工作，它表明模型层面的原创性创新本身就具有“破局能力”，在一定程度上可以突破算力与硬件受限所带来的瓶颈，这对当前 AI4S 的发展具有重要启示意义。展望 2026 年，我认为 AI4S 的关键发展方向将不再局限于单点模型或算法突破，而是走向科研全流程的开源化与共享化，包括数据、模型、工具链和实验流程的协同演进。这一趋势与鄂维南院士提出的“超级实验室”理念高度契合，有望通过开放、协作和规模化智能系统，显著提升科学发现的效率与可复现性。</p><p style=\"text-align: right;\">——冷静文 上海交通大学计算机学院教授</p><p><br /></p><p>对我个人最直接的改变，是把高频但琐碎的事情自动化了。比如以前我会用 Notion 记录大量日程，每个月做一次复盘：这个月做了什么、推进到哪、有哪些产出。现在有了CodeX配合MCP之后，可以自动生成周度、月度、年度复盘与科研进度追踪，减少很多手工整理的成本。其他的事情也是一样。</p><p>我认为 2025 年 AI4S 里最关键的进展，其实是评测与机制开始变得更可落地。因为科学发现本身非常难评估：novelty、影响力、长期价值都不是简单指标能覆盖的。今年一个标志性的趋势是：我们开始看到AI 产出的论文/研究能进入更真实的评审与传播流程，例如出现了更面向 AI 投稿、AI 审稿的会议与流程，甚至在部分方向上，AI 独立完成的工作能够被人类 reviewer 认可并接受。 &nbsp;从我做 agent 的视角看，另一个非常重要的点是动作空间（action space）：当你给 agent 足够可接入的工具与环境时，它才能真正闭环地做 research。比如在计算机领域，只要能接到计算资源与软件工具链，AI 更容易端到端产出可验证结果；但在生物、化学等依赖湿实验的领域，如果没有可被 AI 直接操控的实验动作空间（或足够强的具身/自动化实验平台接口），端到端的独立科研就仍然很难成立。</p><p>最让我印象深刻的是24年 AI Scientist 最开始的工作，实现了端到端的论文生成，之前没有想过这个场景。 &nbsp;至于关键方向，可能会在两个事情上： 更好的评测：从“刷静态任务分数”走向更能衡量发现能力、novelty 与长期贡献的评价框架； &nbsp;扩展动作空间：把更多学科的研究流程工程化、接口化，形成可被 agent 直接调用的标准 pipeline——尤其是在生物等领域，通过自动化实验平台或标准化流程，让 agent 能更直接参与实验与验证，从而真正推动跨学科的闭环科研。</p><p style=\"text-align: right;\">——张佳钇 香港科技大学（广州）博士</p><p><br /></p><p>AI最直观的改变是科研提效，基金申报、论文润色等日常工作能节省不少时间；但AI领域迭代太快，“学的赶不上发的”，难免有焦虑，也迫使自己思考如何平衡热点跟风与自身核心方向深耕；此外，AI带来的信息变多，甄别有效信息成为一项关键的挑战。</p><p style=\"text-align: right;\">——周博宇 南方科技大学机械与能源工程系助理教授</p>",
    "link": "https://www.leiphone.com/category/yanxishe/HWP4OEEqOExyNzia.html",
    "source": "雷锋网",
    "published": "Wed, 31 Dec 2025 18:21:00 +0800",
    "category": "AI通用",
    "quality_score": 3,
    "collected_at": "2026-01-01T04:36:39.054004",
    "key_data": [],
    "simple_summary": "\"AI4S跨越工具阶段，成长为科研探索的深度搭档。\"",
    "xhs_content": "🤖【2025年终回顾】AI4S进化论：从工具到最佳拍档，揭秘科研新境界！✨\n\n✅AI4S，一个曾藏在论文中的梦想，如今已走进我们的生活，成为科学探索的得力助手！2025年的今天，它给我们带来了哪些惊喜呢？\n\n- 高效科研加速器：🚀告别繁琐的数据处理，AI助你聚焦创新！从论文润色到会议纪要，一键搞定！科学家吴琦、许东都说，这是解放创造力的开始！\n\n- 认知破局者：🌟AlphaFold 3、Noetik虚拟细胞模型，AI跨学科突破，让数据成为串联不同领域的桥梁，助力科研生产力爆发！\n\n- 自主探索者：🔍虽然AI Scientist还处于起步阶段，但自动化发现已初露锋芒，未来可期！\n\n💭个人觉得，AI4S的发展真是让人激动不已！曾经遥远的科幻，如今正成为现实。想象一下，在不久的将来，我们或许能借助AI探索更多未知领域，破解生命奥秘！\n\n👇快来评论区分享你的看法吧！你觉得AI4S还将带来哪些变革？让我们一起期待！\n\n#AI4S #科研助手 #人工智能 #自动化发现 #科学探索 #未来已来 #科技创新 #科研生产力 #跨学科突破 #高效科研 #数据驱动 #AlphaFold3 #Noetik虚拟细胞 #自动化数据处理 #吴琦 #许东 #樊隽轩 #张清鹏 #张晓峰",
    "douyin_content": "【开头】\n画面：黑幕，逐字出现巨大白色数字“2025”，随后快速切换至实验室内部，科学家正与电脑屏幕前的AI进行交流。\n字幕：#2025科技大跃进 #AI变搭档\nBGM：选用紧张刺激的电子音乐，营造未来科技感。\n\n【中间】\n画面1：\n快速切换显示科学家从繁琐工作中解放出来，聚焦于创意思考的场景。\n字幕：AI助力，科研加速！\nBGM：节奏加快，凸显科技变革的迅猛。\n\n画面2：\n展示AlphaFold 3和Noetik虚拟细胞模型的震撼画面，配合光影特效。\n字幕：认知破局，学科融合！\n\n画面3：\nAI界面在黑暗中发射出探索的光束，显示自动化发现的未来感图像。\n字幕：自主探索，未来已来！\n\n【结尾】\n画面：科学家向镜头举起手中的数据板，上面显示“AI4S”字样，画面逐渐变为提问的形式。\n字幕：你觉得AI会成为科学研究的未来吗？\nBGM：音乐逐渐降低音量，突出提问的互动性。\n\n【标签建议】\n#AI4Science #科研新范式 #自动化探索 #未来科技 #人工智能 #抖音科普\n\n【整体脚本】\n（黑幕，数字“2025”出现）\n#2025科技大跃进 #AI变搭档\n（切换至实验室，科学家与AI互动）\nAI助力，科研加速！\n（快速切换：科学家创意思考）\n认知破局，学科融合！\n（展示AI成果，特效）\n自主探索，未来已来！\n（科学家举起数据板，提出互动问题）\n你觉得AI会成为科学研究的未来吗？\n#AI4Science #科研新范式 #自动化探索 #未来科技 #人工智能 #抖音科普\n（结束）",
    "zhihu_summary": "💡AI大变身！从工具晋升为最佳搭档，2025年终盘点来啦！🎉\n\n✅AI4S，科研加速器的超级进化\n2025，AI不再只是论文里的美好愿景，它已经实打实地成为科学家们的得力助手！从论文润色到数据处理，从会议纪要整理到科学假设启发，AI让科研变得更加高效。科学家们终于可以从繁琐的试错中解脱出来，集中精力搞创新啦！🔥\n\n✅认知破局者，学科壁垒不再\nAlphaFold 3、Noetik虚拟细胞模型，AI正在打破传统学科的边界。当数据被转化为AI理解的元素，两个独立领域完美融合，认知红利飞速转化为科研生产力。💫\n\n✅未来自主探索者，AI Scientist初露锋芒\n虽然AI Scientist还处于初级阶段，但自动化发现已经让人眼前一亮。未来的科研，AI或将成为自主探索的领航者。🚀\n\n💭看到AI的这些突破，我不禁想大胆预测：或许在不远的将来，AI将成为我们科研生活中的“标配”。而这一切，都离不开科学家们不懈的努力和敢于创新的精神。那么，你对AI在科研领域的未来发展有什么期待呢？\n\n👇快来评论区告诉我吧！让我们一起期待AI带给我们的更多惊喜！🎁\n\n#AI进化论 #科研新势力 #认知破局者 #自主探索者 #未来可期",
    "processed_at": "2026-01-01 04:40:03",
    "ai_processed": true
  },
  {
    "title": "清华赵昊最新力作：0.4 秒完成4D高斯重建，自驾仿真新SOTA丨GAIR 2025",
    "summary": "雷峰网讯 从工厂、矿区的封闭路段到更加开放的世界，自动驾驶技术面临着来自真实交通环境的多重挑战。变道超车的车辆、突然打开的车门、横穿马路的行人……当自动驾驶系统学着给这些动态对象进行4D建模、重建和再仿真时，大多数解决方案仍然依赖于每场景优化、已知的相机校准或短帧窗口，这使得它们变得缓慢且不实用。能否快速、低成本获得动态驾驶场景下的仿真数据，决定了自动驾驶系统在开放世界中的进化速度。在这一背景下，长期深耕神经渲染与仿真技术的赵昊老师团队，提出了首个面向大型动态驾驶场景的无姿态（pose-free) 前馈三维重建框架——DGGT（Driving Gaussian Grounded Transformer）。赵昊现任清华大学智能产业研究院（AIR）助理教授，智源学者（BAAI Scholar）。他的研究聚焦计算机视觉领域，在三维场景理解、生成式仿真与神经渲染等方向深耕多年，研究成果对于自动驾驶及具身智能仿真具有重要意义。值得关注的是，赵昊老师将以组委会主席的身份，出席2025年GAIR全球人工智能与机器人大会，并主持世界模型分论坛，分享他在世界模型方面的最新探索。GAIR大会聚焦人工智能的",
    "raw_summary": "<p>雷峰网讯 从工厂、矿区的封闭路段到更加开放的世界，自动驾驶技术面临着来自真实交通环境的多重挑战。变道超车的车辆、突然打开的车门、横穿马路的行人……当自动驾驶系统学着给这些动态对象进行4D建模、重建和再仿真时，大多数解决方案仍然依赖于每场景优化、已知的相机校准或短帧窗口，这使得它们变得缓慢且不实用。</p><p>能否快速、低成本获得动态驾驶场景下的仿真数据，决定了自动驾驶系统在开放世界中的进化速度。在这一背景下，长期深耕神经渲染与仿真技术的赵昊老师团队，提出了首个面向大型动态驾驶场景的无姿态（pose-free) 前馈三维重建框架——DGGT（Driving Gaussian Grounded Transformer）。</p><p>赵昊现任清华大学智能产业研究院（AIR）助理教授，智源学者（BAAI Scholar）。他的研究聚焦计算机视觉领域，在三维场景理解、生成式仿真与神经渲染等方向深耕多年，研究成果对于自动驾驶及具身智能仿真具有重要意义。</p><p>值得关注的是，赵昊老师将以组委会主席的身份，出席2025年GAIR全球人工智能与机器人大会，并主持世界模型分论坛，分享他在世界模型方面的最新探索。</p><p>GAIR大会聚焦人工智能的核心技术、前沿趋势与产业落地，长期吸引来自全球的技术领袖和科研人士。本届大会将于2025年12月12-13日在深圳·博林天瑞喜来登酒店举行，与产业界和学术界的嘉宾共同研讨人工智能的下一步发展。</p><p style=\"text-align: center;\"><img src=\"https://static.leiphone.com/uploads/new/images/20251231/6954e8282af12.png?imageView2/2/w/740\" /></p><p>论文地址：&nbsp;https://arxiv.org/abs/2512.03004</p><p><strong>01自动驾驶仿真新 SOTA</strong></p><p>DGGT最大的突破，是摆脱了传统方案对逐场景优化、相机标定以及短帧窗口的依赖。通过多头联合预测结构，DGGT只需稀疏、无标定图像，单次前向即可同时输出相机位姿、深度、动态实例与场景表示，重建长序列三维场景。</p><p>且该场景表示可直接在Gaussian层面进行编辑，如移除或移动车辆，插入其他场景的新汽车或骑行者等实例。DGGT的高度可编辑性支持扩散精修自动补洞，输出可用于仿真与数据合成。</p><p>实验结果表明，DGGT在Waymo上达到了 27.41 PSNR，每场景推断 0.39 秒（3 个视角，20 帧），超过了作为优化基线的EmerNeRF、DeformableGS方案和前馈方法，同时保持了速度竞争力。换言之，DGGT比优化类方案更迅速，比前馈方案更保真。</p><p>同样令人惊喜的还有泛化性。DGGT将相机位姿从输入转为模型输出，通过端到端预测内外参并融入场景表示的方法，打破了跨数据集部署的校准壁垒。DGGT模型在 Waymo 上训练，却能在 nuScenes 与 Argoverse2 上实现强劲的零样本泛化，在关键感知指标上相比STORM提升超过50%。如在nuScenes上LPIPS从0.394降至0.152（下降 61.4%），在 Argoverse2上从0.326降至0.155（下降52.5%）。</p><p>值得注意的是，研究团队在nuScenes 和 Argoverse2 数据集上分别进行了零样本和从头训练两种设置的实验评估。在这两种情况下，DGGT均表现出了SOTA级性能。</p><p>此外，系统通过lifespan head建模场景随时间的外观演变，并配合单步扩散精修，可有效抑制运动插值伪影，提升时空一致性与渲染自然度。在保证仿真质量的前提下，DGGT为自动驾驶仿真推开了一扇迈向高速、可扩展新阶段的大门。</p><p><strong>02一次前向，完整 4D 场景</strong></p><p>DGGT的核心设计理念，是一次性预测完整的4D场景状态，同时清晰地将静态背景与动态实体分离，并保持时间上的连贯性。</p><p>具体来说，研究团队将相机位姿从输入转为模型输出，每帧生成像素对齐的高斯映射，并添加一个寿命参数，随时间调制可见性以捕捉变化的外观，随后使用动态头生成密集动态映射，使用运动头估计三维运动，用于稀疏时间戳间插值，同时插入单步扩散细化，抑制重影/遮蔽伪影并恢复细节。</p><p>这产生了单遍、无姿态的算法，能够从未摆拍图像重建动态驱动场景，自然支持高斯层级的实例级编辑。</p><p>在系统结构上，DGGT 采用 ViT 编码器融合 DINO 先验，通过交替注意力得到共享特征，再由多个预测头并行输出：</p><p>相机头估计每一帧内外参数；</p><p>Gaussian 头给出逐像素颜色/位置/旋转/尺度/不透明度参数；</p><p>lifespan 头控制时间可见度；</p><p>动态头输出运动遮罩；</p><p>运动头显式估计动态物体的三维位移；</p><p>天空头稳定建模远景背景。</p><p><strong>03动态驾驶场景仿真新路径</strong></p><p>长期以来，高精度标定设备和固定路线采集方案，一直限制着动态驾驶场景训练数据的成本和采集效率，DGGT则提出了一种规避上述限制的全新方案。</p><p>将相机位姿转为模型输出的设计使DGGT具有了在真实、开放世界中的高度灵活性，同时其多头联合预测结构支持任意数量的输入视图和长序列处理，克服了现有前馈方法在时序扩展性上的瓶颈，为处理大规模自动驾驶日志提供了可行路径。</p><p>更可贵的是，DGGT能在Waymo、nuScenes等大规模数据集上实现SOTA级重建质量的同时，仍然保持亚秒级的推理速度。这种既快又好的特性，平衡满足了工业界对速度与质量的双重需求，使其具有作为实时的预处理模块，集成到自动驾驶系统的训练、仿真与评估流程中的潜力。</p><p>总体来看，0.4秒即可完成支持实例级编辑的4D重建，速度与质量兼顾的动态场景建模，以及对跨数据集泛化瓶颈的突破，无一不意味着低成本生成动态驾驶场景训练数据的新范式，已经距离我们更近一步。</p><p>雷峰网文章</p><p><br /></p>",
    "link": "https://www.leiphone.com/category/industrynews/SYAGG5WQ7Kt3C0SE.html",
    "source": "雷锋网",
    "published": "Wed, 31 Dec 2025 17:10:00 +0800",
    "category": "AI通用",
    "quality_score": 3,
    "collected_at": "2026-01-01T04:36:39.054008",
    "key_data": [],
    "simple_summary": "\"赵昊团队在GAIR 2025上展示0.4秒内实现4D高斯重建的自驾仿真新突破性技术。\"",
    "xhs_content": "🤖【04秒，打开自动驾驶新世界大门！】你敢信？清华赵昊老师团队的新作——DGGT框架，仅需04秒就能完成4D高斯重建，自驾仿真迎来新SOTA！🚗✅\n\n✅ 说起这个DGGT框架，它可是一举解决了自动驾驶在开放世界中的难题，无论是变道超车的车辆，还是突然打开的车门，甚至是横穿马路的行人，它都能快速、低成本地进行仿真数据获取。\n\n✅ 这意味着，自动驾驶系统在应对真实交通环境的多重挑战时，可以更快地学习和进化。😎\n\n💭 我觉得这项技术真是太酷了！想想看，未来我们的自动驾驶汽车将能更好地适应各种复杂路况，出行安全大大提升。🚀\n\n👇 话说回来，你们觉得自动驾驶技术的发展会带来哪些生活上的改变呢？快来评论区聊聊吧！👀\n\n#自动驾驶 #4D高斯重建 #DGGT框架 #清华赵昊 #GAIR2025 #科技改变生活 #未来出行 #智能仿真 #计算机视觉 #科技创新 #自动驾驶新SOTA",
    "douyin_content": "【开头：悬念式】\n（BGM建议：动感电子音乐开始，画面为繁忙的城市交通，突然切换到一辆自动驾驶汽车）\n画面：0-3秒\n字幕：“当自动驾驶遇到‘真实世界’，会发生什么？”\n\n【中间：核心信息点】\n（画面快速切换，展示技术突破关键点）\n画面：3-10秒\n字幕：“3…2…1…启动！清华赵昊团队力作，DGGT技术，04秒完成4D高斯重建！”\n（画面展示动态驾驶场景，配合重建动画）\n\n画面：10-15秒\n字幕：“#GAIR2025 #自动驾驶新SOTA 突破限制，驶向开放世界！”\n\n【结尾：提问互动】\n画面：15-20秒\n字幕：“这样的未来，你期待吗？评论留下你的想法！#自动驾驶未来 #赵昊GAIR2025”\n\n画面：20-25秒\n（BGM逐渐降低音量）\n字幕：“赵昊老师还将主持世界模型分论坛，更多黑科技，等你来发现！”\n\n【结尾：标签与呼吁关注】\n画面：25-30秒\n（BGM渐弱，显示相关标签与呼吁关注的话）\n字幕：“关注我们，不错过每一次科技革新！#科技改变生活 #智源学者”\n\n（视频结束，BGM停止）\n\n【备注】\n- 视频全程建议使用动态效果、过渡效果以增加视觉冲击力。\n- 字幕建议使用鲜明的颜色，便于观看者识别。\n- 互动性问题可以增加视频的参与度，提高传播效果。",
    "zhihu_summary": "💡🚗【04秒，你能做什么？清华赵昊团队刷新自动驾驶仿真速度！】🌟\n\n✅ 04秒，一杯咖啡还未冷却，而清华赵昊团队已实现4D高斯重建，自驾仿真新SOTA！\n✅ 动态驾驶场景，不再惧怕！无姿态三维重建框架DGGT助力自动驾驶系统快速进化！\n✅ 大型动态场景，低成本获得仿真数据，自动驾驶技术迈向开放世界！🌏\n\n💭 在这个速度决定一切的时代，赵昊老师团队的研究无疑是给自动驾驶行业注入了一剂强心针。想象一下，未来的自动驾驶车辆在各种复杂环境中游刃有余，这背后的技术支持，正是我们现在看到的DGGT框架。\n\n👇 互动时间到！你对自动驾驶技术的发展怎么看？你认为04秒完成4D高斯重建将带来哪些变革？快来评论区分享你的观点吧！👀\n\n#自动驾驶 #4D高斯重建 #清华赵昊 #DGGT #GAIR2025 #智能仿真 #科技前沿 #未来出行 #自动驾驶技术 #数据驱动\n\n标签：#自动驾驶技术 #4D高斯重建 #神经渲染 #动态驾驶场景 #赵昊 #清华大学 #GAIR大会 #具身智能 #世界模型 #科技突破",
    "processed_at": "2026-01-01 04:40:36",
    "ai_processed": true
  }
]