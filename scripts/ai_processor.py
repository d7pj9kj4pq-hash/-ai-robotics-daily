#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå¤„ç†è„šæœ¬ - ä¼˜åŒ–ç‰ˆï¼ˆæ”¯æŒå¤šå¹³å°æ ¼å¼ï¼‰
"""

import os
import json
import requests
import re
from datetime import datetime

class AIProcessor:
    def __init__(self):
        self.api_key = os.getenv('ZHIPU_API_KEY')
        self.base_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        
        # ä¸åŒå¹³å°çš„å†…å®¹æ¨¡æ¿
        self.platform_templates = {
            'xiaohongshu': {
                'emoji_prefix': 'ğŸ¤–',
                'hashtags': ['#AIæ—¥æŠ¥', '#ç§‘æŠ€å‰æ²¿', '#äººå·¥æ™ºèƒ½', '#é»‘ç§‘æŠ€'],
                'max_length': 600
            },
            'douyin': {
                'emoji_prefix': 'ğŸ”¥',
                'hashtags': ['#AI', '#ç§‘æŠ€', '#äººå·¥æ™ºèƒ½', '#çŸ¥è¯†åˆ†äº«'],
                'max_length': 200
            },
            'zhihu': {
                'emoji_prefix': 'ğŸ’¡',
                'hashtags': [],
                'max_length': 1000
            }
        }
    
    def _clean_text_for_ai(self, text):
        """ä¸ºAIå¤„ç†æ¸…ç†æ–‡æœ¬"""
        if not text:
            return ""
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ä½†ä¿ç•™ä¸­æ–‡æ ‡ç‚¹
        text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\sï¼Œã€‚ï¼ï¼Ÿã€ï¼šï¼›ï¼ˆï¼‰ã€Šã€‹ã€ã€‘ã€Œã€""''-]', '', text)
        
        # æˆªæ–­åˆ°åˆç†é•¿åº¦
        return text[:1000].strip()
    
    def _create_ai_prompt(self, news_item, platform='xiaohongshu'):
        """åˆ›å»ºAIæç¤ºè¯"""
        title = news_item.get('title', '')
        summary = news_item.get('summary', '')
        source = news_item.get('source', '')
        
        # æ¸…ç†æ–‡æœ¬
        clean_title = self._clean_text_for_ai(title)
        clean_summary = self._clean_text_for_ai(summary)
        
        platform_config = self.platform_templates.get(platform, self.platform_templates['xiaohongshu'])
        
        prompt_templates = {
            'xiaohongshu': f"""è¯·å°†ä»¥ä¸‹ç§‘æŠ€æ–°é—»è½¬åŒ–ä¸ºå°çº¢ä¹¦é£æ ¼çš„æ–‡æ¡ˆï¼š

ã€åŸæ–‡ä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{clean_title}
æ¥æºï¼š{source}
æ‘˜è¦ï¼š{clean_summary}

ã€å…·ä½“è¦æ±‚ã€‘
1. è¯­è¨€é£æ ¼ï¼šæ´»æ³¼ã€äº²åˆ‡ã€æœ‰ç½‘æ„Ÿï¼Œä½¿ç”¨emojiç‚¹ç¼€
2. ç»“æ„ï¼š
   - å¼€å¤´ç”¨å¸å¼•çœ¼çƒçš„å¥å­ï¼ˆå¸¦{platform_config['emoji_prefix']}emojiï¼‰
   - åˆ†ç‚¹åˆ—å‡ºæ ¸å¿ƒäº®ç‚¹ï¼ˆç”¨âœ…å›¾æ ‡ï¼‰
   - åˆ†äº«ä¸ªäººçœ‹æ³•æˆ–å¯å‘ï¼ˆç”¨ğŸ’­emojiï¼‰
   - ç»“å°¾å¼•å¯¼äº’åŠ¨ï¼ˆç”¨ğŸ‘‡emojiï¼‰
3. å†…å®¹è¦ç‚¹ï¼š
   - çªå‡ºæ•°æ®ï¼ˆå¦‚æœ‰æ•°å­—è¦å¼ºè°ƒï¼‰
   - è¯´æ˜åº”ç”¨åœºæ™¯
   - åˆ†æè¡Œä¸šè¶‹åŠ¿
4. é•¿åº¦ï¼š{platform_config['max_length']}å­—ä»¥å†…
5. æ ‡ç­¾ï¼šè‡ªåŠ¨ç”Ÿæˆ3-5ä¸ªç›¸å…³è¯é¢˜æ ‡ç­¾

è¯·ç›´æ¥è¾“å‡ºæ–‡æ¡ˆå†…å®¹ï¼Œä¸è¦åŠ ä»»ä½•è§£é‡Šã€‚""",
            
            'douyin': f"""è¯·å°†ä»¥ä¸‹ç§‘æŠ€æ–°é—»è½¬åŒ–ä¸ºæŠ–éŸ³çŸ­è§†é¢‘è„šæœ¬ï¼š

ã€åŸæ–‡ä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{clean_title}
æ‘˜è¦ï¼š{clean_summary}

ã€è„šæœ¬è¦æ±‚ã€‘
1. æ—¶é•¿ï¼š15-30ç§’çŸ­è§†é¢‘
2. ç»“æ„ï¼š
   - å¼€å¤´ï¼šæ‚¬å¿µå¼ï¼ˆ3ç§’å¸å¼•æ³¨æ„åŠ›ï¼‰
   - ä¸­é—´ï¼šæ ¸å¿ƒä¿¡æ¯ç‚¹ï¼ˆå¿«é€Ÿåˆ‡æ¢ç”»é¢ï¼‰
   - ç»“å°¾ï¼šæé—®äº’åŠ¨
3. é£æ ¼ï¼šèŠ‚å¥å¿«ã€ä¿¡æ¯å¯†é›†ã€æœ‰è®°å¿†ç‚¹
4. åŒ…å«ï¼šç”»é¢å¯¹åº”æè¿°ã€å­—å¹•å»ºè®®ã€BGMå»ºè®®
5. æ ‡ç­¾ï¼šæ¨èçƒ­é—¨è¯é¢˜æ ‡ç­¾

è¯·è¾“å‡ºå®Œæ•´è„šæœ¬ã€‚"""
        }
        
        return prompt_templates.get(platform, prompt_templates['xiaohongshu'])
    
    def _extract_key_data(self, text):
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®æ•°æ®"""
        data_points = []
        
        # æŸ¥æ‰¾æ•°å­—+å•ä½
        patterns = [
            r'(\d+\.?\d*)\s*äº¿',
            r'(\d+\.?\d*)\s*ä¸‡',
            r'(\d+\.?\d*)\s*%',
            r'(\d+)\s*ä¸ª',
            r'(\d+)\s*ä½',
            r'å¢é•¿\s*(\d+\.?\d*)\s*%',
            r'çªç ´\s*(\d+)',
            r'è¾¾åˆ°\s*(\d+)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text)
            data_points.extend(matches)
        
        return data_points[:5]  # è¿”å›å‰5ä¸ªæ•°æ®ç‚¹
    
    def call_glm_api(self, prompt, max_tokens=800):
        """è°ƒç”¨æ™ºè°±GLM API"""
        if not self.api_key:
            print("âš ï¸ è­¦å‘Šï¼šæœªè®¾ç½®ZHIPU_API_KEYï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return "è¿™æ˜¯æ¨¡æ‹Ÿçš„AIç”Ÿæˆå†…å®¹ã€‚è¯·è®¾ç½®ZHIPU_API_KEYè·å–çœŸå®AIå¤„ç†ç»“æœã€‚"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "glm-4",
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.7,
            "max_tokens": max_tokens,
            "top_p": 0.9
        }
        
        try:
            print(f"è°ƒç”¨AI APIï¼Œprompté•¿åº¦: {len(prompt)}")
            response = requests.post(self.base_url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
                return None
                
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def process_news_item(self, news_item):
        """å¤„ç†å•æ¡æ–°é—»"""
        print(f"å¤„ç†: {news_item.get('title', '')[:50]}...")
        
        # æå–å…³é”®æ•°æ®
        key_data = self._extract_key_data(news_item.get('summary', ''))
        
        # ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ
        xhs_prompt = self._create_ai_prompt(news_item, 'xiaohongshu')
        xhs_content = self.call_glm_api(xhs_prompt, 600)
        
        # ç”ŸæˆæŠ–éŸ³è„šæœ¬
        dy_prompt = self._create_ai_prompt(news_item, 'douyin')
        dy_content = self.call_glm_api(dy_prompt, 400)
        
        # ç”ŸæˆçŸ¥ä¹é£æ ¼æ‘˜è¦
        zh_prompt = self._create_ai_prompt(news_item, 'zhihu')
        zh_content = self.call_glm_api(zh_prompt, 300)
        
        # ç”Ÿæˆç®€å•æ‘˜è¦ï¼ˆå¤‡ç”¨ï¼‰
        simple_prompt = f"ç”¨ä¸€å¥è¯æ€»ç»“ï¼š{news_item.get('title', '')}"
        simple_summary = self.call_glm_api(simple_prompt, 100) or news_item.get('summary', '')[:150]
        
        # æ„å»ºç»“æœ
        result = {
            **news_item,
            'key_data': key_data,
            'simple_summary': simple_summary,
            'xhs_content': xhs_content or "ç”Ÿæˆå¤±è´¥",
            'douyin_content': dy_content or "ç”Ÿæˆå¤±è´¥",
            'zhihu_summary': zh_content or simple_summary,
            'processed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'ai_processed': bool(xhs_content)
        }
        
        return result
    
    def process_daily_news(self):
        """å¤„ç†æ¯æ—¥èµ„è®¯"""
        today = datetime.now().strftime('%Y-%m-%d')
        input_file = f'output/daily/news_{today}.json'
        
        if not os.path.exists(input_file):
            print(f"âŒ æœªæ‰¾åˆ°ä»Šæ—¥èµ„è®¯æ–‡ä»¶: {input_file}")
            return []
        
        # è¯»å–æ–°é—»
        with open(input_file, 'r', encoding='utf-8') as f:
            news_items = json.load(f)
        
        print(f"å¼€å§‹å¤„ç† {len(news_items)} æ¡èµ„è®¯...")
        
        processed_items = []
        success_count = 0
        
        for i, item in enumerate(news_items):
            print(f"[{i+1}/{len(news_items)}] ", end="")
            
            try:
                processed_item = self.process_news_item(item)
                processed_items.append(processed_item)
                
                if processed_item['ai_processed']:
                    success_count += 1
                    print("âœ… æˆåŠŸ")
                else:
                    print("âš ï¸ éƒ¨åˆ†æˆåŠŸ")
                
                # APIè°ƒç”¨é—´éš”ï¼Œé¿å…é¢‘ç‡é™åˆ¶
                import time
                time.sleep(2)
                
            except Exception as e:
                print(f"âŒ å¤±è´¥: {e}")
                # æ·»åŠ å¤±è´¥æ ‡è®°ä½†ä¿ç•™åŸå§‹æ•°æ®
                item['ai_processed'] = False
                item['ai_error'] = str(e)
                processed_items.append(item)
                continue
        
        # ä¿å­˜å¤„ç†ç»“æœ
        output_file = f'output/daily/processed_{today}.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(processed_items, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
        print(f"  æ€»æ•°: {len(processed_items)}")
        print(f"  æˆåŠŸ: {success_count}")
        print(f"  å¤±è´¥: {len(processed_items) - success_count}")
        print(f"  ä¿å­˜åˆ°: {output_file}")
        
        return processed_items

def main():
    processor = AIProcessor()
    processor.process_daily_news()

if __name__ == '__main__':
    main()
